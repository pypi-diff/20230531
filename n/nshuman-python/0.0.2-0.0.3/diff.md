# Comparing `tmp/nshuman_python-0.0.2-py3-none-any.whl.zip` & `tmp/nshuman_python-0.0.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,62 +1,62 @@
-Zip file size: 72187 bytes, number of entries: 60
--rw-r--r--  2.0 unx      101 b- defN 23-May-22 06:18 nshuman/__init__.py
--rw-r--r--  2.0 unx       72 b- defN 23-May-22 06:19 nshuman/data/__init__.py
--rw-r--r--  2.0 unx     8156 b- defN 23-May-03 01:15 nshuman/data/coco_tools.py
--rw-r--r--  2.0 unx      339 b- defN 23-May-02 02:43 nshuman/data/image.py
--rw-r--r--  2.0 unx     2685 b- defN 23-May-03 01:16 nshuman/data/json_utils.py
--rw-r--r--  2.0 unx       74 b- defN 23-May-22 06:19 nshuman/eval/__init__.py
--rw-r--r--  2.0 unx     6204 b- defN 23-May-22 06:19 nshuman/eval/coco.py
--rw-r--r--  2.0 unx     5252 b- defN 23-May-22 06:20 nshuman/eval/mot.py
--rw-r--r--  2.0 unx    13225 b- defN 23-May-22 06:41 nshuman/eval/mot_evaluator_custom.py
--rw-r--r--  2.0 unx       48 b- defN 23-May-22 06:20 nshuman/human/__init__.py
--rw-r--r--  2.0 unx      403 b- defN 23-May-16 04:28 nshuman/human/common.py
--rw-r--r--  2.0 unx     2420 b- defN 23-May-22 07:04 nshuman/human/get_result.py
--rw-r--r--  2.0 unx      170 b- defN 23-May-22 06:21 nshuman/model_zoo/__init__.py
--rw-r--r--  2.0 unx     1733 b- defN 23-May-22 06:21 nshuman/model_zoo/get_models.py
--rw-r--r--  2.0 unx       32 b- defN 23-May-22 06:22 nshuman/model_zoo/model_attribute/__init__.py
--rw-r--r--  2.0 unx     2413 b- defN 23-May-22 07:06 nshuman/model_zoo/model_attribute/gender.py
--rw-r--r--  2.0 unx      155 b- defN 23-May-22 06:23 nshuman/model_zoo/model_common/__init__.py
--rw-r--r--  2.0 unx     1099 b- defN 23-Apr-27 23:40 nshuman/model_zoo/model_common/load_onnx.py
--rw-r--r--  2.0 unx     2831 b- defN 23-May-02 02:38 nshuman/model_zoo/model_common/load_openvino.py
--rw-r--r--  2.0 unx     3325 b- defN 23-May-02 02:38 nshuman/model_zoo/model_common/load_tensorRT.py
--rw-r--r--  2.0 unx     6128 b- defN 23-Apr-27 23:43 nshuman/model_zoo/model_common/load_tensorRT_multiple.py
--rw-r--r--  2.0 unx       78 b- defN 23-May-22 06:24 nshuman/model_zoo/model_detection/__init__.py
--rw-r--r--  2.0 unx     8742 b- defN 23-May-22 06:43 nshuman/model_zoo/model_detection/yolov5.py
--rw-r--r--  2.0 unx     8451 b- defN 23-May-22 07:07 nshuman/model_zoo/model_detection/yolov7.py
--rw-r--r--  2.0 unx     7967 b- defN 23-May-22 06:43 nshuman/model_zoo/model_detection/yolox.py
--rw-r--r--  2.0 unx       28 b- defN 23-May-22 06:24 nshuman/model_zoo/model_pose/__init__.py
--rw-r--r--  2.0 unx     3517 b- defN 23-May-22 08:12 nshuman/model_zoo/model_pose/vitpose.py
--rw-r--r--  2.0 unx       51 b- defN 23-May-22 06:25 nshuman/model_zoo/model_tracker/__init__.py
--rw-r--r--  2.0 unx     5341 b- defN 23-May-22 06:43 nshuman/model_zoo/model_tracker/bytetracker.py
--rw-r--r--  2.0 unx       52 b- defN 23-May-22 06:50 nshuman/model_zoo/model_tracker/bytetrack/__init__.py
--rw-r--r--  2.0 unx     7066 b- defN 23-May-02 07:35 nshuman/model_zoo/model_tracker/bytetrack/dist.py
--rw-r--r--  2.0 unx     4958 b- defN 23-May-02 07:35 nshuman/model_zoo/model_tracker/bytetrack/visualize.py
--rw-r--r--  2.0 unx      105 b- defN 23-May-22 06:53 nshuman/model_zoo/model_tracker/bytetrack/tracker/__init__.py
--rw-r--r--  2.0 unx      951 b- defN 23-May-02 07:35 nshuman/model_zoo/model_tracker/bytetrack/tracker/basetrack.py
--rw-r--r--  2.0 unx    11531 b- defN 23-May-16 05:42 nshuman/model_zoo/model_tracker/bytetrack/tracker/byte_tracker.py
--rw-r--r--  2.0 unx     9547 b- defN 23-May-02 07:35 nshuman/model_zoo/model_tracker/bytetrack/tracker/kalman_filter.py
--rw-r--r--  2.0 unx     6188 b- defN 23-May-02 07:40 nshuman/model_zoo/model_tracker/bytetrack/tracker/matching.py
--rw-r--r--  2.0 unx       38 b- defN 23-May-22 06:53 nshuman/model_zoo/model_tracker/bytetrack/tracking_utils/__init__.py
--rw-r--r--  2.0 unx     3627 b- defN 23-May-02 07:35 nshuman/model_zoo/model_tracker/bytetrack/tracking_utils/io.py
--rw-r--r--  2.0 unx      958 b- defN 23-May-02 07:35 nshuman/model_zoo/model_tracker/bytetrack/tracking_utils/timer.py
--rw-r--r--  2.0 unx      116 b- defN 23-May-22 06:27 nshuman/utils/__init__.py
--rw-r--r--  2.0 unx       26 b- defN 23-May-22 06:29 nshuman/utils/utils_attribute/__init__.py
--rw-r--r--  2.0 unx     3369 b- defN 23-May-22 06:37 nshuman/utils/utils_attribute/gender_util.py
--rw-r--r--  2.0 unx       77 b- defN 23-May-22 06:29 nshuman/utils/utils_detection/__init__.py
--rw-r--r--  2.0 unx      278 b- defN 23-May-16 05:02 nshuman/utils/utils_detection/draw_result.py
--rw-r--r--  2.0 unx     1391 b- defN 23-May-16 03:25 nshuman/utils/utils_detection/yolo_const.py
--rw-r--r--  2.0 unx    23404 b- defN 23-May-16 07:41 nshuman/utils/utils_detection/yolo_util.py
--rw-r--r--  2.0 unx       24 b- defN 23-May-22 06:29 nshuman/utils/utils_pose/__init__.py
--rw-r--r--  2.0 unx    22759 b- defN 23-May-22 05:38 nshuman/utils/utils_pose/pose_util.py
--rw-r--r--  2.0 unx      153 b- defN 23-May-22 06:29 nshuman/utils/utils_tracker/__init__.py
--rw-r--r--  2.0 unx     4246 b- defN 23-May-08 04:54 nshuman/utils/utils_tracker/datasets_wrapper.py
--rw-r--r--  2.0 unx     7066 b- defN 23-May-15 06:19 nshuman/utils/utils_tracker/dist.py
--rw-r--r--  2.0 unx     6424 b- defN 23-May-22 06:39 nshuman/utils/utils_tracker/mot_custom.py
--rw-r--r--  2.0 unx      958 b- defN 23-May-15 06:14 nshuman/utils/utils_tracker/timer.py
--rw-r--r--  2.0 unx     1998 b- defN 23-May-22 06:14 nshuman/utils/utils_tracker/utils_tracking.py
--rw-r--r--  2.0 unx     4958 b- defN 23-May-15 06:14 nshuman/utils/utils_tracker/visualize.py
--rw-r--r--  2.0 unx      226 b- defN 23-May-22 08:13 nshuman_python-0.0.2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-22 08:13 nshuman_python-0.0.2.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 23-May-22 08:13 nshuman_python-0.0.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     5800 b- defN 23-May-22 08:13 nshuman_python-0.0.2.dist-info/RECORD
-60 files, 219434 bytes uncompressed, 62661 bytes compressed:  71.4%
+Zip file size: 73696 bytes, number of entries: 60
+-rw-r--r--  2.0 unx      101 b- defN 23-May-25 00:39 nshuman/__init__.py
+-rw-r--r--  2.0 unx       72 b- defN 23-May-25 00:39 nshuman/data/__init__.py
+-rw-r--r--  2.0 unx     8156 b- defN 23-May-25 00:39 nshuman/data/coco_tools.py
+-rw-r--r--  2.0 unx      339 b- defN 23-May-25 00:39 nshuman/data/image.py
+-rw-r--r--  2.0 unx     2685 b- defN 23-May-25 00:39 nshuman/data/json_utils.py
+-rw-r--r--  2.0 unx       74 b- defN 23-May-25 00:39 nshuman/eval/__init__.py
+-rw-r--r--  2.0 unx     6204 b- defN 23-May-25 00:39 nshuman/eval/coco.py
+-rw-r--r--  2.0 unx     5252 b- defN 23-May-25 00:39 nshuman/eval/mot.py
+-rw-r--r--  2.0 unx    13225 b- defN 23-May-25 00:39 nshuman/eval/mot_evaluator_custom.py
+-rw-r--r--  2.0 unx       48 b- defN 23-May-25 00:39 nshuman/human/__init__.py
+-rw-r--r--  2.0 unx      403 b- defN 23-May-25 00:39 nshuman/human/common.py
+-rw-r--r--  2.0 unx     2420 b- defN 23-May-25 00:39 nshuman/human/get_result.py
+-rw-r--r--  2.0 unx      170 b- defN 23-May-25 00:39 nshuman/model_zoo/__init__.py
+-rw-r--r--  2.0 unx     1733 b- defN 23-May-25 00:39 nshuman/model_zoo/get_models.py
+-rw-r--r--  2.0 unx       32 b- defN 23-May-25 00:39 nshuman/model_zoo/model_attribute/__init__.py
+-rw-r--r--  2.0 unx     2413 b- defN 23-May-25 00:39 nshuman/model_zoo/model_attribute/gender.py
+-rw-r--r--  2.0 unx      155 b- defN 23-May-25 00:39 nshuman/model_zoo/model_common/__init__.py
+-rw-r--r--  2.0 unx     1099 b- defN 23-May-25 00:39 nshuman/model_zoo/model_common/load_onnx.py
+-rw-r--r--  2.0 unx     2831 b- defN 23-May-25 00:39 nshuman/model_zoo/model_common/load_openvino.py
+-rw-r--r--  2.0 unx     3325 b- defN 23-May-25 00:39 nshuman/model_zoo/model_common/load_tensorRT.py
+-rw-r--r--  2.0 unx     6128 b- defN 23-May-25 00:39 nshuman/model_zoo/model_common/load_tensorRT_multiple.py
+-rw-r--r--  2.0 unx       78 b- defN 23-May-25 00:39 nshuman/model_zoo/model_detection/__init__.py
+-rw-r--r--  2.0 unx     8742 b- defN 23-May-25 00:39 nshuman/model_zoo/model_detection/yolov5.py
+-rw-r--r--  2.0 unx     8451 b- defN 23-May-25 00:39 nshuman/model_zoo/model_detection/yolov7.py
+-rw-r--r--  2.0 unx     7967 b- defN 23-May-25 00:39 nshuman/model_zoo/model_detection/yolox.py
+-rw-r--r--  2.0 unx       28 b- defN 23-May-25 00:39 nshuman/model_zoo/model_pose/__init__.py
+-rw-r--r--  2.0 unx     7105 b- defN 23-May-25 08:13 nshuman/model_zoo/model_pose/vitpose.py
+-rw-r--r--  2.0 unx       51 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/__init__.py
+-rw-r--r--  2.0 unx     6380 b- defN 23-May-31 00:53 nshuman/model_zoo/model_tracker/bytetracker.py
+-rw-r--r--  2.0 unx       52 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/__init__.py
+-rw-r--r--  2.0 unx     7066 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/dist.py
+-rw-r--r--  2.0 unx     7468 b- defN 23-May-31 00:55 nshuman/model_zoo/model_tracker/bytetrack/visualize.py
+-rw-r--r--  2.0 unx      105 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/tracker/__init__.py
+-rw-r--r--  2.0 unx      951 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/tracker/basetrack.py
+-rw-r--r--  2.0 unx    11531 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/tracker/byte_tracker.py
+-rw-r--r--  2.0 unx     9547 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/tracker/kalman_filter.py
+-rw-r--r--  2.0 unx     6188 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/tracker/matching.py
+-rw-r--r--  2.0 unx       38 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/tracking_utils/__init__.py
+-rw-r--r--  2.0 unx     3627 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/tracking_utils/io.py
+-rw-r--r--  2.0 unx      958 b- defN 23-May-25 00:39 nshuman/model_zoo/model_tracker/bytetrack/tracking_utils/timer.py
+-rw-r--r--  2.0 unx      116 b- defN 23-May-25 00:39 nshuman/utils/__init__.py
+-rw-r--r--  2.0 unx       26 b- defN 23-May-25 00:39 nshuman/utils/utils_attribute/__init__.py
+-rw-r--r--  2.0 unx     3369 b- defN 23-May-25 00:39 nshuman/utils/utils_attribute/gender_util.py
+-rw-r--r--  2.0 unx       77 b- defN 23-May-25 00:39 nshuman/utils/utils_detection/__init__.py
+-rw-r--r--  2.0 unx      278 b- defN 23-May-25 00:39 nshuman/utils/utils_detection/draw_result.py
+-rw-r--r--  2.0 unx     1391 b- defN 23-May-25 00:39 nshuman/utils/utils_detection/yolo_const.py
+-rw-r--r--  2.0 unx    23404 b- defN 23-May-25 00:39 nshuman/utils/utils_detection/yolo_util.py
+-rw-r--r--  2.0 unx       24 b- defN 23-May-25 00:39 nshuman/utils/utils_pose/__init__.py
+-rw-r--r--  2.0 unx    24263 b- defN 23-May-25 08:11 nshuman/utils/utils_pose/pose_util.py
+-rw-r--r--  2.0 unx      153 b- defN 23-May-25 00:39 nshuman/utils/utils_tracker/__init__.py
+-rw-r--r--  2.0 unx     4246 b- defN 23-May-25 00:39 nshuman/utils/utils_tracker/datasets_wrapper.py
+-rw-r--r--  2.0 unx     7066 b- defN 23-May-25 00:39 nshuman/utils/utils_tracker/dist.py
+-rw-r--r--  2.0 unx     6424 b- defN 23-May-25 00:39 nshuman/utils/utils_tracker/mot_custom.py
+-rw-r--r--  2.0 unx      958 b- defN 23-May-25 00:39 nshuman/utils/utils_tracker/timer.py
+-rw-r--r--  2.0 unx     3023 b- defN 23-May-31 00:53 nshuman/utils/utils_tracker/utils_tracking.py
+-rw-r--r--  2.0 unx     4958 b- defN 23-May-25 00:39 nshuman/utils/utils_tracker/visualize.py
+-rw-r--r--  2.0 unx      364 b- defN 23-May-31 00:56 nshuman_python-0.0.3.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-31 00:56 nshuman_python-0.0.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-May-31 00:56 nshuman_python-0.0.3.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     5800 b- defN 23-May-31 00:56 nshuman_python-0.0.3.dist-info/RECORD
+60 files, 229238 bytes uncompressed, 64170 bytes compressed:  72.0%
```

## zipnote {}

```diff
@@ -162,20 +162,20 @@
 
 Filename: nshuman/utils/utils_tracker/utils_tracking.py
 Comment: 
 
 Filename: nshuman/utils/utils_tracker/visualize.py
 Comment: 
 
-Filename: nshuman_python-0.0.2.dist-info/METADATA
+Filename: nshuman_python-0.0.3.dist-info/METADATA
 Comment: 
 
-Filename: nshuman_python-0.0.2.dist-info/WHEEL
+Filename: nshuman_python-0.0.3.dist-info/WHEEL
 Comment: 
 
-Filename: nshuman_python-0.0.2.dist-info/top_level.txt
+Filename: nshuman_python-0.0.3.dist-info/top_level.txt
 Comment: 
 
-Filename: nshuman_python-0.0.2.dist-info/RECORD
+Filename: nshuman_python-0.0.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## nshuman/model_zoo/model_pose/vitpose.py

```diff
@@ -60,30 +60,117 @@
     # torch tensor / norm / (N,C,H,W) / input.cuda() - tensorRT-multiple
     def infer(self,img,bboxes,scores,toRGB=False,box_format='xyxy'): # input RGB image (original)
 
         if type(img)==str:
             img = read_image(img)
         if toRGB:
             img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
+
         input_datas = preprocessing(img,bboxes,scores,self.flip_pairs,image_size=[self.img_size[1],self.img_size[0]],num_joints=self.num_joints,use_udp=self.use_udp,box_format=box_format)
+        centers = np.array([data['center'] for data in input_datas])
+        scales = np.array([data['scale'] for data in input_datas])
 
         outs=[]
         for data in input_datas:
             img = data['img']
             out = self.net(img)[0]
-            if self.model_type=='trt':
-                out = np.reshape(out,(img.shape[0],self.num_joints,self.img_size[0]//4,self.img_size[1]//4))
             outs.append(out)
+        outs = np.array(outs)
+        if self.model_type=='trt':
+            outs = np.reshape(outs,(len(centers),self.num_joints,self.img_size[0]//4,self.img_size[1]//4))
+
+        results = keypoints_from_heatmaps(outs,centers,scales,use_udp=self.use_udp)
+
+        return results
+
+    def infer_multi(self,img,bboxes,scores,toRGB=False,box_format='xyxy'):
+
+        if type(img)==str:
+            img = read_image(img)
+        if toRGB:
+            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
+
+        input_datas = preprocessing(img,bboxes,scores,self.flip_pairs,image_size=[self.img_size[1],self.img_size[0]],num_joints=self.num_joints,use_udp=self.use_udp,box_format=box_format)
+
+        imgs = np.array([np.squeeze(data['img'],0) for data in input_datas])
+        centers = np.array([data['center'] for data in input_datas])
+        scales = np.array([data['scale'] for data in input_datas])
+
+        outs = self.net(imgs)[0]
+        outs = np.array(outs)
+        if self.model_type=='trt':
+            outs = np.reshape(outs,(img.shape[0],self.num_joints,self.img_size[0]//4,self.img_size[1]//4))
+
+        results = keypoints_from_heatmaps(outs,centers,scales,use_udp=self.use_udp)
 
-        results=[]
-        for oi,out in enumerate(outs):
-            N, K, H, W = out.shape
-            
-            center = input_datas[oi]['center']
-            scale = input_datas[oi]['scale']
-            
-            preds = keypoints_from_heatmaps(out,np.expand_dims(center,0),np.expand_dims(scale,0),use_udp=self.use_udp)
-            results.append(preds)
         return results
 
+
+    def infer_benchmark(self,img,bboxes,scores,toRGB=False,box_format='xyxy'): # input RGB image (original)
+
+        if type(img)==str:
+            img = read_image(img)
+        if toRGB:
+            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
+
+        start_preproc=time.time()
+        input_datas = preprocessing(img,bboxes,scores,self.flip_pairs,image_size=[self.img_size[1],self.img_size[0]],num_joints=self.num_joints,use_udp=self.use_udp,box_format=box_format)
+        centers = np.array([data['center'] for data in input_datas])
+        scales = np.array([data['scale'] for data in input_datas])
+        end_preproc=time.time()
+        
+
+        start_forward=time.time()
+        outs=[]
+        for data in input_datas:
+            img = data['img']
+            out = self.net(img)[0]
+            outs.append(out)
+        outs = np.array(outs)
+        if self.model_type=='trt':
+            out = np.reshape(out,(len(centers),self.num_joints,self.img_size[0]//4,self.img_size[1]//4))
+        end_forward=time.time()
+
+        start_decode=time.time()
+        results = keypoints_from_heatmaps(outs,centers,scales,use_udp=self.use_udp)
+        end_decode=time.time()
+
+        time_preproc = (end_preproc-start_preproc)*1000
+        time_forward = (end_forward-start_forward)*1000
+        time_decode = (end_decode-start_decode)*1000
+
+        return results, time_preproc,time_forward,time_decode
+
+    def infer_multi_benchmark(self,img,bboxes,scores,toRGB=False,box_format='xyxy'): # input RGB image (original)
+
+        if type(img)==str:
+            img = read_image(img)
+        if toRGB:
+            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
+
+        start_preproc=time.time()
+        input_datas = preprocessing(img,bboxes,scores,self.flip_pairs,image_size=[self.img_size[1],self.img_size[0]],num_joints=self.num_joints,use_udp=self.use_udp,box_format=box_format)
+        imgs = np.array([np.squeeze(data['img'],0) for data in input_datas])
+        centers = np.array([data['center'] for data in input_datas])
+        scales = np.array([data['scale'] for data in input_datas])
+        end_preproc=time.time()
+        
+
+        start_forward=time.time()
+        outs = self.net(imgs)[0]
+        outs = np.array(outs)
+        if self.model_type=='trt':
+            outs = np.reshape(outs,(img.shape[0],self.num_joints,self.img_size[0]//4,self.img_size[1]//4))
+        end_forward=time.time()
+
+        start_decode=time.time()
+        results = keypoints_from_heatmaps(outs,centers,scales,use_udp=self.use_udp)
+        end_decode=time.time()
+
+        time_preproc = (end_preproc-start_preproc)*1000
+        time_forward = (end_forward-start_forward)*1000
+        time_decode = (end_decode-start_decode)*1000
+
+        return results, time_preproc,time_forward,time_decode
+
```

## nshuman/model_zoo/model_tracker/bytetracker.py

```diff
@@ -40,15 +40,21 @@
         self.tracker = BYTETracker(self.args,frame_rate=self.frame_rate)
         self.frame_id = 0
         self.timer = Timer()
         print("tracker init")
 
     # image - original (raw) image
     # return type : 1 = draw image / 2 = results / 3 = all
-    def dttrack(self,dt_model,image,toRGB=False,person=False,return_type=1): 
+    def dttrack(self,dt_model,image,toRGB=False,person=False,return_type=1,**kwargs): 
+
+        draw_info = kwargs.get('draw_info',True)
+        draw_box = kwargs.get('draw_info',True)
+        draw_id = kwargs.get('draw_id',True)
+        draw_blur = kwargs.get('draw_blur',False)
+        min_size = kwargs.get('min_size',0)
 
         # detect
         self.timer.tic()
         if toRGB:
             image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
         bboxes,scores,labels = dt_model.detect(image,person=person) # rgb image array or path
 
@@ -72,41 +78,49 @@
                     # results.append(
                     #     f"{self.frame_id},{tid},{tlwh[0]:.2f},{tlwh[1]:.2f},{tlwh[2]:.2f},{tlwh[3]:.2f},{t.score:.2f},-1,-1,-1\n"
                     # )   
         
             self.timer.toc()
 
             if return_type==1:
-                online_im = plot_tracking(image, online_tlwhs, online_ids, frame_id=self.frame_id + 1, fps=1. / self.timer.average_time) 
+                online_im = plot_tracking(image, online_tlwhs, online_ids, frame_id=self.frame_id + 1, fps=1. / self.timer.average_time, \
+                                            draw_info=draw_info,draw_box=draw_box,draw_id=draw_id,draw_blur=draw_blur,min_size=min_size) 
                 self.frame_id+=1
                 return online_im
             elif return_type==2:
                 self.frame_id+=1
                 return online_tlwhs, online_ids, online_scores
             else:
-                online_im = plot_tracking(image, online_tlwhs, online_ids, frame_id=self.frame_id + 1, fps=1. / self.timer.average_time) 
+                online_im = plot_tracking(image, online_tlwhs, online_ids, frame_id=self.frame_id + 1, fps=1. / self.timer.average_time, \
+                                            draw_info=draw_info,draw_box=draw_box,draw_id=draw_id,draw_blur=draw_blur,min_size=min_size) 
                 self.frame_id+=1
                 return online_tlwhs, online_ids, online_scores, online_im
             
         else:
             self.timer.toc()
             if return_type==1:
                 return image
             elif return_type==2:
                 return [],[],[],[]
             else:
                 return [],[],[],[],image
 
     # return type : 1 = draw image / 2 = results / 3 = all
-    def track(self,image,bboxes,scores,return_type=1): # image - original (raw) image
+    def track(self,image,bboxes,scores,return_type=1,**kwargs): # image - original (raw) image
         online_tlwhs = []
         online_ids = []
         online_scores = []
         #results = []
 
+        draw_info = kwargs.get('draw_info',True)
+        draw_box = kwargs.get('draw_info',True)
+        draw_id = kwargs.get('draw_id',True)
+        draw_blur = kwargs.get('draw_blur',False)
+        min_size = kwargs.get('min_size',0)
+
         self.timer.tic()
         online_targets = self.tracker.update(bboxes,scores)
 
         for t in online_targets:
             tlwh = t.tlwh
             tid = t.track_id
             vertical = tlwh[2] / tlwh[3] > self.aspect_ratio_thresh
@@ -117,22 +131,24 @@
                 # results.append(
                 #     f"{self.frame_id},{tid},{tlwh[0]:.2f},{tlwh[1]:.2f},{tlwh[2]:.2f},{tlwh[3]:.2f},{t.score:.2f},-1,-1,-1\n"
                 # )   
         
         self.timer.toc()
 
         if return_type==1:
-            online_im = plot_tracking(image, online_tlwhs, online_ids, frame_id=self.frame_id + 1, fps=1. / self.timer.average_time) 
+            online_im = plot_tracking(image, online_tlwhs, online_ids, frame_id=self.frame_id + 1, fps=1. / self.timer.average_time, \
+                                        draw_info=draw_info,draw_box=draw_box,draw_id=draw_id,draw_blur=draw_blur,min_size=min_size)
             self.frame_id+=1
             return online_im
         elif return_type==2:
             self.frame_id+=1
             return online_tlwhs, online_ids, online_scores
         else:
-            online_im = plot_tracking(image, online_tlwhs, online_ids, frame_id=self.frame_id + 1, fps=1. / self.timer.average_time) 
+            online_im = plot_tracking(image, online_tlwhs, online_ids, frame_id=self.frame_id + 1, fps=1. / self.timer.average_time, \
+                                        draw_info=draw_info,draw_box=draw_box,draw_id=draw_id,draw_blur=draw_blur,min_size=min_size) 
             self.frame_id+=1
             return online_tlwhs, online_ids, online_scores, online_im
```

## nshuman/model_zoo/model_tracker/bytetrack/visualize.py

```diff
@@ -44,46 +44,112 @@
 
 def get_color(idx):
     idx = idx * 3
     color = ((37 * idx) % 255, (17 * idx) % 255, (29 * idx) % 255)
 
     return color
 
+# original code
+# def plot_tracking(image, tlwhs, obj_ids, scores=None, frame_id=0, fps=0., ids2=None):
+#     im = np.ascontiguousarray(np.copy(image))
+#     im_h, im_w = im.shape[:2]
+
+#     top_view = np.zeros([im_w, im_w, 3], dtype=np.uint8) + 255
+
+#     #text_scale = max(1, image.shape[1] / 1600.)
+#     #text_thickness = 2
+#     #line_thickness = max(1, int(image.shape[1] / 500.))
+#     text_scale = 2
+#     text_thickness = 2
+#     line_thickness = 3
+
+#     radius = max(5, int(im_w/140.))
+#     cv2.putText(im, 'frame: %d fps: %.2f num: %d' % (frame_id, fps, len(tlwhs)),
+#                 (0, int(15 * text_scale)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), thickness=2)
+
+#     for i, tlwh in enumerate(tlwhs):
+#         x1, y1, w, h = tlwh
+#         intbox = tuple(map(int, (x1, y1, x1 + w, y1 + h)))
+#         obj_id = int(obj_ids[i])
+#         id_text = '{}'.format(int(obj_id))
+#         if ids2 is not None:
+#             id_text = id_text + ', {}'.format(int(ids2[i]))
+#         color = get_color(abs(obj_id))
+#         cv2.rectangle(im, intbox[0:2], intbox[2:4], color=color, thickness=line_thickness)
+#         cv2.putText(im, id_text, (intbox[0], intbox[1]), cv2.FONT_HERSHEY_PLAIN, text_scale, (0, 0, 255),
+#                     thickness=text_thickness)
+#     return im
 
-def plot_tracking(image, tlwhs, obj_ids, scores=None, frame_id=0, fps=0., ids2=None):
+def plot_tracking(image, tlwhs, obj_ids, scores=None, frame_id=0, fps=0., ids2=None, \
+                       draw_info=True,draw_box=True,draw_id=True,draw_blur=False,min_size=15):
     im = np.ascontiguousarray(np.copy(image))
     im_h, im_w = im.shape[:2]
+    
+    if draw_blur:
+        maskShape = (im.shape[0], im.shape[1], 1)
+        mask = np.full(maskShape, 0, dtype=np.uint8)
+        tempImg = im.copy()
 
     top_view = np.zeros([im_w, im_w, 3], dtype=np.uint8) + 255
 
-    #text_scale = max(1, image.shape[1] / 1600.)
-    #text_thickness = 2
-    #line_thickness = max(1, int(image.shape[1] / 500.))
     text_scale = 2
     text_thickness = 2
     line_thickness = 3
 
     radius = max(5, int(im_w/140.))
-    cv2.putText(im, 'frame: %d fps: %.2f num: %d' % (frame_id, fps, len(tlwhs)),
-                (0, int(15 * text_scale)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), thickness=2)
+    if draw_info:
+        cv2.putText(im, 'frame: %d fps: %.2f num: %d' % (frame_id, fps, len(tlwhs)),
+                    (0, int(15 * text_scale)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), thickness=2)
 
     for i, tlwh in enumerate(tlwhs):
         x1, y1, w, h = tlwh
+        if w<min_size or h<min_size:
+            continue
         intbox = tuple(map(int, (x1, y1, x1 + w, y1 + h)))
         obj_id = int(obj_ids[i])
         id_text = '{}'.format(int(obj_id))
         if ids2 is not None:
             id_text = id_text + ', {}'.format(int(ids2[i]))
         color = get_color(abs(obj_id))
-        cv2.rectangle(im, intbox[0:2], intbox[2:4], color=color, thickness=line_thickness)
-        cv2.putText(im, id_text, (intbox[0], intbox[1]), cv2.FONT_HERSHEY_PLAIN, text_scale, (0, 0, 255),
-                    thickness=text_thickness)
+        if draw_box:
+            cv2.rectangle(im, intbox[0:2], intbox[2:4], color=color, thickness=line_thickness)
+        if draw_id:
+            cv2.putText(im, id_text, (intbox[0], intbox[1]), cv2.FONT_HERSHEY_PLAIN, text_scale, (0, 0, 255),
+                        thickness=text_thickness)
+        if draw_blur:
+            int_xywh = tuple(map(int, (x1, y1, w, h)))
+            x,y,w,h = int_xywh
+            if x<0:
+                x=0
+            if y<0:
+                y=0
+            if x>im.shape[1]:
+                x = im.shape[1]-1
+            if h>im.shape[0]:
+                h = im.shape[0]-1
+            tempImg[y:y+h, x:x+w] = cv2.blur(tempImg[y:y+h, x:x+w] ,(23,23))
+            
+            center = (x+(w//2),y+(h//2))
+            axesLength = (round(w/2),round(h*0.575))
+            angle=0
+            startAngle=0
+            endAngle=360
+            color = (0,255,0)
+            thickness=3
+            
+            cv2.ellipse(mask , center ,axesLength, angle,startAngle,endAngle,255,-1)
+            
+    if draw_blur:
+        mask_inv = cv2.bitwise_not(mask)
+        img1_bg = cv2.bitwise_and(im,im,mask = mask_inv)
+        img2_fg = cv2.bitwise_and(tempImg,tempImg,mask = mask)
+        im = cv2.add(img1_bg,img2_fg) 
+            
     return im
 
-
 _COLORS = np.array(
     [
         0.000, 0.447, 0.741,
         0.850, 0.325, 0.098,
         0.929, 0.694, 0.125,
         0.494, 0.184, 0.556,
         0.466, 0.674, 0.188,
```

## nshuman/utils/utils_pose/pose_util.py

```diff
@@ -431,21 +431,57 @@
             preds[i], center[i], scale[i], [W, H], use_udp=use_udp)
 
     if post_process == 'megvii':
         maxvals = maxvals / 255.0 + 0.5
 
     return preds, maxvals
 
-def draw_pose(img,results,kpt_score_thr=0.3,radius=4,thickness=1,bbox_color='green',dataset='coco'):
+# pre
+# def draw_pose(img,results,kpt_score_thr=0.3,radius=4,thickness=1,bbox_color='green',dataset='coco'):
+#     dimg = img.copy()
+#     img_h,img_w,_ = dimg.shape
+
+#     for i in range(len(results)):
+#         preds = results[i][0][0]
+#         pscores = results[i][1][0]
+
+#         kpts = np.array(preds, copy=False)
+#         kpts_scores = np.array(pscores,copy=False)
+        
+#         # draw points
+#         for kid, kpt in enumerate(kpts):
+#             x_coord, y_coord = int(kpt[0]), int(kpt[1])
+#             kpt_score = kpts_scores[kid]
+
+#             if kpt_score > kpt_score_thr:
+#                 color = tuple(int(c) for c in KPT_COLOR[dataset][kid])
+#                 dimg = cv2.circle(dimg, (int(x_coord), int(y_coord)), radius,color, -1)
+
+#         # draw links
+#         for sk_id, sk in enumerate(SKELETON[dataset]):
+#             pos1 = (int(kpts[sk[0], 0]), int(kpts[sk[0], 1]))
+#             pos2 = (int(kpts[sk[1], 0]), int(kpts[sk[1], 1]))
+#             if (pos1[0] > 0 and pos1[0] < img_w and pos1[1] > 0
+#                     and pos1[1] < img_h and pos2[0] > 0 and pos2[0] < img_w
+#                     and pos2[1] > 0 and pos2[1] < img_h
+#                     and kpts_scores[sk[0]] > kpt_score_thr
+#                     and kpts_scores[sk[1]] > kpt_score_thr):
+#                 color = tuple(int(c) for c in LINK_COLOR[dataset][sk_id])
+
+#                 dimg = cv2.line(dimg, pos1, pos2, color, thickness=thickness)
+
+#     return dimg
+
+def draw_pose(img,results,kpt_score_thr=0.3,radius=4,thickness=1,bbox_color='green',dataset='coco'): # results=[keypoints..., scores...]
     dimg = img.copy()
     img_h,img_w,_ = dimg.shape
 
-    for i in range(len(results)):
-        preds = results[i][0][0]
-        pscores = results[i][1][0]
+    for i in range(len(results[0])):
+        preds = results[0][i]
+        pscores = results[1][i]
 
         kpts = np.array(preds, copy=False)
         kpts_scores = np.array(pscores,copy=False)
         
         # draw points
         for kid, kpt in enumerate(kpts):
             x_coord, y_coord = int(kpt[0]), int(kpt[1])
```

## nshuman/utils/utils_tracker/utils_tracking.py

```diff
@@ -2,62 +2,92 @@
 import numpy as np
 import cv2
 #from tqdm import tqdm
 
 from ..utils_pose.pose_util import draw_pose
 
 
-def tracking_video(vid_path,save_path, detection_model, tracker,person=False,toRGB=True):
+def tracking_video(vid_path,save_path, detection_model, tracker,person=False,toRGB=True,**kwargs):
     cap = cv2.VideoCapture(vid_path)
     width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float
     height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float
     fps = cap.get(cv2.CAP_PROP_FPS)
 
     vid_writer = cv2.VideoWriter(
         save_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (int(width), int(height))
     )
 
     while True:
         ret_val, frame = cap.read()
         if ret_val:
-            track_plot = tracker.dttrack(detection_model,frame,toRGB=toRGB,person=person,return_type=1)
+            track_plot = tracker.dttrack(detection_model,frame,toRGB=toRGB,person=person,return_type=1,**kwargs)
             track_plot = cv2.cvtColor(track_plot,cv2.COLOR_RGB2BGR)
             vid_writer.write(track_plot)
         else:
             break
     cap.release()
     vid_writer.release()
 
     print("Finish Tracking ...")
     print("Save:",save_path)
     return
 
-def tracking_video_pose(vid_path,save_path, detection_model,pose_model, tracker,person=False,toRGB=True):
+def tracking_video_pose(vid_path,save_path, detection_model,pose_model, tracker,person=False,toRGB=True,**kwargs):
     cap = cv2.VideoCapture(vid_path)
     width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float
     height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float
     fps = cap.get(cv2.CAP_PROP_FPS)
 
     vid_writer = cv2.VideoWriter(
         save_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (int(width), int(height))
     )
 
     while True:
         ret_val, frame = cap.read()
         if ret_val:
-            online_tlwhs, online_ids, online_scores,track_plot = tracker.dttrack(detection_model,frame,toRGB=toRGB,person=person,return_type=3)
+            online_tlwhs, online_ids, online_scores,track_plot = tracker.dttrack(detection_model,frame,toRGB=toRGB,person=person,return_type=3,**kwargs)
             results = pose_model.infer(frame,online_tlwhs,online_scores,toRGB=toRGB,box_format='xywh')
             track_plot = draw_pose(track_plot,results)
             track_plot = cv2.cvtColor(track_plot,cv2.COLOR_RGB2BGR)
 
             vid_writer.write(track_plot)
         else:
             break
     cap.release()
     vid_writer.release()
 
     print("Finish Tracking ...")
     print("Save:",save_path)
     return
 
+def blur_ellipse(img,bbox_xywh):
+                 
+    maskShape = (img.shape[0], img.shape[1], 1)
+    mask = np.full(maskShape, 0, dtype=np.uint8)
+    tempImg = img.copy()
+    # start the face loop
+    for tlwh in bbox_xywh:
+        tlwh = tlwh.astype(np.int32)
+        x,y,w,h = tlwh
+        #blur first so that the circle is not blurred
+        tempImg[y:y+h, x:x+w] = cv2.blur(tempImg[y:y+h, x:x+w] ,(23,23))
+        # create the circle in the mask and in the tempImg, notice the one in the mask is full
+
+        center = (x+(w//2),y+(h//2))
+        axesLength = (round(w/2),round(h*0.575))
+        angle=0
+        startAngle=0
+        endAngle=360
+        color = (0,255,0)
+        thickness=3
+
+        cv2.ellipse(mask , center ,axesLength, angle,startAngle,endAngle,255,-1)
+
+    mask_inv = cv2.bitwise_not(mask)
+    img1_bg = cv2.bitwise_and(img,img,mask = mask_inv)
+    img2_fg = cv2.bitwise_and(tempImg,tempImg,mask = mask)
+    dst = cv2.add(img1_bg,img2_fg)
+    
+    return dst
+
```

## Comparing `nshuman_python-0.0.2.dist-info/RECORD` & `nshuman_python-0.0.3.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -20,20 +20,20 @@
 nshuman/model_zoo/model_common/load_tensorRT.py,sha256=C-TAjZs1NqeZH93yAgCbbHpcsO5Iulee5Q40_hVrsVc,3325
 nshuman/model_zoo/model_common/load_tensorRT_multiple.py,sha256=5M1ePk6SE7J_T5gBFKMPZZYH9_jJG_WWL8dmoWrKKh0,6128
 nshuman/model_zoo/model_detection/__init__.py,sha256=ROY3P-c_qIggcd52xWucUp5U2gKE_Qms4Q1xNqa3jRU,78
 nshuman/model_zoo/model_detection/yolov5.py,sha256=iADPquHwEgwpL1C6TtEqdoUKkl7Abgacc0-3hAq4NhQ,8742
 nshuman/model_zoo/model_detection/yolov7.py,sha256=hqsYEsDB8qYcY8kN9NjjcL3v0zks5LK_G1V8jGxgptY,8451
 nshuman/model_zoo/model_detection/yolox.py,sha256=BA1E5zp5FHszASIgUr34hy_uIHqEHLK5V1FqBRYI6iE,7967
 nshuman/model_zoo/model_pose/__init__.py,sha256=Td6d36Z-5zJYVLO9SUNHPlRWfaQhr5xpE2khQcrF50k,28
-nshuman/model_zoo/model_pose/vitpose.py,sha256=FRCX1alH5Oz2_ow55tfF0H5-zNRgeWRSeJriy7nvyy0,3517
+nshuman/model_zoo/model_pose/vitpose.py,sha256=lSZ1BOzPhbfbmwMM3bDZC3nzGRM-8PB3fWMHibFLz_I,7105
 nshuman/model_zoo/model_tracker/__init__.py,sha256=jCPBO5CNYTIyGie4CICcb-9C1wD9XOn-tmsXXljiN58,51
-nshuman/model_zoo/model_tracker/bytetracker.py,sha256=O_trKg2aYmoCpSKdCSftUmf5RatjrEQ4RAwh1UcqZOs,5341
+nshuman/model_zoo/model_tracker/bytetracker.py,sha256=_x4Y4D8xT5q4mALPxN_e_Kb3dQfKnBCmgtSqezOGOng,6380
 nshuman/model_zoo/model_tracker/bytetrack/__init__.py,sha256=prl9yiJdYhBrdp964hIg-b9MPuc4yNX4bd9JCyvdx1I,52
 nshuman/model_zoo/model_tracker/bytetrack/dist.py,sha256=_bBR7HpjiyZhe2l0CftQ1pSAl2fIkiAE7FNJZGR5gYc,7066
-nshuman/model_zoo/model_tracker/bytetrack/visualize.py,sha256=GFb5VJe-IOTrV0wky_p5eUpmwJj7Yg4mXAgNnum7Zfw,4958
+nshuman/model_zoo/model_tracker/bytetrack/visualize.py,sha256=6a-gO-n5ggqJ2xtTDQven93dMQWaS1hoQU8kWd7orxM,7468
 nshuman/model_zoo/model_tracker/bytetrack/tracker/__init__.py,sha256=4FNxNttyXlb2ngdQ1NO3j9f-X18E-xA49mXyuqODJIA,105
 nshuman/model_zoo/model_tracker/bytetrack/tracker/basetrack.py,sha256=yTivz3xRa7pKdxVcJJn8rm-Sbfei-qb3OkvhsHP5uy0,951
 nshuman/model_zoo/model_tracker/bytetrack/tracker/byte_tracker.py,sha256=6dBb42xS5Mw6Q5iKq-B8tmQexSUXhxYMMBKhHKgBFdk,11531
 nshuman/model_zoo/model_tracker/bytetrack/tracker/kalman_filter.py,sha256=mELQ3ZlXyX4xLULleJRBrdVQggZth8wFGsdoFDpG6zk,9547
 nshuman/model_zoo/model_tracker/bytetrack/tracker/matching.py,sha256=yADO-IxWcIZy47MhHs3PAlIfU9oXi-XMmC01LgkExv4,6188
 nshuman/model_zoo/model_tracker/bytetrack/tracking_utils/__init__.py,sha256=n0QTSR4QRuW_zEA_3aq8LqzDykgGN3m95WrUMpVo_Nk,38
 nshuman/model_zoo/model_tracker/bytetrack/tracking_utils/io.py,sha256=KtcgFGtTNpfRMT4g1lc2ZAON00wCWfTH5zgDLpwrg3k,3627
@@ -42,19 +42,19 @@
 nshuman/utils/utils_attribute/__init__.py,sha256=qjkD2MMlR1ip2IRYJ6-Wvbu73t9fU4V7r6jTENagzdI,26
 nshuman/utils/utils_attribute/gender_util.py,sha256=LeOU2i8nDrl3ZyR3witwvQ7FGOE3p9oURkwCLzEDSME,3369
 nshuman/utils/utils_detection/__init__.py,sha256=4MJcx-ULqu3N2yz4ljV4RAA6JN1AxOUTS0V870kkiWY,77
 nshuman/utils/utils_detection/draw_result.py,sha256=FSkoNiZCztJ_LCuSAlrwtaKsqIeHeCL4iVIyPZZLwCE,278
 nshuman/utils/utils_detection/yolo_const.py,sha256=A1kyyMBdOCqQit87FGqPHrk6HW1Wk2grP6d44xM_w44,1391
 nshuman/utils/utils_detection/yolo_util.py,sha256=2AnvgUsXHNqzi6_iiI3aqpi6AP8xHjmJrEWnc_iQhcQ,23404
 nshuman/utils/utils_pose/__init__.py,sha256=rhs79-DUnCu7O7HtNmqhifM4hITVvkeIGM8ylaBzDXI,24
-nshuman/utils/utils_pose/pose_util.py,sha256=ite_DSKn1fKcjL6IqCVJScm47Gk4Ng7aRSlsGn8lVJY,22759
+nshuman/utils/utils_pose/pose_util.py,sha256=ZL1V-KHjkRI4zk70DdvfcSj4mc0dLMo16kQp-_-DHTA,24263
 nshuman/utils/utils_tracker/__init__.py,sha256=Vq_fZBEeZ1UK3wAx9RZZpPJYf7CM-soacjMGas4IqbQ,153
 nshuman/utils/utils_tracker/datasets_wrapper.py,sha256=BDqr3PG_C_PlVcVwVH6xQf5-S-JtktWja6aD3zkSd58,4246
 nshuman/utils/utils_tracker/dist.py,sha256=_bBR7HpjiyZhe2l0CftQ1pSAl2fIkiAE7FNJZGR5gYc,7066
 nshuman/utils/utils_tracker/mot_custom.py,sha256=MeluHAOuH_oKSDdrRz0AZ3b1qx5AXw-9R80rpyhYXok,6424
 nshuman/utils/utils_tracker/timer.py,sha256=wjOo45QtJzTwtWt584Xaq8wBpXB2SclpQ6UYuVFpXSU,958
-nshuman/utils/utils_tracker/utils_tracking.py,sha256=FXYgMMT7viaQiyL4tRXK4CbK5TEqw-oOLU42fi5R0rY,1998
+nshuman/utils/utils_tracker/utils_tracking.py,sha256=tpEcjR1MLXsdZ7bG1czbM7cjIwBhJsZX7Wbh0BTppoE,3023
 nshuman/utils/utils_tracker/visualize.py,sha256=GFb5VJe-IOTrV0wky_p5eUpmwJj7Yg4mXAgNnum7Zfw,4958
-nshuman_python-0.0.2.dist-info/METADATA,sha256=31fSEkR0Iha2-ks-RJKeSSlN7EzNEG0uNRQoi09F7ZQ,226
-nshuman_python-0.0.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-nshuman_python-0.0.2.dist-info/top_level.txt,sha256=u_WHp5R9CrjOiRDIiwMBp9gWkP1EQlma7RhOD0LtGmg,8
-nshuman_python-0.0.2.dist-info/RECORD,,
+nshuman_python-0.0.3.dist-info/METADATA,sha256=RDDs8YjOIhH-CFtXVYrvQX287XanAJAx4g1TgavIPl4,364
+nshuman_python-0.0.3.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+nshuman_python-0.0.3.dist-info/top_level.txt,sha256=u_WHp5R9CrjOiRDIiwMBp9gWkP1EQlma7RhOD0LtGmg,8
+nshuman_python-0.0.3.dist-info/RECORD,,
```

