# Comparing `tmp/mlrun-1.4.0rc7-py3-none-any.whl.zip` & `tmp/mlrun-1.4.0rc8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,412 +1,412 @@
-Zip file size: 1192190 bytes, number of entries: 410
--rw-r--r--  2.0 unx     8727 b- defN 23-May-22 19:22 mlrun/__init__.py
--rw-r--r--  2.0 unx    49342 b- defN 23-May-22 19:22 mlrun/__main__.py
--rw-r--r--  2.0 unx    55437 b- defN 23-May-22 19:22 mlrun/config.py
--rw-r--r--  2.0 unx     6780 b- defN 23-May-22 19:22 mlrun/errors.py
--rw-r--r--  2.0 unx    39096 b- defN 23-May-22 19:22 mlrun/execution.py
--rw-r--r--  2.0 unx    15624 b- defN 23-May-22 19:22 mlrun/features.py
--rw-r--r--  2.0 unx     4876 b- defN 23-May-22 19:22 mlrun/k8s_utils.py
--rw-r--r--  2.0 unx    29646 b- defN 23-May-22 19:22 mlrun/kfpops.py
--rw-r--r--  2.0 unx     8360 b- defN 23-May-22 19:22 mlrun/lists.py
--rw-r--r--  2.0 unx    57270 b- defN 23-May-22 19:22 mlrun/model.py
--rw-r--r--  2.0 unx    11828 b- defN 23-May-22 19:22 mlrun/render.py
--rw-r--r--  2.0 unx    64759 b- defN 23-May-22 19:22 mlrun/run.py
--rw-r--r--  2.0 unx     7783 b- defN 23-May-22 19:22 mlrun/secrets.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/__init__.py
--rw-r--r--  2.0 unx     2105 b- defN 23-May-22 19:22 mlrun/api/alembic.ini
--rw-r--r--  2.0 unx      685 b- defN 23-May-22 19:22 mlrun/api/constants.py
--rw-r--r--  2.0 unx    25653 b- defN 23-May-22 19:22 mlrun/api/initial_data.py
--rw-r--r--  2.0 unx     7543 b- defN 23-May-22 19:22 mlrun/api/launcher.py
--rw-r--r--  2.0 unx    26443 b- defN 23-May-22 19:22 mlrun/api/main.py
--rw-r--r--  2.0 unx     5247 b- defN 23-May-22 19:22 mlrun/api/middlewares.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/api/__init__.py
--rw-r--r--  2.0 unx     4243 b- defN 23-May-22 19:22 mlrun/api/api/api.py
--rw-r--r--  2.0 unx     3197 b- defN 23-May-22 19:22 mlrun/api/api/deps.py
--rw-r--r--  2.0 unx    36404 b- defN 23-May-22 19:22 mlrun/api/api/utils.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/__init__.py
--rw-r--r--  2.0 unx    10394 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/artifacts.py
--rw-r--r--  2.0 unx     1199 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/auth.py
--rw-r--r--  2.0 unx     3618 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/background_tasks.py
--rw-r--r--  2.0 unx     1214 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/client_spec.py
--rw-r--r--  2.0 unx     1175 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/clusterization_spec.py
--rw-r--r--  2.0 unx    29543 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/feature_store.py
--rw-r--r--  2.0 unx     6104 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/files.py
--rw-r--r--  2.0 unx     5468 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/frontend_spec.py
--rw-r--r--  2.0 unx    35206 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/functions.py
--rw-r--r--  2.0 unx     5986 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/grafana_proxy.py
--rw-r--r--  2.0 unx     1344 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/healthz.py
--rw-r--r--  2.0 unx    10399 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/hub.py
--rw-r--r--  2.0 unx     2450 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/logs.py
--rw-r--r--  2.0 unx    15817 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/model_endpoints.py
--rw-r--r--  2.0 unx     3756 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/operations.py
--rw-r--r--  2.0 unx     9220 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/pipelines.py
--rw-r--r--  2.0 unx    11494 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/projects.py
--rw-r--r--  2.0 unx     9078 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/runs.py
--rw-r--r--  2.0 unx     9063 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/runtime_resources.py
--rw-r--r--  2.0 unx    10731 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/schedules.py
--rw-r--r--  2.0 unx     6061 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/secrets.py
--rw-r--r--  2.0 unx     5298 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/submit.py
--rw-r--r--  2.0 unx     4894 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/tags.py
--rw-r--r--  2.0 unx     1203 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/internal/__init__.py
--rw-r--r--  2.0 unx     1043 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/internal/config.py
--rw-r--r--  2.0 unx     1724 b- defN 23-May-22 19:22 mlrun/api/api/endpoints/internal/memory_reports.py
--rw-r--r--  2.0 unx     1209 b- defN 23-May-22 19:22 mlrun/api/crud/__init__.py
--rw-r--r--  2.0 unx     5610 b- defN 23-May-22 19:22 mlrun/api/crud/artifacts.py
--rw-r--r--  2.0 unx     7331 b- defN 23-May-22 19:22 mlrun/api/crud/client_spec.py
--rw-r--r--  2.0 unx     1055 b- defN 23-May-22 19:22 mlrun/api/crud/clusterization_spec.py
--rw-r--r--  2.0 unx    18628 b- defN 23-May-22 19:22 mlrun/api/crud/feature_store.py
--rw-r--r--  2.0 unx     3556 b- defN 23-May-22 19:22 mlrun/api/crud/functions.py
--rw-r--r--  2.0 unx    12025 b- defN 23-May-22 19:22 mlrun/api/crud/hub.py
--rw-r--r--  2.0 unx     9729 b- defN 23-May-22 19:22 mlrun/api/crud/logs.py
--rw-r--r--  2.0 unx     2751 b- defN 23-May-22 19:22 mlrun/api/crud/notifications.py
--rw-r--r--  2.0 unx    14030 b- defN 23-May-22 19:22 mlrun/api/crud/pipelines.py
--rw-r--r--  2.0 unx    14269 b- defN 23-May-22 19:22 mlrun/api/crud/projects.py
--rw-r--r--  2.0 unx     5963 b- defN 23-May-22 19:22 mlrun/api/crud/runs.py
--rw-r--r--  2.0 unx     5575 b- defN 23-May-22 19:22 mlrun/api/crud/runtime_resources.py
--rw-r--r--  2.0 unx    20145 b- defN 23-May-22 19:22 mlrun/api/crud/secrets.py
--rw-r--r--  2.0 unx     3277 b- defN 23-May-22 19:22 mlrun/api/crud/tags.py
--rw-r--r--  2.0 unx      722 b- defN 23-May-22 19:22 mlrun/api/crud/model_monitoring/__init__.py
--rw-r--r--  2.0 unx    15692 b- defN 23-May-22 19:22 mlrun/api/crud/model_monitoring/grafana.py
--rw-r--r--  2.0 unx    43000 b- defN 23-May-22 19:22 mlrun/api/crud/model_monitoring/model_endpoints.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/crud/runtimes/__init__.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/crud/runtimes/nuclio/__init__.py
--rw-r--r--  2.0 unx    17168 b- defN 23-May-22 19:22 mlrun/api/crud/runtimes/nuclio/function.py
--rw-r--r--  2.0 unx    11398 b- defN 23-May-22 19:22 mlrun/api/crud/runtimes/nuclio/helpers.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/db/__init__.py
--rw-r--r--  2.0 unx    15056 b- defN 23-May-22 19:22 mlrun/api/db/base.py
--rw-r--r--  2.0 unx      816 b- defN 23-May-22 19:22 mlrun/api/db/init_db.py
--rw-r--r--  2.0 unx      993 b- defN 23-May-22 19:22 mlrun/api/db/session.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/db/sqldb/__init__.py
--rw-r--r--  2.0 unx   144159 b- defN 23-May-22 19:22 mlrun/api/db/sqldb/db.py
--rw-r--r--  2.0 unx     2340 b- defN 23-May-22 19:22 mlrun/api/db/sqldb/helpers.py
--rw-r--r--  2.0 unx     2542 b- defN 23-May-22 19:22 mlrun/api/db/sqldb/session.py
--rw-r--r--  2.0 unx     1063 b- defN 23-May-22 19:22 mlrun/api/db/sqldb/models/__init__.py
--rw-r--r--  2.0 unx    20642 b- defN 23-May-22 19:22 mlrun/api/db/sqldb/models/models_mysql.py
--rw-r--r--  2.0 unx    18304 b- defN 23-May-22 19:22 mlrun/api/db/sqldb/models/models_sqlite.py
--rw-r--r--  2.0 unx     2906 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/env.py
--rw-r--r--  2.0 unx     1203 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/28383af526f3_market_place_to_hub.py
--rw-r--r--  2.0 unx     4614 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/32bae1b0e29c_increase_timestamp_fields_precision.py
--rw-r--r--  2.0 unx     1936 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/4903aef6a91d_tag_foreign_key_and_cascades.py
--rw-r--r--  2.0 unx     1909 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/5f1351c88a19_adding_background_tasks_table.py
--rw-r--r--  2.0 unx     1415 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/88e656800d6a_add_requested_logs_column_and_index_to_.py
--rw-r--r--  2.0 unx     1504 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/9d16de5f03a7_adding_data_versions_table.py
--rw-r--r--  2.0 unx     1649 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/b86f5b53f3d7_adding_name_and_updated_to_runs_table.py
--rw-r--r--  2.0 unx    24057 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/c4af40b0bf61_init.py
--rw-r--r--  2.0 unx     2457 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/c905d15bd91d_notifications.py
--rw-r--r--  2.0 unx     1351 b- defN 23-May-22 19:22 mlrun/api/migrations_mysql/versions/ee041e8fdaa0_adding_next_run_time_column_to_schedule_.py
--rw-r--r--  2.0 unx     2906 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/env.py
--rw-r--r--  2.0 unx    11473 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/11f8dd2dc9fe_init.py
--rw-r--r--  2.0 unx     1348 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/1c954f8cb32d_schedule_last_run_uri.py
--rw-r--r--  2.0 unx     5180 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/2b6d23c715aa_adding_feature_sets.py
--rw-r--r--  2.0 unx     2595 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/4acd9430b093_market_place_to_hub.py
--rw-r--r--  2.0 unx     1388 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/6401142f2d7c_adding_next_run_time_column_to_schedule_.py
--rw-r--r--  2.0 unx     1767 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/64d90a1a69bc_adding_background_tasks_table.py
--rw-r--r--  2.0 unx     1360 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/803438ecd005_add_requested_logs_column_to_runs.py
--rw-r--r--  2.0 unx     1259 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/863114f0c659_refactoring_feature_set.py
--rw-r--r--  2.0 unx     2147 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/959ae00528ad_notifications.py
--rw-r--r--  2.0 unx     1482 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/accf9fc83d38_adding_data_versions_table.py
--rw-r--r--  2.0 unx     1892 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/b68e8e897a28_schedule_labels.py
--rw-r--r--  2.0 unx     1882 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/bcd0c1f9720c_adding_project_labels.py
--rw-r--r--  2.0 unx     1420 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/cf21882f938e_schedule_id.py
--rw-r--r--  2.0 unx     2034 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/d781f58f607f_tag_object_name_string.py
--rw-r--r--  2.0 unx     1828 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/deac06871ace_adding_marketplace_sources_table.py
--rw-r--r--  2.0 unx     1380 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/e1dd5983c06b_schedule_concurrency_limit.py
--rw-r--r--  2.0 unx     1831 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/e5594ed3ab53_adding_name_and_updated_to_runs_table.py
--rw-r--r--  2.0 unx     3936 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/f4249b4ba6fa_adding_feature_vectors.py
--rw-r--r--  2.0 unx     2588 b- defN 23-May-22 19:22 mlrun/api/migrations_sqlite/versions/f7b5a1a03629_adding_feature_labels.py
--rw-r--r--  2.0 unx    13338 b- defN 23-May-22 19:22 mlrun/api/schemas/__init__.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/utils/__init__.py
--rw-r--r--  2.0 unx     1092 b- defN 23-May-22 19:22 mlrun/api/utils/asyncio.py
--rw-r--r--  2.0 unx     7371 b- defN 23-May-22 19:22 mlrun/api/utils/background_tasks.py
--rw-r--r--  2.0 unx    25637 b- defN 23-May-22 19:22 mlrun/api/utils/builder.py
--rw-r--r--  2.0 unx     2431 b- defN 23-May-22 19:22 mlrun/api/utils/helpers.py
--rw-r--r--  2.0 unx     3728 b- defN 23-May-22 19:22 mlrun/api/utils/memory_reports.py
--rw-r--r--  2.0 unx     2599 b- defN 23-May-22 19:22 mlrun/api/utils/periodic.py
--rw-r--r--  2.0 unx    39305 b- defN 23-May-22 19:22 mlrun/api/utils/scheduler.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/utils/auth/__init__.py
--rw-r--r--  2.0 unx    12383 b- defN 23-May-22 19:22 mlrun/api/utils/auth/verifier.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/utils/auth/providers/__init__.py
--rw-r--r--  2.0 unx     1381 b- defN 23-May-22 19:22 mlrun/api/utils/auth/providers/base.py
--rw-r--r--  2.0 unx     1460 b- defN 23-May-22 19:22 mlrun/api/utils/auth/providers/nop.py
--rw-r--r--  2.0 unx    10883 b- defN 23-May-22 19:22 mlrun/api/utils/auth/providers/opa.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/utils/clients/__init__.py
--rw-r--r--  2.0 unx    13271 b- defN 23-May-22 19:22 mlrun/api/utils/clients/chief.py
--rw-r--r--  2.0 unx    31249 b- defN 23-May-22 19:22 mlrun/api/utils/clients/iguazio.py
--rw-r--r--  2.0 unx    12109 b- defN 23-May-22 19:22 mlrun/api/utils/clients/log_collector.py
--rw-r--r--  2.0 unx     9916 b- defN 23-May-22 19:22 mlrun/api/utils/clients/nuclio.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/utils/clients/protocols/__init__.py
--rw-r--r--  2.0 unx     2567 b- defN 23-May-22 19:22 mlrun/api/utils/clients/protocols/grpc.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/utils/db/__init__.py
--rw-r--r--  2.0 unx     3305 b- defN 23-May-22 19:22 mlrun/api/utils/db/alembic.py
--rw-r--r--  2.0 unx     8214 b- defN 23-May-22 19:22 mlrun/api/utils/db/backup.py
--rw-r--r--  2.0 unx     3787 b- defN 23-May-22 19:22 mlrun/api/utils/db/mysql.py
--rw-r--r--  2.0 unx      992 b- defN 23-May-22 19:22 mlrun/api/utils/db/sql_collation.py
--rw-r--r--  2.0 unx     3861 b- defN 23-May-22 19:22 mlrun/api/utils/db/sqlite_migration.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/utils/projects/__init__.py
--rw-r--r--  2.0 unx    17423 b- defN 23-May-22 19:22 mlrun/api/utils/projects/follower.py
--rw-r--r--  2.0 unx    19372 b- defN 23-May-22 19:22 mlrun/api/utils/projects/leader.py
--rw-r--r--  2.0 unx     7133 b- defN 23-May-22 19:22 mlrun/api/utils/projects/member.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/utils/projects/remotes/__init__.py
--rw-r--r--  2.0 unx     2659 b- defN 23-May-22 19:22 mlrun/api/utils/projects/remotes/follower.py
--rw-r--r--  2.0 unx     2094 b- defN 23-May-22 19:22 mlrun/api/utils/projects/remotes/leader.py
--rw-r--r--  2.0 unx     5000 b- defN 23-May-22 19:22 mlrun/api/utils/projects/remotes/nop_follower.py
--rw-r--r--  2.0 unx     3861 b- defN 23-May-22 19:22 mlrun/api/utils/projects/remotes/nop_leader.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/api/utils/singletons/__init__.py
--rw-r--r--  2.0 unx     1202 b- defN 23-May-22 19:22 mlrun/api/utils/singletons/db.py
--rw-r--r--  2.0 unx    22651 b- defN 23-May-22 19:22 mlrun/api/utils/singletons/k8s.py
--rw-r--r--  2.0 unx      840 b- defN 23-May-22 19:22 mlrun/api/utils/singletons/logs_dir.py
--rw-r--r--  2.0 unx     1279 b- defN 23-May-22 19:22 mlrun/api/utils/singletons/project_member.py
--rw-r--r--  2.0 unx     1063 b- defN 23-May-22 19:22 mlrun/api/utils/singletons/scheduler.py
--rw-r--r--  2.0 unx     1091 b- defN 23-May-22 19:22 mlrun/artifacts/__init__.py
--rw-r--r--  2.0 unx    30849 b- defN 23-May-22 19:22 mlrun/artifacts/base.py
--rw-r--r--  2.0 unx    20432 b- defN 23-May-22 19:22 mlrun/artifacts/dataset.py
--rw-r--r--  2.0 unx    12594 b- defN 23-May-22 19:22 mlrun/artifacts/manager.py
--rw-r--r--  2.0 unx    23673 b- defN 23-May-22 19:22 mlrun/artifacts/model.py
--rw-r--r--  2.0 unx    15383 b- defN 23-May-22 19:22 mlrun/artifacts/plots.py
--rw-r--r--  2.0 unx      571 b- defN 23-May-22 19:22 mlrun/common/__init__.py
--rw-r--r--  2.0 unx      660 b- defN 23-May-22 19:22 mlrun/common/constants.py
--rw-r--r--  2.0 unx     5670 b- defN 23-May-22 19:22 mlrun/common/model_monitoring.py
--rw-r--r--  2.0 unx      790 b- defN 23-May-22 19:22 mlrun/common/types.py
--rw-r--r--  2.0 unx     3973 b- defN 23-May-22 19:22 mlrun/common/schemas/__init__.py
--rw-r--r--  2.0 unx     1923 b- defN 23-May-22 19:22 mlrun/common/schemas/artifact.py
--rw-r--r--  2.0 unx     5251 b- defN 23-May-22 19:22 mlrun/common/schemas/auth.py
--rw-r--r--  2.0 unx     1553 b- defN 23-May-22 19:22 mlrun/common/schemas/background_task.py
--rw-r--r--  2.0 unx     2751 b- defN 23-May-22 19:22 mlrun/common/schemas/client_spec.py
--rw-r--r--  2.0 unx      888 b- defN 23-May-22 19:22 mlrun/common/schemas/clusterization_spec.py
--rw-r--r--  2.0 unx     6243 b- defN 23-May-22 19:22 mlrun/common/schemas/constants.py
--rw-r--r--  2.0 unx     3671 b- defN 23-May-22 19:22 mlrun/common/schemas/feature_store.py
--rw-r--r--  2.0 unx     2546 b- defN 23-May-22 19:22 mlrun/common/schemas/frontend_spec.py
--rw-r--r--  2.0 unx     3971 b- defN 23-May-22 19:22 mlrun/common/schemas/function.py
--rw-r--r--  2.0 unx      705 b- defN 23-May-22 19:22 mlrun/common/schemas/http.py
--rw-r--r--  2.0 unx     4245 b- defN 23-May-22 19:22 mlrun/common/schemas/hub.py
--rw-r--r--  2.0 unx     1395 b- defN 23-May-22 19:22 mlrun/common/schemas/k8s.py
--rw-r--r--  2.0 unx      920 b- defN 23-May-22 19:22 mlrun/common/schemas/memory_reports.py
--rw-r--r--  2.0 unx    12593 b- defN 23-May-22 19:22 mlrun/common/schemas/model_endpoints.py
--rw-r--r--  2.0 unx      879 b- defN 23-May-22 19:22 mlrun/common/schemas/notification.py
--rw-r--r--  2.0 unx     1907 b- defN 23-May-22 19:22 mlrun/common/schemas/object.py
--rw-r--r--  2.0 unx     1184 b- defN 23-May-22 19:22 mlrun/common/schemas/pipeline.py
--rw-r--r--  2.0 unx     4094 b- defN 23-May-22 19:22 mlrun/common/schemas/project.py
--rw-r--r--  2.0 unx     1636 b- defN 23-May-22 19:22 mlrun/common/schemas/runtime_resource.py
--rw-r--r--  2.0 unx     4188 b- defN 23-May-22 19:22 mlrun/common/schemas/schedule.py
--rw-r--r--  2.0 unx     1484 b- defN 23-May-22 19:22 mlrun/common/schemas/secret.py
--rw-r--r--  2.0 unx      905 b- defN 23-May-22 19:22 mlrun/common/schemas/tag.py
--rw-r--r--  2.0 unx     1087 b- defN 23-May-22 19:22 mlrun/data_types/__init__.py
--rw-r--r--  2.0 unx     4647 b- defN 23-May-22 19:22 mlrun/data_types/data_types.py
--rw-r--r--  2.0 unx     5813 b- defN 23-May-22 19:22 mlrun/data_types/infer.py
--rw-r--r--  2.0 unx     9426 b- defN 23-May-22 19:22 mlrun/data_types/spark.py
--rw-r--r--  2.0 unx     3443 b- defN 23-May-22 19:22 mlrun/datastore/__init__.py
--rw-r--r--  2.0 unx     6946 b- defN 23-May-22 19:22 mlrun/datastore/azure_blob.py
--rw-r--r--  2.0 unx    18274 b- defN 23-May-22 19:22 mlrun/datastore/base.py
--rw-r--r--  2.0 unx     7995 b- defN 23-May-22 19:22 mlrun/datastore/datastore.py
--rw-r--r--  2.0 unx     3791 b- defN 23-May-22 19:22 mlrun/datastore/filestore.py
--rw-r--r--  2.0 unx     5114 b- defN 23-May-22 19:22 mlrun/datastore/google_cloud_storage.py
--rw-r--r--  2.0 unx     2627 b- defN 23-May-22 19:22 mlrun/datastore/inmem.py
--rw-r--r--  2.0 unx     4873 b- defN 23-May-22 19:22 mlrun/datastore/redis.py
--rw-r--r--  2.0 unx     7035 b- defN 23-May-22 19:22 mlrun/datastore/s3.py
--rw-r--r--  2.0 unx    34280 b- defN 23-May-22 19:22 mlrun/datastore/sources.py
--rw-r--r--  2.0 unx     1410 b- defN 23-May-22 19:22 mlrun/datastore/spark_udf.py
--rw-r--r--  2.0 unx     6895 b- defN 23-May-22 19:22 mlrun/datastore/store_resources.py
--rw-r--r--  2.0 unx    62060 b- defN 23-May-22 19:22 mlrun/datastore/targets.py
--rw-r--r--  2.0 unx     2900 b- defN 23-May-22 19:22 mlrun/datastore/utils.py
--rw-r--r--  2.0 unx     8097 b- defN 23-May-22 19:22 mlrun/datastore/v3io.py
--rw-r--r--  2.0 unx     1343 b- defN 23-May-22 19:22 mlrun/datastore/wasbfs/__init__.py
--rw-r--r--  2.0 unx     6152 b- defN 23-May-22 19:22 mlrun/datastore/wasbfs/fs.py
--rw-r--r--  2.0 unx     2816 b- defN 23-May-22 19:22 mlrun/db/__init__.py
--rw-r--r--  2.0 unx    15968 b- defN 23-May-22 19:22 mlrun/db/base.py
--rw-r--r--  2.0 unx   130841 b- defN 23-May-22 19:22 mlrun/db/httpdb.py
--rw-r--r--  2.0 unx    13197 b- defN 23-May-22 19:22 mlrun/db/nopdb.py
--rw-r--r--  2.0 unx    25577 b- defN 23-May-22 19:22 mlrun/db/sqldb.py
--rw-r--r--  2.0 unx     1501 b- defN 23-May-22 19:22 mlrun/feature_store/__init__.py
--rw-r--r--  2.0 unx    43719 b- defN 23-May-22 19:22 mlrun/feature_store/api.py
--rw-r--r--  2.0 unx    12781 b- defN 23-May-22 19:22 mlrun/feature_store/common.py
--rw-r--r--  2.0 unx    47683 b- defN 23-May-22 19:22 mlrun/feature_store/feature_set.py
--rw-r--r--  2.0 unx    21940 b- defN 23-May-22 19:22 mlrun/feature_store/feature_vector.py
--rw-r--r--  2.0 unx    11681 b- defN 23-May-22 19:22 mlrun/feature_store/ingestion.py
--rw-r--r--  2.0 unx    28635 b- defN 23-May-22 19:22 mlrun/feature_store/steps.py
--rw-r--r--  2.0 unx     1232 b- defN 23-May-22 19:22 mlrun/feature_store/retrieval/__init__.py
--rw-r--r--  2.0 unx    25911 b- defN 23-May-22 19:22 mlrun/feature_store/retrieval/base.py
--rw-r--r--  2.0 unx     4261 b- defN 23-May-22 19:22 mlrun/feature_store/retrieval/dask_merger.py
--rw-r--r--  2.0 unx     7141 b- defN 23-May-22 19:22 mlrun/feature_store/retrieval/job.py
--rw-r--r--  2.0 unx     4765 b- defN 23-May-22 19:22 mlrun/feature_store/retrieval/local_merger.py
--rw-r--r--  2.0 unx     3352 b- defN 23-May-22 19:22 mlrun/feature_store/retrieval/online.py
--rw-r--r--  2.0 unx     9661 b- defN 23-May-22 19:22 mlrun/feature_store/retrieval/spark_merger.py
--rw-r--r--  2.0 unx      743 b- defN 23-May-22 19:22 mlrun/frameworks/__init__.py
--rw-r--r--  2.0 unx    11466 b- defN 23-May-22 19:22 mlrun/frameworks/parallel_coordinates.py
--rw-r--r--  2.0 unx      962 b- defN 23-May-22 19:22 mlrun/frameworks/_common/__init__.py
--rw-r--r--  2.0 unx     8515 b- defN 23-May-22 19:22 mlrun/frameworks/_common/artifacts_library.py
--rw-r--r--  2.0 unx    21018 b- defN 23-May-22 19:22 mlrun/frameworks/_common/mlrun_interface.py
--rw-r--r--  2.0 unx    55376 b- defN 23-May-22 19:22 mlrun/frameworks/_common/model_handler.py
--rw-r--r--  2.0 unx     3469 b- defN 23-May-22 19:22 mlrun/frameworks/_common/plan.py
--rw-r--r--  2.0 unx     5757 b- defN 23-May-22 19:22 mlrun/frameworks/_common/producer.py
--rw-r--r--  2.0 unx     9209 b- defN 23-May-22 19:22 mlrun/frameworks/_common/utils.py
--rw-r--r--  2.0 unx      750 b- defN 23-May-22 19:22 mlrun/frameworks/_dl_common/__init__.py
--rw-r--r--  2.0 unx     1151 b- defN 23-May-22 19:22 mlrun/frameworks/_dl_common/model_handler.py
--rw-r--r--  2.0 unx      996 b- defN 23-May-22 19:22 mlrun/frameworks/_dl_common/utils.py
--rw-r--r--  2.0 unx      787 b- defN 23-May-22 19:22 mlrun/frameworks/_dl_common/loggers/__init__.py
--rw-r--r--  2.0 unx    11531 b- defN 23-May-22 19:22 mlrun/frameworks/_dl_common/loggers/logger.py
--rw-r--r--  2.0 unx    14777 b- defN 23-May-22 19:22 mlrun/frameworks/_dl_common/loggers/mlrun_logger.py
--rw-r--r--  2.0 unx    28414 b- defN 23-May-22 19:22 mlrun/frameworks/_dl_common/loggers/tensorboard_logger.py
--rw-r--r--  2.0 unx      956 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/__init__.py
--rw-r--r--  2.0 unx     3169 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/artifacts_library.py
--rw-r--r--  2.0 unx    16957 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/model_handler.py
--rw-r--r--  2.0 unx     2368 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/pkl_model_server.py
--rw-r--r--  2.0 unx     4881 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/plan.py
--rw-r--r--  2.0 unx     4061 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/producer.py
--rw-r--r--  2.0 unx    10490 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/utils.py
--rw-r--r--  2.0 unx      737 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/loggers/__init__.py
--rw-r--r--  2.0 unx     5684 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/loggers/logger.py
--rw-r--r--  2.0 unx     6453 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/loggers/mlrun_logger.py
--rw-r--r--  2.0 unx      922 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/plans/__init__.py
--rw-r--r--  2.0 unx     5212 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/plans/calibration_curve_plan.py
--rw-r--r--  2.0 unx     6078 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/plans/confusion_matrix_plan.py
--rw-r--r--  2.0 unx     6658 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/plans/dataset_plan.py
--rw-r--r--  2.0 unx     5318 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/plans/feature_importance_plan.py
--rw-r--r--  2.0 unx     6993 b- defN 23-May-22 19:22 mlrun/frameworks/_ml_common/plans/roc_curve_plan.py
--rw-r--r--  2.0 unx      706 b- defN 23-May-22 19:22 mlrun/frameworks/auto_mlrun/__init__.py
--rw-r--r--  2.0 unx    23796 b- defN 23-May-22 19:22 mlrun/frameworks/auto_mlrun/auto_mlrun.py
--rw-r--r--  2.0 unx      721 b- defN 23-May-22 19:22 mlrun/frameworks/huggingface/__init__.py
--rw-r--r--  2.0 unx     6083 b- defN 23-May-22 19:22 mlrun/frameworks/huggingface/model_server.py
--rw-r--r--  2.0 unx    15883 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/__init__.py
--rw-r--r--  2.0 unx    13891 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/model_handler.py
--rw-r--r--  2.0 unx     9189 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/model_server.py
--rw-r--r--  2.0 unx     8278 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/utils.py
--rw-r--r--  2.0 unx      857 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/callbacks/__init__.py
--rw-r--r--  2.0 unx     4081 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/callbacks/callback.py
--rw-r--r--  2.0 unx     5156 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/callbacks/logging_callback.py
--rw-r--r--  2.0 unx     4137 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/callbacks/mlrun_logging_callback.py
--rw-r--r--  2.0 unx      842 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/mlrun_interfaces/__init__.py
--rw-r--r--  2.0 unx     1624 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/mlrun_interfaces/booster_mlrun_interface.py
--rw-r--r--  2.0 unx    14256 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/mlrun_interfaces/mlrun_interface.py
--rw-r--r--  2.0 unx     1333 b- defN 23-May-22 19:22 mlrun/frameworks/lgbm/mlrun_interfaces/model_mlrun_interface.py
--rw-r--r--  2.0 unx      791 b- defN 23-May-22 19:22 mlrun/frameworks/onnx/__init__.py
--rw-r--r--  2.0 unx     6098 b- defN 23-May-22 19:22 mlrun/frameworks/onnx/dataset.py
--rw-r--r--  2.0 unx     2405 b- defN 23-May-22 19:22 mlrun/frameworks/onnx/mlrun_interface.py
--rw-r--r--  2.0 unx     6203 b- defN 23-May-22 19:22 mlrun/frameworks/onnx/model_handler.py
--rw-r--r--  2.0 unx     7061 b- defN 23-May-22 19:22 mlrun/frameworks/onnx/model_server.py
--rw-r--r--  2.0 unx    22056 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/__init__.py
--rw-r--r--  2.0 unx    27904 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/callbacks_handler.py
--rw-r--r--  2.0 unx    44639 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/mlrun_interface.py
--rw-r--r--  2.0 unx    22465 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/model_handler.py
--rw-r--r--  2.0 unx    10136 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/model_server.py
--rw-r--r--  2.0 unx     4515 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/utils.py
--rw-r--r--  2.0 unx      896 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/callbacks/__init__.py
--rw-r--r--  2.0 unx    11524 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/callbacks/callback.py
--rw-r--r--  2.0 unx    23166 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/callbacks/logging_callback.py
--rw-r--r--  2.0 unx     9310 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/callbacks/mlrun_logging_callback.py
--rw-r--r--  2.0 unx    26661 b- defN 23-May-22 19:22 mlrun/frameworks/pytorch/callbacks/tensorboard_logging_callback.py
--rw-r--r--  2.0 unx    10892 b- defN 23-May-22 19:22 mlrun/frameworks/sklearn/__init__.py
--rw-r--r--  2.0 unx     5852 b- defN 23-May-22 19:22 mlrun/frameworks/sklearn/estimator.py
--rw-r--r--  2.0 unx     7117 b- defN 23-May-22 19:22 mlrun/frameworks/sklearn/metric.py
--rw-r--r--  2.0 unx    12215 b- defN 23-May-22 19:22 mlrun/frameworks/sklearn/metrics_library.py
--rw-r--r--  2.0 unx    14126 b- defN 23-May-22 19:22 mlrun/frameworks/sklearn/mlrun_interface.py
--rw-r--r--  2.0 unx     4745 b- defN 23-May-22 19:22 mlrun/frameworks/sklearn/model_handler.py
--rw-r--r--  2.0 unx     1209 b- defN 23-May-22 19:22 mlrun/frameworks/sklearn/utils.py
--rw-r--r--  2.0 unx    10455 b- defN 23-May-22 19:22 mlrun/frameworks/tf_keras/__init__.py
--rw-r--r--  2.0 unx    16627 b- defN 23-May-22 19:22 mlrun/frameworks/tf_keras/mlrun_interface.py
--rw-r--r--  2.0 unx    28247 b- defN 23-May-22 19:22 mlrun/frameworks/tf_keras/model_handler.py
--rw-r--r--  2.0 unx     9565 b- defN 23-May-22 19:22 mlrun/frameworks/tf_keras/model_server.py
--rw-r--r--  2.0 unx     4284 b- defN 23-May-22 19:22 mlrun/frameworks/tf_keras/utils.py
--rw-r--r--  2.0 unx      844 b- defN 23-May-22 19:22 mlrun/frameworks/tf_keras/callbacks/__init__.py
--rw-r--r--  2.0 unx    21886 b- defN 23-May-22 19:22 mlrun/frameworks/tf_keras/callbacks/logging_callback.py
--rw-r--r--  2.0 unx     8791 b- defN 23-May-22 19:22 mlrun/frameworks/tf_keras/callbacks/mlrun_logging_callback.py
--rw-r--r--  2.0 unx    28728 b- defN 23-May-22 19:22 mlrun/frameworks/tf_keras/callbacks/tensorboard_logging_callback.py
--rw-r--r--  2.0 unx    10287 b- defN 23-May-22 19:22 mlrun/frameworks/xgboost/__init__.py
--rw-r--r--  2.0 unx      878 b- defN 23-May-22 19:22 mlrun/frameworks/xgboost/mlrun_interface.py
--rw-r--r--  2.0 unx    11617 b- defN 23-May-22 19:22 mlrun/frameworks/xgboost/model_handler.py
--rw-r--r--  2.0 unx     1069 b- defN 23-May-22 19:22 mlrun/frameworks/xgboost/utils.py
--rw-r--r--  2.0 unx      577 b- defN 23-May-22 19:22 mlrun/launcher/__init__.py
--rw-r--r--  2.0 unx    14925 b- defN 23-May-22 19:22 mlrun/launcher/base.py
--rw-r--r--  2.0 unx     6164 b- defN 23-May-22 19:22 mlrun/launcher/client.py
--rw-r--r--  2.0 unx     1883 b- defN 23-May-22 19:22 mlrun/launcher/factory.py
--rw-r--r--  2.0 unx    10378 b- defN 23-May-22 19:22 mlrun/launcher/local.py
--rw-r--r--  2.0 unx     6742 b- defN 23-May-22 19:22 mlrun/launcher/remote.py
--rw-r--r--  2.0 unx      760 b- defN 23-May-22 19:22 mlrun/mlutils/__init__.py
--rw-r--r--  2.0 unx     5325 b- defN 23-May-22 19:22 mlrun/mlutils/data.py
--rw-r--r--  2.0 unx     2598 b- defN 23-May-22 19:22 mlrun/mlutils/models.py
--rw-r--r--  2.0 unx    30120 b- defN 23-May-22 19:22 mlrun/mlutils/plots.py
--rw-r--r--  2.0 unx     1208 b- defN 23-May-22 19:22 mlrun/model_monitoring/__init__.py
--rw-r--r--  2.0 unx    23948 b- defN 23-May-22 19:22 mlrun/model_monitoring/features_drift_table.py
--rw-r--r--  2.0 unx     9756 b- defN 23-May-22 19:22 mlrun/model_monitoring/helpers.py
--rw-r--r--  2.0 unx     5196 b- defN 23-May-22 19:22 mlrun/model_monitoring/model_endpoint.py
--rw-r--r--  2.0 unx    36885 b- defN 23-May-22 19:22 mlrun/model_monitoring/model_monitoring_batch.py
--rw-r--r--  2.0 unx    43172 b- defN 23-May-22 19:22 mlrun/model_monitoring/stream_processing_fs.py
--rw-r--r--  2.0 unx     4240 b- defN 23-May-22 19:22 mlrun/model_monitoring/stores/__init__.py
--rw-r--r--  2.0 unx    17357 b- defN 23-May-22 19:22 mlrun/model_monitoring/stores/kv_model_endpoint_store.py
--rw-r--r--  2.0 unx     5695 b- defN 23-May-22 19:22 mlrun/model_monitoring/stores/model_endpoint_store.py
--rw-r--r--  2.0 unx    15706 b- defN 23-May-22 19:22 mlrun/model_monitoring/stores/sql_model_endpoint_store.py
--rw-r--r--  2.0 unx      884 b- defN 23-May-22 19:22 mlrun/model_monitoring/stores/models/__init__.py
--rw-r--r--  2.0 unx      655 b- defN 23-May-22 19:22 mlrun/model_monitoring/stores/models/base.py
--rw-r--r--  2.0 unx     3741 b- defN 23-May-22 19:22 mlrun/model_monitoring/stores/models/mysql.py
--rw-r--r--  2.0 unx     3658 b- defN 23-May-22 19:22 mlrun/model_monitoring/stores/models/sqlite.py
--rw-r--r--  2.0 unx     2400 b- defN 23-May-22 19:22 mlrun/platforms/__init__.py
--rw-r--r--  2.0 unx    23997 b- defN 23-May-22 19:22 mlrun/platforms/iguazio.py
--rw-r--r--  2.0 unx    11852 b- defN 23-May-22 19:22 mlrun/platforms/other.py
--rw-r--r--  2.0 unx     1153 b- defN 23-May-22 19:22 mlrun/projects/__init__.py
--rw-r--r--  2.0 unx    17480 b- defN 23-May-22 19:22 mlrun/projects/operations.py
--rw-r--r--  2.0 unx    38343 b- defN 23-May-22 19:22 mlrun/projects/pipelines.py
--rw-r--r--  2.0 unx   111849 b- defN 23-May-22 19:22 mlrun/projects/project.py
--rw-r--r--  2.0 unx     8773 b- defN 23-May-22 19:22 mlrun/runtimes/__init__.py
--rw-r--r--  2.0 unx    86765 b- defN 23-May-22 19:22 mlrun/runtimes/base.py
--rw-r--r--  2.0 unx     6689 b- defN 23-May-22 19:22 mlrun/runtimes/constants.py
--rw-r--r--  2.0 unx    30353 b- defN 23-May-22 19:22 mlrun/runtimes/daskjob.py
--rw-r--r--  2.0 unx     9561 b- defN 23-May-22 19:22 mlrun/runtimes/funcdoc.py
--rw-r--r--  2.0 unx    45205 b- defN 23-May-22 19:22 mlrun/runtimes/function.py
--rw-r--r--  2.0 unx     4911 b- defN 23-May-22 19:22 mlrun/runtimes/function_reference.py
--rw-r--r--  2.0 unx     6530 b- defN 23-May-22 19:22 mlrun/runtimes/generators.py
--rw-r--r--  2.0 unx    15318 b- defN 23-May-22 19:22 mlrun/runtimes/kubejob.py
--rw-r--r--  2.0 unx    19158 b- defN 23-May-22 19:22 mlrun/runtimes/local.py
--rw-r--r--  2.0 unx     2885 b- defN 23-May-22 19:22 mlrun/runtimes/nuclio.py
--rw-r--r--  2.0 unx    60808 b- defN 23-May-22 19:22 mlrun/runtimes/pod.py
--rw-r--r--  2.0 unx     7695 b- defN 23-May-22 19:22 mlrun/runtimes/remotesparkjob.py
--rw-r--r--  2.0 unx    29858 b- defN 23-May-22 19:22 mlrun/runtimes/serving.py
--rw-r--r--  2.0 unx    21048 b- defN 23-May-22 19:22 mlrun/runtimes/utils.py
--rw-r--r--  2.0 unx      790 b- defN 23-May-22 19:22 mlrun/runtimes/mpijob/__init__.py
--rw-r--r--  2.0 unx    14713 b- defN 23-May-22 19:22 mlrun/runtimes/mpijob/abstract.py
--rw-r--r--  2.0 unx    13845 b- defN 23-May-22 19:22 mlrun/runtimes/mpijob/v1.py
--rw-r--r--  2.0 unx     8460 b- defN 23-May-22 19:22 mlrun/runtimes/mpijob/v1alpha1.py
--rw-r--r--  2.0 unx      673 b- defN 23-May-22 19:22 mlrun/runtimes/package/__init__.py
--rw-r--r--  2.0 unx    27068 b- defN 23-May-22 19:22 mlrun/runtimes/package/context_handler.py
--rw-r--r--  2.0 unx      751 b- defN 23-May-22 19:22 mlrun/runtimes/sparkjob/__init__.py
--rw-r--r--  2.0 unx    35028 b- defN 23-May-22 19:22 mlrun/runtimes/sparkjob/abstract.py
--rw-r--r--  2.0 unx    28746 b- defN 23-May-22 19:22 mlrun/runtimes/sparkjob/spark3job.py
--rw-r--r--  2.0 unx     1078 b- defN 23-May-22 19:22 mlrun/serving/__init__.py
--rw-r--r--  2.0 unx     6116 b- defN 23-May-22 19:22 mlrun/serving/merger.py
--rw-r--r--  2.0 unx    18038 b- defN 23-May-22 19:22 mlrun/serving/remote.py
--rw-r--r--  2.0 unx    55277 b- defN 23-May-22 19:22 mlrun/serving/routers.py
--rw-r--r--  2.0 unx    20247 b- defN 23-May-22 19:22 mlrun/serving/server.py
--rw-r--r--  2.0 unx      836 b- defN 23-May-22 19:22 mlrun/serving/serving_wrapper.py
--rw-r--r--  2.0 unx    54169 b- defN 23-May-22 19:22 mlrun/serving/states.py
--rw-r--r--  2.0 unx     3902 b- defN 23-May-22 19:22 mlrun/serving/utils.py
--rw-r--r--  2.0 unx    11814 b- defN 23-May-22 19:22 mlrun/serving/v1_serving.py
--rw-r--r--  2.0 unx    21460 b- defN 23-May-22 19:22 mlrun/serving/v2_serving.py
--rw-r--r--  2.0 unx      826 b- defN 23-May-22 19:22 mlrun/utils/__init__.py
--rw-r--r--  2.0 unx    10397 b- defN 23-May-22 19:22 mlrun/utils/async_http.py
--rw-r--r--  2.0 unx     3456 b- defN 23-May-22 19:22 mlrun/utils/azure_vault.py
--rw-r--r--  2.0 unx     6245 b- defN 23-May-22 19:22 mlrun/utils/clones.py
--rw-r--r--  2.0 unx     1662 b- defN 23-May-22 19:22 mlrun/utils/db.py
--rw-r--r--  2.0 unx    43609 b- defN 23-May-22 19:22 mlrun/utils/helpers.py
--rw-r--r--  2.0 unx     7093 b- defN 23-May-22 19:22 mlrun/utils/http.py
--rw-r--r--  2.0 unx     7035 b- defN 23-May-22 19:22 mlrun/utils/logger.py
--rw-r--r--  2.0 unx     9969 b- defN 23-May-22 19:22 mlrun/utils/model_monitoring.py
--rw-r--r--  2.0 unx     3954 b- defN 23-May-22 19:22 mlrun/utils/regex.py
--rw-r--r--  2.0 unx      883 b- defN 23-May-22 19:22 mlrun/utils/singleton.py
--rw-r--r--  2.0 unx     1319 b- defN 23-May-22 19:22 mlrun/utils/v3io_clients.py
--rw-r--r--  2.0 unx    10447 b- defN 23-May-22 19:22 mlrun/utils/vault.py
--rw-r--r--  2.0 unx      990 b- defN 23-May-22 19:22 mlrun/utils/notifications/__init__.py
--rw-r--r--  2.0 unx    12462 b- defN 23-May-22 19:22 mlrun/utils/notifications/notification_pusher.py
--rw-r--r--  2.0 unx     1803 b- defN 23-May-22 19:22 mlrun/utils/notifications/notification/__init__.py
--rw-r--r--  2.0 unx     2177 b- defN 23-May-22 19:22 mlrun/utils/notifications/notification/base.py
--rw-r--r--  2.0 unx     1971 b- defN 23-May-22 19:22 mlrun/utils/notifications/notification/console.py
--rw-r--r--  2.0 unx     4722 b- defN 23-May-22 19:22 mlrun/utils/notifications/notification/git.py
--rw-r--r--  2.0 unx     2021 b- defN 23-May-22 19:22 mlrun/utils/notifications/notification/ipython.py
--rw-r--r--  2.0 unx     3751 b- defN 23-May-22 19:22 mlrun/utils/notifications/notification/slack.py
--rw-r--r--  2.0 unx      614 b- defN 23-May-22 19:22 mlrun/utils/version/__init__.py
--rw-r--r--  2.0 unx       88 b- defN 23-May-22 19:22 mlrun/utils/version/version.json
--rw-r--r--  2.0 unx     1970 b- defN 23-May-22 19:22 mlrun/utils/version/version.py
--rw-r--r--  2.0 unx    11357 b- defN 23-May-22 19:22 mlrun-1.4.0rc7.dist-info/LICENSE
--rw-r--r--  2.0 unx    16892 b- defN 23-May-22 19:22 mlrun-1.4.0rc7.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-22 19:22 mlrun-1.4.0rc7.dist-info/WHEEL
--rw-r--r--  2.0 unx       47 b- defN 23-May-22 19:22 mlrun-1.4.0rc7.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        6 b- defN 23-May-22 19:22 mlrun-1.4.0rc7.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    38488 b- defN 23-May-22 19:22 mlrun-1.4.0rc7.dist-info/RECORD
-410 files, 4443871 bytes uncompressed, 1130800 bytes compressed:  74.6%
+Zip file size: 1193777 bytes, number of entries: 410
+-rw-r--r--  2.0 unx     8727 b- defN 23-May-30 08:22 mlrun/__init__.py
+-rw-r--r--  2.0 unx    49342 b- defN 23-May-30 08:22 mlrun/__main__.py
+-rw-r--r--  2.0 unx    55437 b- defN 23-May-30 08:22 mlrun/config.py
+-rw-r--r--  2.0 unx     6780 b- defN 23-May-30 08:22 mlrun/errors.py
+-rw-r--r--  2.0 unx    39096 b- defN 23-May-30 08:22 mlrun/execution.py
+-rw-r--r--  2.0 unx    15624 b- defN 23-May-30 08:22 mlrun/features.py
+-rw-r--r--  2.0 unx     4876 b- defN 23-May-30 08:22 mlrun/k8s_utils.py
+-rw-r--r--  2.0 unx    29646 b- defN 23-May-30 08:22 mlrun/kfpops.py
+-rw-r--r--  2.0 unx     8360 b- defN 23-May-30 08:22 mlrun/lists.py
+-rw-r--r--  2.0 unx    58708 b- defN 23-May-30 08:22 mlrun/model.py
+-rw-r--r--  2.0 unx    11828 b- defN 23-May-30 08:22 mlrun/render.py
+-rw-r--r--  2.0 unx    64773 b- defN 23-May-30 08:22 mlrun/run.py
+-rw-r--r--  2.0 unx     7783 b- defN 23-May-30 08:22 mlrun/secrets.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/__init__.py
+-rw-r--r--  2.0 unx     2105 b- defN 23-May-30 08:22 mlrun/api/alembic.ini
+-rw-r--r--  2.0 unx      685 b- defN 23-May-30 08:22 mlrun/api/constants.py
+-rw-r--r--  2.0 unx    25653 b- defN 23-May-30 08:22 mlrun/api/initial_data.py
+-rw-r--r--  2.0 unx     7575 b- defN 23-May-30 08:22 mlrun/api/launcher.py
+-rw-r--r--  2.0 unx    26457 b- defN 23-May-30 08:22 mlrun/api/main.py
+-rw-r--r--  2.0 unx     5247 b- defN 23-May-30 08:22 mlrun/api/middlewares.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/api/__init__.py
+-rw-r--r--  2.0 unx     4243 b- defN 23-May-30 08:22 mlrun/api/api/api.py
+-rw-r--r--  2.0 unx     3197 b- defN 23-May-30 08:22 mlrun/api/api/deps.py
+-rw-r--r--  2.0 unx    36613 b- defN 23-May-30 08:22 mlrun/api/api/utils.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/__init__.py
+-rw-r--r--  2.0 unx    10452 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/artifacts.py
+-rw-r--r--  2.0 unx     1199 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/auth.py
+-rw-r--r--  2.0 unx     3618 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/background_tasks.py
+-rw-r--r--  2.0 unx     1214 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/client_spec.py
+-rw-r--r--  2.0 unx     1175 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/clusterization_spec.py
+-rw-r--r--  2.0 unx    29192 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/feature_store.py
+-rw-r--r--  2.0 unx     6104 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/files.py
+-rw-r--r--  2.0 unx     5468 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/frontend_spec.py
+-rw-r--r--  2.0 unx    35186 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/functions.py
+-rw-r--r--  2.0 unx     5935 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/grafana_proxy.py
+-rw-r--r--  2.0 unx     1344 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/healthz.py
+-rw-r--r--  2.0 unx    10312 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/hub.py
+-rw-r--r--  2.0 unx     2445 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/logs.py
+-rw-r--r--  2.0 unx    15651 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/model_endpoints.py
+-rw-r--r--  2.0 unx     3756 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/operations.py
+-rw-r--r--  2.0 unx     9165 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/pipelines.py
+-rw-r--r--  2.0 unx    11494 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/projects.py
+-rw-r--r--  2.0 unx     9078 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/runs.py
+-rw-r--r--  2.0 unx     9035 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/runtime_resources.py
+-rw-r--r--  2.0 unx    10554 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/schedules.py
+-rw-r--r--  2.0 unx     6061 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/secrets.py
+-rw-r--r--  2.0 unx     5298 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/submit.py
+-rw-r--r--  2.0 unx     4849 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/tags.py
+-rw-r--r--  2.0 unx     1203 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/internal/__init__.py
+-rw-r--r--  2.0 unx     1043 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/internal/config.py
+-rw-r--r--  2.0 unx     1718 b- defN 23-May-30 08:22 mlrun/api/api/endpoints/internal/memory_reports.py
+-rw-r--r--  2.0 unx     1209 b- defN 23-May-30 08:22 mlrun/api/crud/__init__.py
+-rw-r--r--  2.0 unx     5610 b- defN 23-May-30 08:22 mlrun/api/crud/artifacts.py
+-rw-r--r--  2.0 unx     7331 b- defN 23-May-30 08:22 mlrun/api/crud/client_spec.py
+-rw-r--r--  2.0 unx     1055 b- defN 23-May-30 08:22 mlrun/api/crud/clusterization_spec.py
+-rw-r--r--  2.0 unx    18628 b- defN 23-May-30 08:22 mlrun/api/crud/feature_store.py
+-rw-r--r--  2.0 unx     3556 b- defN 23-May-30 08:22 mlrun/api/crud/functions.py
+-rw-r--r--  2.0 unx    12025 b- defN 23-May-30 08:22 mlrun/api/crud/hub.py
+-rw-r--r--  2.0 unx     9409 b- defN 23-May-30 08:22 mlrun/api/crud/logs.py
+-rw-r--r--  2.0 unx     2751 b- defN 23-May-30 08:22 mlrun/api/crud/notifications.py
+-rw-r--r--  2.0 unx    14090 b- defN 23-May-30 08:22 mlrun/api/crud/pipelines.py
+-rw-r--r--  2.0 unx    14269 b- defN 23-May-30 08:22 mlrun/api/crud/projects.py
+-rw-r--r--  2.0 unx     5963 b- defN 23-May-30 08:22 mlrun/api/crud/runs.py
+-rw-r--r--  2.0 unx     5575 b- defN 23-May-30 08:22 mlrun/api/crud/runtime_resources.py
+-rw-r--r--  2.0 unx    20145 b- defN 23-May-30 08:22 mlrun/api/crud/secrets.py
+-rw-r--r--  2.0 unx     3277 b- defN 23-May-30 08:22 mlrun/api/crud/tags.py
+-rw-r--r--  2.0 unx      722 b- defN 23-May-30 08:22 mlrun/api/crud/model_monitoring/__init__.py
+-rw-r--r--  2.0 unx    15692 b- defN 23-May-30 08:22 mlrun/api/crud/model_monitoring/grafana.py
+-rw-r--r--  2.0 unx    43000 b- defN 23-May-30 08:22 mlrun/api/crud/model_monitoring/model_endpoints.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/crud/runtimes/__init__.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/crud/runtimes/nuclio/__init__.py
+-rw-r--r--  2.0 unx    18574 b- defN 23-May-30 08:22 mlrun/api/crud/runtimes/nuclio/function.py
+-rw-r--r--  2.0 unx    11398 b- defN 23-May-30 08:22 mlrun/api/crud/runtimes/nuclio/helpers.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/db/__init__.py
+-rw-r--r--  2.0 unx    15056 b- defN 23-May-30 08:22 mlrun/api/db/base.py
+-rw-r--r--  2.0 unx      816 b- defN 23-May-30 08:22 mlrun/api/db/init_db.py
+-rw-r--r--  2.0 unx      993 b- defN 23-May-30 08:22 mlrun/api/db/session.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/db/sqldb/__init__.py
+-rw-r--r--  2.0 unx   145830 b- defN 23-May-30 08:22 mlrun/api/db/sqldb/db.py
+-rw-r--r--  2.0 unx     2340 b- defN 23-May-30 08:22 mlrun/api/db/sqldb/helpers.py
+-rw-r--r--  2.0 unx     2542 b- defN 23-May-30 08:22 mlrun/api/db/sqldb/session.py
+-rw-r--r--  2.0 unx     1063 b- defN 23-May-30 08:22 mlrun/api/db/sqldb/models/__init__.py
+-rw-r--r--  2.0 unx    20642 b- defN 23-May-30 08:22 mlrun/api/db/sqldb/models/models_mysql.py
+-rw-r--r--  2.0 unx    18304 b- defN 23-May-30 08:22 mlrun/api/db/sqldb/models/models_sqlite.py
+-rw-r--r--  2.0 unx     2906 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/env.py
+-rw-r--r--  2.0 unx     1203 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/28383af526f3_market_place_to_hub.py
+-rw-r--r--  2.0 unx     4614 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/32bae1b0e29c_increase_timestamp_fields_precision.py
+-rw-r--r--  2.0 unx     1936 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/4903aef6a91d_tag_foreign_key_and_cascades.py
+-rw-r--r--  2.0 unx     1909 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/5f1351c88a19_adding_background_tasks_table.py
+-rw-r--r--  2.0 unx     1415 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/88e656800d6a_add_requested_logs_column_and_index_to_.py
+-rw-r--r--  2.0 unx     1504 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/9d16de5f03a7_adding_data_versions_table.py
+-rw-r--r--  2.0 unx     1649 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/b86f5b53f3d7_adding_name_and_updated_to_runs_table.py
+-rw-r--r--  2.0 unx    24057 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/c4af40b0bf61_init.py
+-rw-r--r--  2.0 unx     2457 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/c905d15bd91d_notifications.py
+-rw-r--r--  2.0 unx     1351 b- defN 23-May-30 08:22 mlrun/api/migrations_mysql/versions/ee041e8fdaa0_adding_next_run_time_column_to_schedule_.py
+-rw-r--r--  2.0 unx     2906 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/env.py
+-rw-r--r--  2.0 unx    11473 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/11f8dd2dc9fe_init.py
+-rw-r--r--  2.0 unx     1348 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/1c954f8cb32d_schedule_last_run_uri.py
+-rw-r--r--  2.0 unx     5180 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/2b6d23c715aa_adding_feature_sets.py
+-rw-r--r--  2.0 unx     2595 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/4acd9430b093_market_place_to_hub.py
+-rw-r--r--  2.0 unx     1388 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/6401142f2d7c_adding_next_run_time_column_to_schedule_.py
+-rw-r--r--  2.0 unx     1767 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/64d90a1a69bc_adding_background_tasks_table.py
+-rw-r--r--  2.0 unx     1360 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/803438ecd005_add_requested_logs_column_to_runs.py
+-rw-r--r--  2.0 unx     1259 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/863114f0c659_refactoring_feature_set.py
+-rw-r--r--  2.0 unx     2147 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/959ae00528ad_notifications.py
+-rw-r--r--  2.0 unx     1482 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/accf9fc83d38_adding_data_versions_table.py
+-rw-r--r--  2.0 unx     1892 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/b68e8e897a28_schedule_labels.py
+-rw-r--r--  2.0 unx     1882 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/bcd0c1f9720c_adding_project_labels.py
+-rw-r--r--  2.0 unx     1420 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/cf21882f938e_schedule_id.py
+-rw-r--r--  2.0 unx     2034 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/d781f58f607f_tag_object_name_string.py
+-rw-r--r--  2.0 unx     1828 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/deac06871ace_adding_marketplace_sources_table.py
+-rw-r--r--  2.0 unx     1380 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/e1dd5983c06b_schedule_concurrency_limit.py
+-rw-r--r--  2.0 unx     1831 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/e5594ed3ab53_adding_name_and_updated_to_runs_table.py
+-rw-r--r--  2.0 unx     3936 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/f4249b4ba6fa_adding_feature_vectors.py
+-rw-r--r--  2.0 unx     2588 b- defN 23-May-30 08:22 mlrun/api/migrations_sqlite/versions/f7b5a1a03629_adding_feature_labels.py
+-rw-r--r--  2.0 unx    13338 b- defN 23-May-30 08:22 mlrun/api/schemas/__init__.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/utils/__init__.py
+-rw-r--r--  2.0 unx     1092 b- defN 23-May-30 08:22 mlrun/api/utils/asyncio.py
+-rw-r--r--  2.0 unx     7371 b- defN 23-May-30 08:22 mlrun/api/utils/background_tasks.py
+-rw-r--r--  2.0 unx    25794 b- defN 23-May-30 08:22 mlrun/api/utils/builder.py
+-rw-r--r--  2.0 unx     2431 b- defN 23-May-30 08:22 mlrun/api/utils/helpers.py
+-rw-r--r--  2.0 unx     3728 b- defN 23-May-30 08:22 mlrun/api/utils/memory_reports.py
+-rw-r--r--  2.0 unx     2599 b- defN 23-May-30 08:22 mlrun/api/utils/periodic.py
+-rw-r--r--  2.0 unx    39305 b- defN 23-May-30 08:22 mlrun/api/utils/scheduler.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/utils/auth/__init__.py
+-rw-r--r--  2.0 unx    12383 b- defN 23-May-30 08:22 mlrun/api/utils/auth/verifier.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/utils/auth/providers/__init__.py
+-rw-r--r--  2.0 unx     1381 b- defN 23-May-30 08:22 mlrun/api/utils/auth/providers/base.py
+-rw-r--r--  2.0 unx     1460 b- defN 23-May-30 08:22 mlrun/api/utils/auth/providers/nop.py
+-rw-r--r--  2.0 unx    10883 b- defN 23-May-30 08:22 mlrun/api/utils/auth/providers/opa.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/utils/clients/__init__.py
+-rw-r--r--  2.0 unx    13271 b- defN 23-May-30 08:22 mlrun/api/utils/clients/chief.py
+-rw-r--r--  2.0 unx    31249 b- defN 23-May-30 08:22 mlrun/api/utils/clients/iguazio.py
+-rw-r--r--  2.0 unx    12281 b- defN 23-May-30 08:22 mlrun/api/utils/clients/log_collector.py
+-rw-r--r--  2.0 unx     9916 b- defN 23-May-30 08:22 mlrun/api/utils/clients/nuclio.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/utils/clients/protocols/__init__.py
+-rw-r--r--  2.0 unx     2567 b- defN 23-May-30 08:22 mlrun/api/utils/clients/protocols/grpc.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/utils/db/__init__.py
+-rw-r--r--  2.0 unx     3305 b- defN 23-May-30 08:22 mlrun/api/utils/db/alembic.py
+-rw-r--r--  2.0 unx     8214 b- defN 23-May-30 08:22 mlrun/api/utils/db/backup.py
+-rw-r--r--  2.0 unx     3787 b- defN 23-May-30 08:22 mlrun/api/utils/db/mysql.py
+-rw-r--r--  2.0 unx      992 b- defN 23-May-30 08:22 mlrun/api/utils/db/sql_collation.py
+-rw-r--r--  2.0 unx     3861 b- defN 23-May-30 08:22 mlrun/api/utils/db/sqlite_migration.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/utils/projects/__init__.py
+-rw-r--r--  2.0 unx    17423 b- defN 23-May-30 08:22 mlrun/api/utils/projects/follower.py
+-rw-r--r--  2.0 unx    19372 b- defN 23-May-30 08:22 mlrun/api/utils/projects/leader.py
+-rw-r--r--  2.0 unx     7133 b- defN 23-May-30 08:22 mlrun/api/utils/projects/member.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/utils/projects/remotes/__init__.py
+-rw-r--r--  2.0 unx     2659 b- defN 23-May-30 08:22 mlrun/api/utils/projects/remotes/follower.py
+-rw-r--r--  2.0 unx     2094 b- defN 23-May-30 08:22 mlrun/api/utils/projects/remotes/leader.py
+-rw-r--r--  2.0 unx     5000 b- defN 23-May-30 08:22 mlrun/api/utils/projects/remotes/nop_follower.py
+-rw-r--r--  2.0 unx     3861 b- defN 23-May-30 08:22 mlrun/api/utils/projects/remotes/nop_leader.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/api/utils/singletons/__init__.py
+-rw-r--r--  2.0 unx     1202 b- defN 23-May-30 08:22 mlrun/api/utils/singletons/db.py
+-rw-r--r--  2.0 unx    22651 b- defN 23-May-30 08:22 mlrun/api/utils/singletons/k8s.py
+-rw-r--r--  2.0 unx      840 b- defN 23-May-30 08:22 mlrun/api/utils/singletons/logs_dir.py
+-rw-r--r--  2.0 unx     1279 b- defN 23-May-30 08:22 mlrun/api/utils/singletons/project_member.py
+-rw-r--r--  2.0 unx     1063 b- defN 23-May-30 08:22 mlrun/api/utils/singletons/scheduler.py
+-rw-r--r--  2.0 unx     1091 b- defN 23-May-30 08:22 mlrun/artifacts/__init__.py
+-rw-r--r--  2.0 unx    30849 b- defN 23-May-30 08:22 mlrun/artifacts/base.py
+-rw-r--r--  2.0 unx    20432 b- defN 23-May-30 08:22 mlrun/artifacts/dataset.py
+-rw-r--r--  2.0 unx    12594 b- defN 23-May-30 08:22 mlrun/artifacts/manager.py
+-rw-r--r--  2.0 unx    23673 b- defN 23-May-30 08:22 mlrun/artifacts/model.py
+-rw-r--r--  2.0 unx    15383 b- defN 23-May-30 08:22 mlrun/artifacts/plots.py
+-rw-r--r--  2.0 unx      571 b- defN 23-May-30 08:22 mlrun/common/__init__.py
+-rw-r--r--  2.0 unx      660 b- defN 23-May-30 08:22 mlrun/common/constants.py
+-rw-r--r--  2.0 unx     5670 b- defN 23-May-30 08:22 mlrun/common/model_monitoring.py
+-rw-r--r--  2.0 unx      790 b- defN 23-May-30 08:22 mlrun/common/types.py
+-rw-r--r--  2.0 unx     3973 b- defN 23-May-30 08:22 mlrun/common/schemas/__init__.py
+-rw-r--r--  2.0 unx     1923 b- defN 23-May-30 08:22 mlrun/common/schemas/artifact.py
+-rw-r--r--  2.0 unx     5251 b- defN 23-May-30 08:22 mlrun/common/schemas/auth.py
+-rw-r--r--  2.0 unx     1553 b- defN 23-May-30 08:22 mlrun/common/schemas/background_task.py
+-rw-r--r--  2.0 unx     2751 b- defN 23-May-30 08:22 mlrun/common/schemas/client_spec.py
+-rw-r--r--  2.0 unx      888 b- defN 23-May-30 08:22 mlrun/common/schemas/clusterization_spec.py
+-rw-r--r--  2.0 unx     6243 b- defN 23-May-30 08:22 mlrun/common/schemas/constants.py
+-rw-r--r--  2.0 unx     3671 b- defN 23-May-30 08:22 mlrun/common/schemas/feature_store.py
+-rw-r--r--  2.0 unx     2546 b- defN 23-May-30 08:22 mlrun/common/schemas/frontend_spec.py
+-rw-r--r--  2.0 unx     3971 b- defN 23-May-30 08:22 mlrun/common/schemas/function.py
+-rw-r--r--  2.0 unx      705 b- defN 23-May-30 08:22 mlrun/common/schemas/http.py
+-rw-r--r--  2.0 unx     4245 b- defN 23-May-30 08:22 mlrun/common/schemas/hub.py
+-rw-r--r--  2.0 unx     1395 b- defN 23-May-30 08:22 mlrun/common/schemas/k8s.py
+-rw-r--r--  2.0 unx      920 b- defN 23-May-30 08:22 mlrun/common/schemas/memory_reports.py
+-rw-r--r--  2.0 unx    12593 b- defN 23-May-30 08:22 mlrun/common/schemas/model_endpoints.py
+-rw-r--r--  2.0 unx      879 b- defN 23-May-30 08:22 mlrun/common/schemas/notification.py
+-rw-r--r--  2.0 unx     1907 b- defN 23-May-30 08:22 mlrun/common/schemas/object.py
+-rw-r--r--  2.0 unx     1184 b- defN 23-May-30 08:22 mlrun/common/schemas/pipeline.py
+-rw-r--r--  2.0 unx     4094 b- defN 23-May-30 08:22 mlrun/common/schemas/project.py
+-rw-r--r--  2.0 unx     1636 b- defN 23-May-30 08:22 mlrun/common/schemas/runtime_resource.py
+-rw-r--r--  2.0 unx     4188 b- defN 23-May-30 08:22 mlrun/common/schemas/schedule.py
+-rw-r--r--  2.0 unx     1484 b- defN 23-May-30 08:22 mlrun/common/schemas/secret.py
+-rw-r--r--  2.0 unx      905 b- defN 23-May-30 08:22 mlrun/common/schemas/tag.py
+-rw-r--r--  2.0 unx     1087 b- defN 23-May-30 08:22 mlrun/data_types/__init__.py
+-rw-r--r--  2.0 unx     4647 b- defN 23-May-30 08:22 mlrun/data_types/data_types.py
+-rw-r--r--  2.0 unx     5813 b- defN 23-May-30 08:22 mlrun/data_types/infer.py
+-rw-r--r--  2.0 unx     9426 b- defN 23-May-30 08:22 mlrun/data_types/spark.py
+-rw-r--r--  2.0 unx     3443 b- defN 23-May-30 08:22 mlrun/datastore/__init__.py
+-rw-r--r--  2.0 unx     6946 b- defN 23-May-30 08:22 mlrun/datastore/azure_blob.py
+-rw-r--r--  2.0 unx    18274 b- defN 23-May-30 08:22 mlrun/datastore/base.py
+-rw-r--r--  2.0 unx     7995 b- defN 23-May-30 08:22 mlrun/datastore/datastore.py
+-rw-r--r--  2.0 unx     3791 b- defN 23-May-30 08:22 mlrun/datastore/filestore.py
+-rw-r--r--  2.0 unx     5114 b- defN 23-May-30 08:22 mlrun/datastore/google_cloud_storage.py
+-rw-r--r--  2.0 unx     2627 b- defN 23-May-30 08:22 mlrun/datastore/inmem.py
+-rw-r--r--  2.0 unx     4873 b- defN 23-May-30 08:22 mlrun/datastore/redis.py
+-rw-r--r--  2.0 unx     7035 b- defN 23-May-30 08:22 mlrun/datastore/s3.py
+-rw-r--r--  2.0 unx    34280 b- defN 23-May-30 08:22 mlrun/datastore/sources.py
+-rw-r--r--  2.0 unx     1410 b- defN 23-May-30 08:22 mlrun/datastore/spark_udf.py
+-rw-r--r--  2.0 unx     6895 b- defN 23-May-30 08:22 mlrun/datastore/store_resources.py
+-rw-r--r--  2.0 unx    62060 b- defN 23-May-30 08:22 mlrun/datastore/targets.py
+-rw-r--r--  2.0 unx     2900 b- defN 23-May-30 08:22 mlrun/datastore/utils.py
+-rw-r--r--  2.0 unx     8097 b- defN 23-May-30 08:22 mlrun/datastore/v3io.py
+-rw-r--r--  2.0 unx     1343 b- defN 23-May-30 08:22 mlrun/datastore/wasbfs/__init__.py
+-rw-r--r--  2.0 unx     6152 b- defN 23-May-30 08:22 mlrun/datastore/wasbfs/fs.py
+-rw-r--r--  2.0 unx     2816 b- defN 23-May-30 08:22 mlrun/db/__init__.py
+-rw-r--r--  2.0 unx    15968 b- defN 23-May-30 08:22 mlrun/db/base.py
+-rw-r--r--  2.0 unx   130841 b- defN 23-May-30 08:22 mlrun/db/httpdb.py
+-rw-r--r--  2.0 unx    13197 b- defN 23-May-30 08:22 mlrun/db/nopdb.py
+-rw-r--r--  2.0 unx    25577 b- defN 23-May-30 08:22 mlrun/db/sqldb.py
+-rw-r--r--  2.0 unx     1501 b- defN 23-May-30 08:22 mlrun/feature_store/__init__.py
+-rw-r--r--  2.0 unx    43719 b- defN 23-May-30 08:22 mlrun/feature_store/api.py
+-rw-r--r--  2.0 unx    12781 b- defN 23-May-30 08:22 mlrun/feature_store/common.py
+-rw-r--r--  2.0 unx    47683 b- defN 23-May-30 08:22 mlrun/feature_store/feature_set.py
+-rw-r--r--  2.0 unx    21940 b- defN 23-May-30 08:22 mlrun/feature_store/feature_vector.py
+-rw-r--r--  2.0 unx    11681 b- defN 23-May-30 08:22 mlrun/feature_store/ingestion.py
+-rw-r--r--  2.0 unx    28635 b- defN 23-May-30 08:22 mlrun/feature_store/steps.py
+-rw-r--r--  2.0 unx     1232 b- defN 23-May-30 08:22 mlrun/feature_store/retrieval/__init__.py
+-rw-r--r--  2.0 unx    25911 b- defN 23-May-30 08:22 mlrun/feature_store/retrieval/base.py
+-rw-r--r--  2.0 unx     4261 b- defN 23-May-30 08:22 mlrun/feature_store/retrieval/dask_merger.py
+-rw-r--r--  2.0 unx     7141 b- defN 23-May-30 08:22 mlrun/feature_store/retrieval/job.py
+-rw-r--r--  2.0 unx     4765 b- defN 23-May-30 08:22 mlrun/feature_store/retrieval/local_merger.py
+-rw-r--r--  2.0 unx     3352 b- defN 23-May-30 08:22 mlrun/feature_store/retrieval/online.py
+-rw-r--r--  2.0 unx     9661 b- defN 23-May-30 08:22 mlrun/feature_store/retrieval/spark_merger.py
+-rw-r--r--  2.0 unx      743 b- defN 23-May-30 08:22 mlrun/frameworks/__init__.py
+-rw-r--r--  2.0 unx    11466 b- defN 23-May-30 08:22 mlrun/frameworks/parallel_coordinates.py
+-rw-r--r--  2.0 unx      962 b- defN 23-May-30 08:22 mlrun/frameworks/_common/__init__.py
+-rw-r--r--  2.0 unx     8515 b- defN 23-May-30 08:22 mlrun/frameworks/_common/artifacts_library.py
+-rw-r--r--  2.0 unx    21018 b- defN 23-May-30 08:22 mlrun/frameworks/_common/mlrun_interface.py
+-rw-r--r--  2.0 unx    55376 b- defN 23-May-30 08:22 mlrun/frameworks/_common/model_handler.py
+-rw-r--r--  2.0 unx     3469 b- defN 23-May-30 08:22 mlrun/frameworks/_common/plan.py
+-rw-r--r--  2.0 unx     5757 b- defN 23-May-30 08:22 mlrun/frameworks/_common/producer.py
+-rw-r--r--  2.0 unx     9209 b- defN 23-May-30 08:22 mlrun/frameworks/_common/utils.py
+-rw-r--r--  2.0 unx      750 b- defN 23-May-30 08:22 mlrun/frameworks/_dl_common/__init__.py
+-rw-r--r--  2.0 unx     1151 b- defN 23-May-30 08:22 mlrun/frameworks/_dl_common/model_handler.py
+-rw-r--r--  2.0 unx      996 b- defN 23-May-30 08:22 mlrun/frameworks/_dl_common/utils.py
+-rw-r--r--  2.0 unx      787 b- defN 23-May-30 08:22 mlrun/frameworks/_dl_common/loggers/__init__.py
+-rw-r--r--  2.0 unx    11531 b- defN 23-May-30 08:22 mlrun/frameworks/_dl_common/loggers/logger.py
+-rw-r--r--  2.0 unx    14777 b- defN 23-May-30 08:22 mlrun/frameworks/_dl_common/loggers/mlrun_logger.py
+-rw-r--r--  2.0 unx    28414 b- defN 23-May-30 08:22 mlrun/frameworks/_dl_common/loggers/tensorboard_logger.py
+-rw-r--r--  2.0 unx      956 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/__init__.py
+-rw-r--r--  2.0 unx     3169 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/artifacts_library.py
+-rw-r--r--  2.0 unx    16957 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/model_handler.py
+-rw-r--r--  2.0 unx     2368 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/pkl_model_server.py
+-rw-r--r--  2.0 unx     4881 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/plan.py
+-rw-r--r--  2.0 unx     4061 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/producer.py
+-rw-r--r--  2.0 unx    10490 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/utils.py
+-rw-r--r--  2.0 unx      737 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/loggers/__init__.py
+-rw-r--r--  2.0 unx     5684 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/loggers/logger.py
+-rw-r--r--  2.0 unx     6453 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/loggers/mlrun_logger.py
+-rw-r--r--  2.0 unx      922 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/plans/__init__.py
+-rw-r--r--  2.0 unx     5212 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/plans/calibration_curve_plan.py
+-rw-r--r--  2.0 unx     6078 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/plans/confusion_matrix_plan.py
+-rw-r--r--  2.0 unx     6658 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/plans/dataset_plan.py
+-rw-r--r--  2.0 unx     5318 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/plans/feature_importance_plan.py
+-rw-r--r--  2.0 unx     6993 b- defN 23-May-30 08:22 mlrun/frameworks/_ml_common/plans/roc_curve_plan.py
+-rw-r--r--  2.0 unx      706 b- defN 23-May-30 08:22 mlrun/frameworks/auto_mlrun/__init__.py
+-rw-r--r--  2.0 unx    23796 b- defN 23-May-30 08:22 mlrun/frameworks/auto_mlrun/auto_mlrun.py
+-rw-r--r--  2.0 unx      721 b- defN 23-May-30 08:22 mlrun/frameworks/huggingface/__init__.py
+-rw-r--r--  2.0 unx     6083 b- defN 23-May-30 08:22 mlrun/frameworks/huggingface/model_server.py
+-rw-r--r--  2.0 unx    15883 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/__init__.py
+-rw-r--r--  2.0 unx    13891 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/model_handler.py
+-rw-r--r--  2.0 unx     9189 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/model_server.py
+-rw-r--r--  2.0 unx     8278 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/utils.py
+-rw-r--r--  2.0 unx      857 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/callbacks/__init__.py
+-rw-r--r--  2.0 unx     4081 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/callbacks/callback.py
+-rw-r--r--  2.0 unx     5156 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/callbacks/logging_callback.py
+-rw-r--r--  2.0 unx     4137 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/callbacks/mlrun_logging_callback.py
+-rw-r--r--  2.0 unx      842 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/mlrun_interfaces/__init__.py
+-rw-r--r--  2.0 unx     1624 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/mlrun_interfaces/booster_mlrun_interface.py
+-rw-r--r--  2.0 unx    14256 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/mlrun_interfaces/mlrun_interface.py
+-rw-r--r--  2.0 unx     1333 b- defN 23-May-30 08:22 mlrun/frameworks/lgbm/mlrun_interfaces/model_mlrun_interface.py
+-rw-r--r--  2.0 unx      791 b- defN 23-May-30 08:22 mlrun/frameworks/onnx/__init__.py
+-rw-r--r--  2.0 unx     6098 b- defN 23-May-30 08:22 mlrun/frameworks/onnx/dataset.py
+-rw-r--r--  2.0 unx     2405 b- defN 23-May-30 08:22 mlrun/frameworks/onnx/mlrun_interface.py
+-rw-r--r--  2.0 unx     6203 b- defN 23-May-30 08:22 mlrun/frameworks/onnx/model_handler.py
+-rw-r--r--  2.0 unx     7061 b- defN 23-May-30 08:22 mlrun/frameworks/onnx/model_server.py
+-rw-r--r--  2.0 unx    22056 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/__init__.py
+-rw-r--r--  2.0 unx    27904 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/callbacks_handler.py
+-rw-r--r--  2.0 unx    44639 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/mlrun_interface.py
+-rw-r--r--  2.0 unx    22465 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/model_handler.py
+-rw-r--r--  2.0 unx    10136 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/model_server.py
+-rw-r--r--  2.0 unx     4515 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/utils.py
+-rw-r--r--  2.0 unx      896 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/callbacks/__init__.py
+-rw-r--r--  2.0 unx    11524 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/callbacks/callback.py
+-rw-r--r--  2.0 unx    23166 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/callbacks/logging_callback.py
+-rw-r--r--  2.0 unx     9310 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/callbacks/mlrun_logging_callback.py
+-rw-r--r--  2.0 unx    26661 b- defN 23-May-30 08:22 mlrun/frameworks/pytorch/callbacks/tensorboard_logging_callback.py
+-rw-r--r--  2.0 unx    10892 b- defN 23-May-30 08:22 mlrun/frameworks/sklearn/__init__.py
+-rw-r--r--  2.0 unx     5852 b- defN 23-May-30 08:22 mlrun/frameworks/sklearn/estimator.py
+-rw-r--r--  2.0 unx     7117 b- defN 23-May-30 08:22 mlrun/frameworks/sklearn/metric.py
+-rw-r--r--  2.0 unx    12215 b- defN 23-May-30 08:22 mlrun/frameworks/sklearn/metrics_library.py
+-rw-r--r--  2.0 unx    14126 b- defN 23-May-30 08:22 mlrun/frameworks/sklearn/mlrun_interface.py
+-rw-r--r--  2.0 unx     4745 b- defN 23-May-30 08:22 mlrun/frameworks/sklearn/model_handler.py
+-rw-r--r--  2.0 unx     1209 b- defN 23-May-30 08:22 mlrun/frameworks/sklearn/utils.py
+-rw-r--r--  2.0 unx    10455 b- defN 23-May-30 08:22 mlrun/frameworks/tf_keras/__init__.py
+-rw-r--r--  2.0 unx    16627 b- defN 23-May-30 08:22 mlrun/frameworks/tf_keras/mlrun_interface.py
+-rw-r--r--  2.0 unx    28247 b- defN 23-May-30 08:22 mlrun/frameworks/tf_keras/model_handler.py
+-rw-r--r--  2.0 unx     9565 b- defN 23-May-30 08:22 mlrun/frameworks/tf_keras/model_server.py
+-rw-r--r--  2.0 unx     4284 b- defN 23-May-30 08:22 mlrun/frameworks/tf_keras/utils.py
+-rw-r--r--  2.0 unx      844 b- defN 23-May-30 08:22 mlrun/frameworks/tf_keras/callbacks/__init__.py
+-rw-r--r--  2.0 unx    21886 b- defN 23-May-30 08:22 mlrun/frameworks/tf_keras/callbacks/logging_callback.py
+-rw-r--r--  2.0 unx     8791 b- defN 23-May-30 08:22 mlrun/frameworks/tf_keras/callbacks/mlrun_logging_callback.py
+-rw-r--r--  2.0 unx    28728 b- defN 23-May-30 08:22 mlrun/frameworks/tf_keras/callbacks/tensorboard_logging_callback.py
+-rw-r--r--  2.0 unx    10287 b- defN 23-May-30 08:22 mlrun/frameworks/xgboost/__init__.py
+-rw-r--r--  2.0 unx      878 b- defN 23-May-30 08:22 mlrun/frameworks/xgboost/mlrun_interface.py
+-rw-r--r--  2.0 unx    11617 b- defN 23-May-30 08:22 mlrun/frameworks/xgboost/model_handler.py
+-rw-r--r--  2.0 unx     1069 b- defN 23-May-30 08:22 mlrun/frameworks/xgboost/utils.py
+-rw-r--r--  2.0 unx      577 b- defN 23-May-30 08:22 mlrun/launcher/__init__.py
+-rw-r--r--  2.0 unx    15180 b- defN 23-May-30 08:22 mlrun/launcher/base.py
+-rw-r--r--  2.0 unx     6164 b- defN 23-May-30 08:22 mlrun/launcher/client.py
+-rw-r--r--  2.0 unx     1883 b- defN 23-May-30 08:22 mlrun/launcher/factory.py
+-rw-r--r--  2.0 unx    10569 b- defN 23-May-30 08:22 mlrun/launcher/local.py
+-rw-r--r--  2.0 unx     6770 b- defN 23-May-30 08:22 mlrun/launcher/remote.py
+-rw-r--r--  2.0 unx      760 b- defN 23-May-30 08:22 mlrun/mlutils/__init__.py
+-rw-r--r--  2.0 unx     5325 b- defN 23-May-30 08:22 mlrun/mlutils/data.py
+-rw-r--r--  2.0 unx     2598 b- defN 23-May-30 08:22 mlrun/mlutils/models.py
+-rw-r--r--  2.0 unx    30120 b- defN 23-May-30 08:22 mlrun/mlutils/plots.py
+-rw-r--r--  2.0 unx     1208 b- defN 23-May-30 08:22 mlrun/model_monitoring/__init__.py
+-rw-r--r--  2.0 unx    23948 b- defN 23-May-30 08:22 mlrun/model_monitoring/features_drift_table.py
+-rw-r--r--  2.0 unx     9756 b- defN 23-May-30 08:22 mlrun/model_monitoring/helpers.py
+-rw-r--r--  2.0 unx     5196 b- defN 23-May-30 08:22 mlrun/model_monitoring/model_endpoint.py
+-rw-r--r--  2.0 unx    36885 b- defN 23-May-30 08:22 mlrun/model_monitoring/model_monitoring_batch.py
+-rw-r--r--  2.0 unx    43134 b- defN 23-May-30 08:22 mlrun/model_monitoring/stream_processing_fs.py
+-rw-r--r--  2.0 unx     4240 b- defN 23-May-30 08:22 mlrun/model_monitoring/stores/__init__.py
+-rw-r--r--  2.0 unx    17357 b- defN 23-May-30 08:22 mlrun/model_monitoring/stores/kv_model_endpoint_store.py
+-rw-r--r--  2.0 unx     5695 b- defN 23-May-30 08:22 mlrun/model_monitoring/stores/model_endpoint_store.py
+-rw-r--r--  2.0 unx    15706 b- defN 23-May-30 08:22 mlrun/model_monitoring/stores/sql_model_endpoint_store.py
+-rw-r--r--  2.0 unx      884 b- defN 23-May-30 08:22 mlrun/model_monitoring/stores/models/__init__.py
+-rw-r--r--  2.0 unx      655 b- defN 23-May-30 08:22 mlrun/model_monitoring/stores/models/base.py
+-rw-r--r--  2.0 unx     3741 b- defN 23-May-30 08:22 mlrun/model_monitoring/stores/models/mysql.py
+-rw-r--r--  2.0 unx     3658 b- defN 23-May-30 08:22 mlrun/model_monitoring/stores/models/sqlite.py
+-rw-r--r--  2.0 unx     2400 b- defN 23-May-30 08:22 mlrun/platforms/__init__.py
+-rw-r--r--  2.0 unx    23997 b- defN 23-May-30 08:22 mlrun/platforms/iguazio.py
+-rw-r--r--  2.0 unx    11852 b- defN 23-May-30 08:22 mlrun/platforms/other.py
+-rw-r--r--  2.0 unx     1153 b- defN 23-May-30 08:22 mlrun/projects/__init__.py
+-rw-r--r--  2.0 unx    17582 b- defN 23-May-30 08:22 mlrun/projects/operations.py
+-rw-r--r--  2.0 unx    38343 b- defN 23-May-30 08:22 mlrun/projects/pipelines.py
+-rw-r--r--  2.0 unx   113384 b- defN 23-May-30 08:22 mlrun/projects/project.py
+-rw-r--r--  2.0 unx     8773 b- defN 23-May-30 08:22 mlrun/runtimes/__init__.py
+-rw-r--r--  2.0 unx    86181 b- defN 23-May-30 08:22 mlrun/runtimes/base.py
+-rw-r--r--  2.0 unx     6689 b- defN 23-May-30 08:22 mlrun/runtimes/constants.py
+-rw-r--r--  2.0 unx    30353 b- defN 23-May-30 08:22 mlrun/runtimes/daskjob.py
+-rw-r--r--  2.0 unx     9561 b- defN 23-May-30 08:22 mlrun/runtimes/funcdoc.py
+-rw-r--r--  2.0 unx    45205 b- defN 23-May-30 08:22 mlrun/runtimes/function.py
+-rw-r--r--  2.0 unx     4911 b- defN 23-May-30 08:22 mlrun/runtimes/function_reference.py
+-rw-r--r--  2.0 unx     6530 b- defN 23-May-30 08:22 mlrun/runtimes/generators.py
+-rw-r--r--  2.0 unx    15410 b- defN 23-May-30 08:22 mlrun/runtimes/kubejob.py
+-rw-r--r--  2.0 unx    19158 b- defN 23-May-30 08:22 mlrun/runtimes/local.py
+-rw-r--r--  2.0 unx     2885 b- defN 23-May-30 08:22 mlrun/runtimes/nuclio.py
+-rw-r--r--  2.0 unx    60808 b- defN 23-May-30 08:22 mlrun/runtimes/pod.py
+-rw-r--r--  2.0 unx     7695 b- defN 23-May-30 08:22 mlrun/runtimes/remotesparkjob.py
+-rw-r--r--  2.0 unx    29858 b- defN 23-May-30 08:22 mlrun/runtimes/serving.py
+-rw-r--r--  2.0 unx    21048 b- defN 23-May-30 08:22 mlrun/runtimes/utils.py
+-rw-r--r--  2.0 unx      790 b- defN 23-May-30 08:22 mlrun/runtimes/mpijob/__init__.py
+-rw-r--r--  2.0 unx    14713 b- defN 23-May-30 08:22 mlrun/runtimes/mpijob/abstract.py
+-rw-r--r--  2.0 unx    13845 b- defN 23-May-30 08:22 mlrun/runtimes/mpijob/v1.py
+-rw-r--r--  2.0 unx     8460 b- defN 23-May-30 08:22 mlrun/runtimes/mpijob/v1alpha1.py
+-rw-r--r--  2.0 unx      673 b- defN 23-May-30 08:22 mlrun/runtimes/package/__init__.py
+-rw-r--r--  2.0 unx    27068 b- defN 23-May-30 08:22 mlrun/runtimes/package/context_handler.py
+-rw-r--r--  2.0 unx      751 b- defN 23-May-30 08:22 mlrun/runtimes/sparkjob/__init__.py
+-rw-r--r--  2.0 unx    35028 b- defN 23-May-30 08:22 mlrun/runtimes/sparkjob/abstract.py
+-rw-r--r--  2.0 unx    28746 b- defN 23-May-30 08:22 mlrun/runtimes/sparkjob/spark3job.py
+-rw-r--r--  2.0 unx     1078 b- defN 23-May-30 08:22 mlrun/serving/__init__.py
+-rw-r--r--  2.0 unx     6116 b- defN 23-May-30 08:22 mlrun/serving/merger.py
+-rw-r--r--  2.0 unx    18038 b- defN 23-May-30 08:22 mlrun/serving/remote.py
+-rw-r--r--  2.0 unx    55277 b- defN 23-May-30 08:22 mlrun/serving/routers.py
+-rw-r--r--  2.0 unx    20247 b- defN 23-May-30 08:22 mlrun/serving/server.py
+-rw-r--r--  2.0 unx      836 b- defN 23-May-30 08:22 mlrun/serving/serving_wrapper.py
+-rw-r--r--  2.0 unx    54169 b- defN 23-May-30 08:22 mlrun/serving/states.py
+-rw-r--r--  2.0 unx     3902 b- defN 23-May-30 08:22 mlrun/serving/utils.py
+-rw-r--r--  2.0 unx    11814 b- defN 23-May-30 08:22 mlrun/serving/v1_serving.py
+-rw-r--r--  2.0 unx    21460 b- defN 23-May-30 08:22 mlrun/serving/v2_serving.py
+-rw-r--r--  2.0 unx      826 b- defN 23-May-30 08:22 mlrun/utils/__init__.py
+-rw-r--r--  2.0 unx    10397 b- defN 23-May-30 08:22 mlrun/utils/async_http.py
+-rw-r--r--  2.0 unx     3456 b- defN 23-May-30 08:22 mlrun/utils/azure_vault.py
+-rw-r--r--  2.0 unx     6245 b- defN 23-May-30 08:22 mlrun/utils/clones.py
+-rw-r--r--  2.0 unx     1662 b- defN 23-May-30 08:22 mlrun/utils/db.py
+-rw-r--r--  2.0 unx    43736 b- defN 23-May-30 08:22 mlrun/utils/helpers.py
+-rw-r--r--  2.0 unx     7093 b- defN 23-May-30 08:22 mlrun/utils/http.py
+-rw-r--r--  2.0 unx     7035 b- defN 23-May-30 08:22 mlrun/utils/logger.py
+-rw-r--r--  2.0 unx     9969 b- defN 23-May-30 08:22 mlrun/utils/model_monitoring.py
+-rw-r--r--  2.0 unx     3954 b- defN 23-May-30 08:22 mlrun/utils/regex.py
+-rw-r--r--  2.0 unx      883 b- defN 23-May-30 08:22 mlrun/utils/singleton.py
+-rw-r--r--  2.0 unx     1319 b- defN 23-May-30 08:22 mlrun/utils/v3io_clients.py
+-rw-r--r--  2.0 unx    10447 b- defN 23-May-30 08:22 mlrun/utils/vault.py
+-rw-r--r--  2.0 unx      990 b- defN 23-May-30 08:22 mlrun/utils/notifications/__init__.py
+-rw-r--r--  2.0 unx    12518 b- defN 23-May-30 08:22 mlrun/utils/notifications/notification_pusher.py
+-rw-r--r--  2.0 unx     1803 b- defN 23-May-30 08:22 mlrun/utils/notifications/notification/__init__.py
+-rw-r--r--  2.0 unx     2177 b- defN 23-May-30 08:22 mlrun/utils/notifications/notification/base.py
+-rw-r--r--  2.0 unx     1971 b- defN 23-May-30 08:22 mlrun/utils/notifications/notification/console.py
+-rw-r--r--  2.0 unx     4722 b- defN 23-May-30 08:22 mlrun/utils/notifications/notification/git.py
+-rw-r--r--  2.0 unx     2021 b- defN 23-May-30 08:22 mlrun/utils/notifications/notification/ipython.py
+-rw-r--r--  2.0 unx     3751 b- defN 23-May-30 08:22 mlrun/utils/notifications/notification/slack.py
+-rw-r--r--  2.0 unx      614 b- defN 23-May-30 08:22 mlrun/utils/version/__init__.py
+-rw-r--r--  2.0 unx       88 b- defN 23-May-30 08:23 mlrun/utils/version/version.json
+-rw-r--r--  2.0 unx     1970 b- defN 23-May-30 08:22 mlrun/utils/version/version.py
+-rw-r--r--  2.0 unx    11357 b- defN 23-May-30 08:23 mlrun-1.4.0rc8.dist-info/LICENSE
+-rw-r--r--  2.0 unx    16853 b- defN 23-May-30 08:23 mlrun-1.4.0rc8.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-30 08:23 mlrun-1.4.0rc8.dist-info/WHEEL
+-rw-r--r--  2.0 unx       47 b- defN 23-May-30 08:23 mlrun-1.4.0rc8.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        6 b- defN 23-May-30 08:23 mlrun-1.4.0rc8.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    38488 b- defN 23-May-30 08:23 mlrun-1.4.0rc8.dist-info/RECORD
+410 files, 4449516 bytes uncompressed, 1132387 bytes compressed:  74.6%
```

## zipnote {}

```diff
@@ -1206,26 +1206,26 @@
 
 Filename: mlrun/utils/version/version.json
 Comment: 
 
 Filename: mlrun/utils/version/version.py
 Comment: 
 
-Filename: mlrun-1.4.0rc7.dist-info/LICENSE
+Filename: mlrun-1.4.0rc8.dist-info/LICENSE
 Comment: 
 
-Filename: mlrun-1.4.0rc7.dist-info/METADATA
+Filename: mlrun-1.4.0rc8.dist-info/METADATA
 Comment: 
 
-Filename: mlrun-1.4.0rc7.dist-info/WHEEL
+Filename: mlrun-1.4.0rc8.dist-info/WHEEL
 Comment: 
 
-Filename: mlrun-1.4.0rc7.dist-info/entry_points.txt
+Filename: mlrun-1.4.0rc8.dist-info/entry_points.txt
 Comment: 
 
-Filename: mlrun-1.4.0rc7.dist-info/top_level.txt
+Filename: mlrun-1.4.0rc8.dist-info/top_level.txt
 Comment: 
 
-Filename: mlrun-1.4.0rc7.dist-info/RECORD
+Filename: mlrun-1.4.0rc8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mlrun/model.py

```diff
@@ -13,14 +13,15 @@
 # limitations under the License.
 
 import inspect
 import pathlib
 import re
 import time
 import typing
+import warnings
 from collections import OrderedDict
 from copy import deepcopy
 from datetime import datetime
 from os import environ
 from typing import Any, Dict, List, Optional, Tuple, Union
 
 import mlrun
@@ -386,24 +387,25 @@
         secret=None,
         source=None,
         extra=None,
         load_source_on_run=None,
         with_mlrun=None,
         auto_build=None,
         requirements=None,
+        requirements_file=None,
         overwrite=False,
     ):
         if image:
             self.image = image
         if base_image:
             self.base_image = base_image
         if commands:
             self.with_commands(commands, overwrite=overwrite)
         if requirements:
-            self.with_requirements(requirements, overwrite=overwrite)
+            self.with_requirements(requirements, requirements_file, overwrite=overwrite)
         if extra:
             self.extra = extra
         if secret is not None:
             self.secret = secret
         if source:
             self.source = source
         if load_source_on_run:
@@ -439,38 +441,69 @@
             # using list(set(x)) won't retain order,
             # solution inspired from https://stackoverflow.com/a/17016257/8116661
             self.commands = list(dict.fromkeys(self.commands))
 
     def with_requirements(
         self,
         requirements: Union[str, List[str]],
+        requirements_file: str = "",
         overwrite: bool = False,
     ):
         """add package requirements from file or list to build spec.
 
-        :param requirements:  python requirements file path or list of packages
-        :param overwrite:     overwrite existing requirements
+        :param requirements:        a list of python packages
+        :param requirements_file:   path to a python requirements file
+        :param overwrite:           overwrite existing requirements,
+                                    when False (default) will append to existing requirements
         :return: function object
         """
-        resolved_requirements = self._resolve_requirements(requirements)
+        if isinstance(requirements, str) and mlrun.utils.is_file_path(requirements):
+            # TODO: remove in 1.6.0
+            warnings.warn(
+                "Passing a requirements file path as a string in the 'requirements' argument is deprecated "
+                "and will be removed in 1.6.0, use 'requirements_file' instead",
+                FutureWarning,
+            )
+
+        resolved_requirements = self._resolve_requirements(
+            requirements, requirements_file
+        )
         requirements = self.requirements or [] if not overwrite else []
 
         # make sure we don't append the same line twice
         for requirement in resolved_requirements:
             if requirement not in requirements:
                 requirements.append(requirement)
 
         self.requirements = requirements
 
     @staticmethod
-    def _resolve_requirements(requirements_to_resolve: typing.Union[str, list]) -> list:
-        # if a string, read the file then encode
-        if isinstance(requirements_to_resolve, str):
-            with open(requirements_to_resolve, "r") as fp:
-                requirements_to_resolve = fp.read().splitlines()
+    def _resolve_requirements(
+        requirements: typing.Union[str, list], requirements_file: str = ""
+    ) -> list:
+        requirements_to_resolve = []
+
+        # handle the requirements_file argument
+        if requirements_file:
+            with open(requirements_file, "r") as fp:
+                requirements_to_resolve.extend(fp.read().splitlines())
+
+        # handle the requirements argument
+        # TODO: remove in 1.6.0, when requirements can only be a list
+        if isinstance(requirements, str):
+            # if it's a file path, read the file and add its content to the list
+            if mlrun.utils.is_file_path(requirements):
+                with open(requirements, "r") as fp:
+                    requirements_to_resolve.extend(fp.read().splitlines())
+            else:
+                # it's a string but not a file path, split it by lines and add it to the list
+                requirements_to_resolve.append(requirements)
+        else:
+            # it's a list, add it to the list
+            requirements_to_resolve.extend(requirements)
 
         requirements = []
         for requirement in requirements_to_resolve:
             # clean redundant leading and trailing whitespaces
             requirement = requirement.strip()
 
             # ignore empty lines
```

## mlrun/run.py

```diff
@@ -1137,38 +1137,40 @@
         f" remote: {remote},"
         f" namespace: {namespace}"
     )
 
     if remote:
         mldb = mlrun.db.get_run_db()
 
-        def get_pipeline_if_completed(run_id, namespace=namespace):
-            resp = mldb.get_pipeline(run_id, namespace=namespace, project=project)
-            status = resp["run"]["status"]
-            show_kfp_run(resp, clear_output=True)
-            if status not in RunStatuses.stable_statuses():
-                # TODO: think of nicer liveness indication and make it re-usable
-                # log '.' each retry as a liveness indication
-                logger.debug(".")
+        def _wait_for_pipeline_completion():
+            pipeline = mldb.get_pipeline(run_id, namespace=namespace, project=project)
+            pipeline_status = pipeline["run"]["status"]
+            show_kfp_run(pipeline, clear_output=True)
+            if pipeline_status not in RunStatuses.stable_statuses():
+                logger.debug(
+                    "Waiting for pipeline completion",
+                    run_id=run_id,
+                    status=pipeline_status,
+                )
                 raise RuntimeError("pipeline run has not completed yet")
 
-            return resp
+            return pipeline
 
         if mldb.kind != "http":
             raise ValueError(
-                "get pipeline require access to remote api-service"
-                ", please set the dbpath url"
+                "get pipeline requires access to remote api-service"
+                ", set the dbpath url"
             )
 
         resp = retry_until_successful(
             10,
             timeout,
             logger,
             False,
-            get_pipeline_if_completed,
+            _wait_for_pipeline_completion,
             run_id,
             namespace=namespace,
         )
     else:
         client = Client(namespace=namespace)
         resp = client.wait_for_run_completion(run_id, timeout)
         if resp:
```

## mlrun/api/launcher.py

```diff
@@ -26,15 +26,17 @@
 import mlrun.utils.regex
 
 
 class ServerSideLauncher(mlrun.launcher.base.BaseLauncher):
     def launch(
         self,
         runtime: mlrun.runtimes.BaseRuntime,
-        task: Optional[Union[mlrun.run.RunTemplate, mlrun.run.RunObject]] = None,
+        task: Optional[
+            Union["mlrun.run.RunTemplate", "mlrun.run.RunObject", dict]
+        ] = None,
         handler: Optional[str] = None,
         name: Optional[str] = "",
         project: Optional[str] = "",
         params: Optional[dict] = None,
         inputs: Optional[Dict[str, str]] = None,
         out_path: Optional[str] = "",
         workdir: Optional[str] = "",
```

## mlrun/api/main.py

```diff
@@ -562,24 +562,25 @@
 
 
 def _push_terminal_run_notifications(db: mlrun.api.db.base.DBInterface, db_session):
     """
     Get all runs with notification configs which became terminal since the last call to the function
     and push their notifications if they haven't been pushed yet.
     """
-
     # Import here to avoid circular import
     import mlrun.api.api.utils
 
     # When pushing notifications, push notifications only for runs that entered a terminal state
     # since the last time we pushed notifications.
     # On the first time we push notifications, we'll push notifications for all runs that are in a terminal state
     # and their notifications haven't been sent yet.
     global _last_notification_push_time
 
+    now = datetime.datetime.now(datetime.timezone.utc)
+
     runs = db.list_runs(
         db_session,
         project="*",
         states=mlrun.runtimes.constants.RunStates.terminal_states(),
         last_update_time_from=_last_notification_push_time,
         with_notifications=True,
     )
@@ -595,15 +596,15 @@
     ]
 
     logger.debug(
         "Got terminal runs with configured notifications", runs_amount=len(runs)
     )
     mlrun.utils.notifications.NotificationPusher(unmasked_runs).push(db)
 
-    _last_notification_push_time = datetime.datetime.now(datetime.timezone.utc)
+    _last_notification_push_time = now
 
 
 async def _stop_logs():
     """
     Stop logs for runs that are in terminal state and last updated in the previous interval
     """
     logger.debug(
```

## mlrun/api/api/utils.py

```diff
@@ -207,18 +207,24 @@
     mask_notification_params_on_task(task)
 
 
 def mask_notification_params_on_task(task):
     run_uid = get_in(task, "metadata.uid")
     project = get_in(task, "metadata.project")
     notifications = task.get("spec", {}).get("notifications", [])
+    masked_notifications = []
     if notifications:
         for notification in notifications:
             notification_object = mlrun.model.Notification.from_dict(notification)
-            mask_notification_params_with_secret(project, run_uid, notification_object)
+            masked_notifications.append(
+                mask_notification_params_with_secret(
+                    project, run_uid, notification_object
+                ).to_dict()
+            )
+    task.setdefault("spec", {})["notifications"] = masked_notifications
 
 
 def mask_notification_params_with_secret(
     project: str, run_uid: str, notification_object: mlrun.model.Notification
 ) -> mlrun.model.Notification:
     if notification_object.params and "secret" not in notification_object.params:
         secret_key = mlrun.api.crud.Secrets().generate_client_project_secret_key(
```

## mlrun/api/api/endpoints/artifacts.py

```diff
@@ -66,15 +66,17 @@
 
     data = None
     try:
         data = await request.json()
     except ValueError:
         log_and_raise(HTTPStatus.BAD_REQUEST.value, reason="bad JSON body")
 
-    logger.debug("Storing artifact", data=data)
+    logger.debug(
+        "Storing artifact", project=project, uid=uid, key=key, tag=tag, iter=iter
+    )
     await run_in_threadpool(
         mlrun.api.crud.Artifacts().store_artifact,
         db_session,
         key,
         data,
         uid,
         tag,
```

## mlrun/api/api/endpoints/feature_store.py

```diff
@@ -30,20 +30,18 @@
 from mlrun.api.api import deps
 from mlrun.api.api.utils import log_and_raise, parse_reference
 from mlrun.data_types import InferOptions
 from mlrun.datastore.targets import get_default_prefix_for_target
 from mlrun.feature_store.api import RunConfig, ingest
 from mlrun.model import DataSource, DataTargetBase
 
-router = APIRouter()
+router = APIRouter(prefix="/projects/{project}")
 
 
-@router.post(
-    "/projects/{project}/feature-sets", response_model=mlrun.common.schemas.FeatureSet
-)
+@router.post("/feature-sets", response_model=mlrun.common.schemas.FeatureSet)
 async def create_feature_set(
     project: str,
     feature_set: mlrun.common.schemas.FeatureSet,
     versioned: bool = True,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ):
@@ -75,15 +73,15 @@
         feature_set.metadata.name,
         feature_set.metadata.tag or "latest",
         feature_set_uid,
     )
 
 
 @router.put(
-    "/projects/{project}/feature-sets/{name}/references/{reference}",
+    "/feature-sets/{name}/references/{reference}",
     response_model=mlrun.common.schemas.FeatureSet,
 )
 async def store_feature_set(
     project: str,
     name: str,
     reference: str,
     feature_set: mlrun.common.schemas.FeatureSet,
@@ -121,15 +119,15 @@
         project,
         feature_set.metadata.name,
         tag,
         uid,
     )
 
 
-@router.patch("/projects/{project}/feature-sets/{name}/references/{reference}")
+@router.patch("/feature-sets/{name}/references/{reference}")
 async def patch_feature_set(
     project: str,
     name: str,
     feature_set_update: dict,
     reference: str,
     patch_mode: mlrun.common.schemas.PatchMode = Header(
         mlrun.common.schemas.PatchMode.replace,
@@ -156,15 +154,15 @@
         uid,
         patch_mode,
     )
     return Response(status_code=HTTPStatus.OK.value)
 
 
 @router.get(
-    "/projects/{project}/feature-sets/{name}/references/{reference}",
+    "/feature-sets/{name}/references/{reference}",
     response_model=mlrun.common.schemas.FeatureSet,
 )
 async def get_feature_set(
     project: str,
     name: str,
     reference: str,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
@@ -185,16 +183,16 @@
         name,
         mlrun.common.schemas.AuthorizationAction.read,
         auth_info,
     )
     return feature_set
 
 
-@router.delete("/projects/{project}/feature-sets/{name}")
-@router.delete("/projects/{project}/feature-sets/{name}/references/{reference}")
+@router.delete("/feature-sets/{name}")
+@router.delete("/feature-sets/{name}/references/{reference}")
 async def delete_feature_set(
     project: str,
     name: str,
     reference: str = None,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ):
@@ -216,15 +214,15 @@
         tag,
         uid,
     )
     return Response(status_code=HTTPStatus.NO_CONTENT.value)
 
 
 @router.get(
-    "/projects/{project}/feature-sets",
+    "/feature-sets",
     response_model=mlrun.common.schemas.FeatureSetsOutput,
 )
 async def list_feature_sets(
     project: str,
     name: str = None,
     state: str = None,
     tag: str = None,
@@ -273,15 +271,15 @@
         ),
         auth_info,
     )
     return mlrun.common.schemas.FeatureSetsOutput(feature_sets=feature_sets)
 
 
 @router.get(
-    "/projects/{project}/feature-sets/{name}/tags",
+    "/feature-sets/{name}/tags",
     response_model=mlrun.common.schemas.FeatureSetsTagsOutput,
 )
 async def list_feature_sets_tags(
     project: str,
     name: str,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
@@ -343,15 +341,15 @@
     return any(
         path and (path.startswith("v3io://") or path.startswith("v3ios://"))
         for path in paths
     )
 
 
 @router.post(
-    "/projects/{project}/feature-sets/{name}/references/{reference}/ingest",
+    "/feature-sets/{name}/references/{reference}/ingest",
     response_model=mlrun.common.schemas.FeatureSetIngestOutput,
     status_code=HTTPStatus.ACCEPTED.value,
 )
 async def ingest_feature_set(
     project: str,
     name: str,
     reference: str,
@@ -455,17 +453,15 @@
     # ingest may modify the feature-set contents, so returning the updated feature-set.
     result_feature_set = mlrun.common.schemas.FeatureSet(**feature_set.to_dict())
     return mlrun.common.schemas.FeatureSetIngestOutput(
         feature_set=result_feature_set, run_object=run_params.to_dict()
     )
 
 
-@router.get(
-    "/projects/{project}/features", response_model=mlrun.common.schemas.FeaturesOutput
-)
+@router.get("/features", response_model=mlrun.common.schemas.FeaturesOutput)
 async def list_features(
     project: str,
     name: str = None,
     tag: str = None,
     entities: List[str] = Query(None, alias="entity"),
     labels: List[str] = Query(None, alias="label"),
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
@@ -493,17 +489,15 @@
             feature_list_output.feature.name,
         ),
         auth_info,
     )
     return mlrun.common.schemas.FeaturesOutput(features=features)
 
 
-@router.get(
-    "/projects/{project}/entities", response_model=mlrun.common.schemas.EntitiesOutput
-)
+@router.get("/entities", response_model=mlrun.common.schemas.EntitiesOutput)
 async def list_entities(
     project: str,
     name: str = None,
     tag: str = None,
     labels: List[str] = Query(None, alias="label"),
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
@@ -530,15 +524,15 @@
         ),
         auth_info,
     )
     return mlrun.common.schemas.EntitiesOutput(entities=entities)
 
 
 @router.post(
-    "/projects/{project}/feature-vectors",
+    "/feature-vectors",
     response_model=mlrun.common.schemas.FeatureVector,
 )
 async def create_feature_vector(
     project: str,
     feature_vector: mlrun.common.schemas.FeatureVector,
     versioned: bool = True,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
@@ -575,15 +569,15 @@
         feature_vector.metadata.name,
         feature_vector.metadata.tag or "latest",
         feature_vector_uid,
     )
 
 
 @router.get(
-    "/projects/{project}/feature-vectors/{name}/references/{reference}",
+    "/feature-vectors/{name}/references/{reference}",
     response_model=mlrun.common.schemas.FeatureVector,
 )
 async def get_feature_vector(
     project: str,
     name: str,
     reference: str,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
@@ -608,15 +602,15 @@
     await _verify_feature_vector_features_permissions(
         auth_info, project, feature_vector.dict()
     )
     return feature_vector
 
 
 @router.get(
-    "/projects/{project}/feature-vectors",
+    "/feature-vectors",
     response_model=mlrun.common.schemas.FeatureVectorsOutput,
 )
 async def list_feature_vectors(
     project: str,
     name: str = None,
     state: str = None,
     tag: str = None,
@@ -667,15 +661,15 @@
             for fv in feature_vectors
         ]
     )
     return mlrun.common.schemas.FeatureVectorsOutput(feature_vectors=feature_vectors)
 
 
 @router.get(
-    "/projects/{project}/feature-vectors/{name}/tags",
+    "/feature-vectors/{name}/tags",
     response_model=mlrun.common.schemas.FeatureVectorsTagsOutput,
 )
 async def list_feature_vectors_tags(
     project: str,
     name: str,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
@@ -714,15 +708,15 @@
         for tag_tuple in tag_tuples
         if tag_tuple[1] in allowed_feature_vector_names
     }
     return mlrun.common.schemas.FeatureVectorsTagsOutput(tags=list(tags))
 
 
 @router.put(
-    "/projects/{project}/feature-vectors/{name}/references/{reference}",
+    "/feature-vectors/{name}/references/{reference}",
     response_model=mlrun.common.schemas.FeatureVector,
 )
 async def store_feature_vector(
     project: str,
     name: str,
     reference: str,
     feature_vector: mlrun.common.schemas.FeatureVector,
@@ -764,15 +758,15 @@
         project,
         name,
         tag,
         uid,
     )
 
 
-@router.patch("/projects/{project}/feature-vectors/{name}/references/{reference}")
+@router.patch("/feature-vectors/{name}/references/{reference}")
 async def patch_feature_vector(
     project: str,
     name: str,
     feature_vector_patch: dict,
     reference: str,
     patch_mode: mlrun.common.schemas.PatchMode = Header(
         mlrun.common.schemas.PatchMode.replace,
@@ -801,16 +795,16 @@
         tag,
         uid,
         patch_mode,
     )
     return Response(status_code=HTTPStatus.OK.value)
 
 
-@router.delete("/projects/{project}/feature-vectors/{name}")
-@router.delete("/projects/{project}/feature-vectors/{name}/references/{reference}")
+@router.delete("/feature-vectors/{name}")
+@router.delete("/feature-vectors/{name}/references/{reference}")
 async def delete_feature_vector(
     project: str,
     name: str,
     reference: str = None,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ):
```

## mlrun/api/api/endpoints/functions.py

```diff
@@ -401,35 +401,29 @@
             last_log_timestamp,
             verbose,
         )
 
     return await run_in_threadpool(
         _handle_job_deploy_status,
         db_session,
-        auth_info,
         fn,
         name,
         project,
         tag,
-        last_log_timestamp,
-        verbose,
         offset,
         logs,
     )
 
 
 def _handle_job_deploy_status(
     db_session,
-    auth_info,
     fn,
     name,
     project,
     tag,
-    last_log_timestamp,
-    verbose,
     offset,
     logs,
 ):
     # job deploy status
     state = get_in(fn, "status.state", "")
     pod = get_in(fn, "status.build_pod", "")
     image = get_in(fn, "spec.build.image", "")
@@ -476,30 +470,31 @@
                 "x-mlrun-function-status": state,
                 "function_status": state,
                 "function_image": image,
                 "builder_pod": pod,
             },
         )
 
-    logger.info(f"get pod {pod} status")
+    # TODO: change state to pod_status
     state = mlrun.api.utils.singletons.k8s.get_k8s_helper(silent=False).get_pod_status(
         pod
     )
-    logger.info(f"pod state={state}")
+    logger.info("Resolved pod status", pod_status=state, pod_name=pod)
 
     if state == "succeeded":
-        logger.info("build completed successfully")
+        logger.info("Build completed successfully")
         state = mlrun.common.schemas.FunctionState.ready
     if state in ["failed", "error"]:
-        logger.error(f"build {state}, watch the build pod logs: {pod}")
+        logger.error("Build failed", pod_name=pod, pod_status=state)
         state = mlrun.common.schemas.FunctionState.error
 
     if (logs and state != "pending") or state in terminal_states:
         resp = mlrun.api.utils.singletons.k8s.get_k8s_helper(silent=False).logs(pod)
         if state in terminal_states:
+            # TODO: move to log collector
             log_file.parent.mkdir(parents=True, exist_ok=True)
             with log_file.open("wb") as fp:
                 fp.write(resp.encode())
 
         if resp and logs:
             # begin from the offset number and then encode
             out = resp[offset:].encode()
@@ -653,21 +648,25 @@
                         model_monitoring_access_key = None
                         if not mlrun.mlconf.is_ce_mode():
                             model_monitoring_access_key = _process_model_monitoring_secret(
                                 db_session,
                                 fn.metadata.project,
                                 mlrun.common.model_monitoring.ProjectSecretKeys.ACCESS_KEY,
                             )
-                            if mlrun.utils.model_monitoring.get_stream_path(
+
+                            stream_path = mlrun.utils.model_monitoring.get_stream_path(
                                 project=fn.metadata.project
-                            ).startswith("v3io://"):
+                            )
+
+                            if stream_path.startswith("v3io://"):
                                 # Initialize model monitoring V3IO stream
                                 _create_model_monitoring_stream(
                                     project=fn.metadata.project,
                                     function=fn,
+                                    stream_path=stream_path,
                                 )
 
                         if fn.spec.tracking_policy:
                             # Convert to `TrackingPolicy` object as `fn.spec.tracking_policy` is provided as a dict
                             fn.spec.tracking_policy = (
                                 mlrun.utils.model_monitoring.TrackingPolicy.from_dict(
                                     fn.spec.tracking_policy
@@ -720,15 +719,15 @@
                 mlrun_version_specifier,
                 skip_deployed,
                 builder_env=builder_env,
                 client_version=client_version,
                 client_python_version=client_python_version,
             )
         fn.save(versioned=True)
-        logger.info("Fn:\n %s", fn.to_yaml())
+        logger.info("Resolved function", fn=fn.to_yaml())
     except Exception as err:
         logger.error(traceback.format_exc())
         log_and_raise(
             HTTPStatus.BAD_REQUEST.value,
             reason=f"runtime error: {err_to_str(err)}",
         )
     return fn, ready
@@ -832,21 +831,17 @@
         logger.error(traceback.format_exc())
         log_and_raise(
             HTTPStatus.BAD_REQUEST.value,
             reason=f"runtime error: {err_to_str(err)}",
         )
 
 
-def _create_model_monitoring_stream(project: str, function):
+def _create_model_monitoring_stream(project: str, function, stream_path):
     _init_serving_function_stream_args(fn=function)
 
-    stream_path = mlrun.mlconf.get_model_monitoring_file_target_path(
-        project=project, kind="events"
-    )
-
     _, container, stream_path = parse_model_endpoint_store_prefix(stream_path)
 
     # TODO: How should we configure sharding here?
     logger.info(
         "Creating model endpoint stream for project",
         project=project,
         stream_path=stream_path,
```

## mlrun/api/api/endpoints/grafana_proxy.py

```diff
@@ -24,15 +24,15 @@
 import mlrun.api.crud
 import mlrun.api.crud.model_monitoring.grafana
 import mlrun.api.utils.auth.verifier
 import mlrun.common.model_monitoring
 import mlrun.common.schemas
 from mlrun.api.api import deps
 
-router = APIRouter()
+router = APIRouter(prefix="/grafana-proxy/model-endpoints")
 
 NAME_TO_SEARCH_FUNCTION_DICTIONARY = {
     "list_projects": mlrun.api.crud.model_monitoring.grafana.grafana_list_projects,
 }
 NAME_TO_QUERY_FUNCTION_DICTIONARY = {
     "list_endpoints": mlrun.api.crud.model_monitoring.grafana.grafana_list_endpoints,
     "individual_feature_analysis": mlrun.api.crud.model_monitoring.grafana.grafana_individual_feature_analysis,
@@ -40,28 +40,28 @@
     "incoming_features": mlrun.api.crud.model_monitoring.grafana.grafana_incoming_features,
 }
 
 SUPPORTED_QUERY_FUNCTIONS = set(NAME_TO_QUERY_FUNCTION_DICTIONARY.keys())
 SUPPORTED_SEARCH_FUNCTIONS = set(NAME_TO_SEARCH_FUNCTION_DICTIONARY)
 
 
-@router.get("/grafana-proxy/model-endpoints", status_code=HTTPStatus.OK.value)
+@router.get("", status_code=HTTPStatus.OK.value)
 def grafana_proxy_model_endpoints_check_connection(
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
 ):
     """
     Root of grafana proxy for the model-endpoints API, used for validating the model-endpoints data source
     connectivity.
     """
     if not mlrun.mlconf.is_ce_mode():
         mlrun.api.crud.ModelEndpoints().get_access_key(auth_info)
     return Response(status_code=HTTPStatus.OK.value)
 
 
-@router.post("/grafana-proxy/model-endpoints/search", response_model=List[str])
+@router.post("/search", response_model=List[str])
 async def grafana_proxy_model_endpoints_search(
     request: Request,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ) -> List[str]:
     """
     Search route for model-endpoints grafana proxy API, used for creating an interface between grafana queries and
@@ -97,15 +97,15 @@
         result = await run_in_threadpool(
             function, db_session, auth_info, query_parameters
         )
     return result
 
 
 @router.post(
-    "/grafana-proxy/model-endpoints/query",
+    "/query",
     response_model=List[
         Union[
             mlrun.common.schemas.GrafanaTable,
             mlrun.common.schemas.GrafanaTimeSeriesTarget,
         ]
     ],
 )
```

## mlrun/api/api/endpoints/hub.py

```diff
@@ -25,19 +25,19 @@
 import mlrun.api.api.deps
 import mlrun.api.crud
 import mlrun.api.utils.auth.verifier
 import mlrun.api.utils.singletons.db
 import mlrun.common.schemas
 import mlrun.common.schemas.hub
 
-router = APIRouter()
+router = APIRouter(prefix="/hub/sources")
 
 
 @router.post(
-    path="/hub/sources",
+    path="",
     status_code=HTTPStatus.CREATED.value,
     response_model=mlrun.common.schemas.hub.IndexedHubSource,
 )
 async def create_source(
     source: mlrun.common.schemas.hub.IndexedHubSource,
     db_session: Session = Depends(mlrun.api.api.deps.get_db_session),
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
@@ -59,15 +59,15 @@
         mlrun.api.utils.singletons.db.get_db().get_hub_source,
         db_session,
         source.source.metadata.name,
     )
 
 
 @router.get(
-    path="/hub/sources",
+    path="",
     response_model=List[mlrun.common.schemas.hub.IndexedHubSource],
 )
 async def list_sources(
     db_session: Session = Depends(mlrun.api.api.deps.get_db_session),
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
         mlrun.api.api.deps.authenticate_request
     ),
@@ -80,15 +80,15 @@
 
     return await run_in_threadpool(
         mlrun.api.utils.singletons.db.get_db().list_hub_sources, db_session
     )
 
 
 @router.delete(
-    path="/hub/sources/{source_name}",
+    path="/{source_name}",
     status_code=HTTPStatus.NO_CONTENT.value,
 )
 async def delete_source(
     source_name: str,
     db_session: Session = Depends(mlrun.api.api.deps.get_db_session),
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
         mlrun.api.api.deps.authenticate_request
@@ -105,15 +105,15 @@
         db_session,
         source_name,
     )
     await run_in_threadpool(mlrun.api.crud.Hub().remove_source, source_name)
 
 
 @router.get(
-    path="/hub/sources/{source_name}",
+    path="/{source_name}",
     response_model=mlrun.common.schemas.hub.IndexedHubSource,
 )
 async def get_source(
     source_name: str,
     db_session: Session = Depends(mlrun.api.api.deps.get_db_session),
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
         mlrun.api.api.deps.authenticate_request
@@ -128,15 +128,15 @@
         auth_info,
     )
 
     return hub_source
 
 
 @router.put(
-    path="/hub/sources/{source_name}",
+    path="/{source_name}",
     response_model=mlrun.common.schemas.hub.IndexedHubSource,
 )
 async def store_source(
     source_name: str,
     source: mlrun.common.schemas.hub.IndexedHubSource,
     db_session: Session = Depends(mlrun.api.api.deps.get_db_session),
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
@@ -160,15 +160,15 @@
 
     return await run_in_threadpool(
         mlrun.api.utils.singletons.db.get_db().get_hub_source, db_session, source_name
     )
 
 
 @router.get(
-    path="/hub/sources/{source_name}/items",
+    path="/{source_name}/items",
     response_model=mlrun.common.schemas.hub.HubCatalog,
 )
 async def get_catalog(
     source_name: str,
     version: Optional[str] = Query(None),
     tag: Optional[str] = Query(None),
     force_refresh: Optional[bool] = Query(False, alias="force-refresh"),
@@ -192,15 +192,15 @@
         version,
         tag,
         force_refresh,
     )
 
 
 @router.get(
-    "/hub/sources/{source_name}/items/{item_name}",
+    "/{source_name}/items/{item_name}",
     response_model=mlrun.common.schemas.hub.HubItem,
 )
 async def get_item(
     source_name: str,
     item_name: str,
     version: Optional[str] = Query(None),
     tag: Optional[str] = Query("latest"),
@@ -226,15 +226,15 @@
         version,
         tag,
         force_refresh,
     )
 
 
 @router.get(
-    "/hub/sources/{source_name}/item-object",
+    "/{source_name}/item-object",
 )
 async def get_object(
     source_name: str,
     url: str,
     db_session: Session = Depends(mlrun.api.api.deps.get_db_session),
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
         mlrun.api.api.deps.authenticate_request
@@ -259,15 +259,15 @@
 
     ctype, _ = mimetypes.guess_type(url)
     if not ctype:
         ctype = "application/octet-stream"
     return Response(content=object_data, media_type=ctype)
 
 
-@router.get("/hub/sources/{source_name}/items/{item_name}/assets/{asset_name}")
+@router.get("/{source_name}/items/{item_name}/assets/{asset_name}")
 async def get_asset(
     source_name: str,
     item_name: str,
     asset_name: str,
     tag: Optional[str] = Query("latest"),
     version: Optional[str] = Query(None),
     db_session: Session = Depends(mlrun.api.api.deps.get_db_session),
```

## mlrun/api/api/endpoints/logs.py

```diff
@@ -17,18 +17,18 @@
 from fastapi.concurrency import run_in_threadpool
 
 import mlrun.api.api.deps
 import mlrun.api.crud
 import mlrun.api.utils.auth.verifier
 import mlrun.common.schemas
 
-router = fastapi.APIRouter()
+router = fastapi.APIRouter(prefix="/log/{project}")
 
 
-@router.post("/log/{project}/{uid}")
+@router.post("/{uid}")
 async def store_log(
     request: fastapi.Request,
     project: str,
     uid: str,
     append: bool = True,
     auth_info: mlrun.common.schemas.AuthInfo = fastapi.Depends(
         mlrun.api.api.deps.authenticate_request
@@ -48,15 +48,15 @@
         project,
         uid,
         append,
     )
     return {}
 
 
-@router.get("/log/{project}/{uid}")
+@router.get("/{uid}")
 async def get_log(
     project: str,
     uid: str,
     size: int = -1,
     offset: int = 0,
     auth_info: mlrun.common.schemas.AuthInfo = fastapi.Depends(
         mlrun.api.api.deps.authenticate_request
```

## mlrun/api/api/endpoints/model_endpoints.py

```diff
@@ -24,19 +24,19 @@
 
 import mlrun.api.api.deps
 import mlrun.api.crud
 import mlrun.api.utils.auth.verifier
 import mlrun.common.schemas
 from mlrun.errors import MLRunConflictError
 
-router = APIRouter()
+router = APIRouter(prefix="/projects/{project}/model-endpoints")
 
 
 @router.put(
-    "/projects/{project}/model-endpoints/{endpoint_id}",
+    "/{endpoint_id}",
     response_model=mlrun.common.schemas.ModelEndpoint,
 )
 async def create_or_patch(
     project: str,
     endpoint_id: str,
     model_endpoint: mlrun.common.schemas.ModelEndpoint,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
@@ -82,15 +82,15 @@
         access_key=os.environ.get("V3IO_ACCESS_KEY"),
         model_endpoint=model_endpoint,
         auth_info=auth_info,
     )
 
 
 @router.post(
-    "/projects/{project}/model-endpoints/{endpoint_id}",
+    "/{endpoint_id}",
     response_model=mlrun.common.schemas.ModelEndpoint,
 )
 async def create_model_endpoint(
     project: str,
     endpoint_id: str,
     model_endpoint: mlrun.common.schemas.ModelEndpoint,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
@@ -134,15 +134,15 @@
         mlrun.api.crud.ModelEndpoints().create_model_endpoint,
         db_session=db_session,
         model_endpoint=model_endpoint,
     )
 
 
 @router.patch(
-    "/projects/{project}/model-endpoints/{endpoint_id}",
+    "/{endpoint_id}",
     response_model=mlrun.common.schemas.ModelEndpoint,
 )
 async def patch_model_endpoint(
     project: str,
     endpoint_id: str,
     attributes: str = None,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
@@ -184,15 +184,15 @@
         project=project,
         endpoint_id=endpoint_id,
         attributes=json.loads(attributes),
     )
 
 
 @router.delete(
-    "/projects/{project}/model-endpoints/{endpoint_id}",
+    "/{endpoint_id}",
     status_code=HTTPStatus.NO_CONTENT.value,
 )
 async def delete_model_endpoint(
     project: str,
     endpoint_id: str,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
         mlrun.api.api.deps.authenticate_request
@@ -219,15 +219,15 @@
         mlrun.api.crud.ModelEndpoints().delete_model_endpoint,
         project=project,
         endpoint_id=endpoint_id,
     )
 
 
 @router.get(
-    "/projects/{project}/model-endpoints",
+    "",
     response_model=mlrun.common.schemas.ModelEndpointList,
 )
 async def list_model_endpoints(
     project: str,
     model: Optional[str] = Query(None),
     function: Optional[str] = Query(None),
     labels: List[str] = Query([], alias="label"),
@@ -312,15 +312,15 @@
     )
 
     endpoints.endpoints = allowed_endpoints
     return endpoints
 
 
 @router.get(
-    "/projects/{project}/model-endpoints/{endpoint_id}",
+    "/{endpoint_id}",
     response_model=mlrun.common.schemas.ModelEndpoint,
 )
 async def get_model_endpoint(
     project: str,
     endpoint_id: str,
     start: str = Query(default="now-1h"),
     end: str = Query(default="now"),
```

## mlrun/api/api/endpoints/pipelines.py

```diff
@@ -28,20 +28,18 @@
 import mlrun.common.schemas
 import mlrun.errors
 from mlrun.api.api import deps
 from mlrun.api.api.utils import log_and_raise
 from mlrun.config import config
 from mlrun.utils import logger
 
-router = APIRouter()
+router = APIRouter(prefix="/projects/{project}/pipelines")
 
 
-@router.get(
-    "/projects/{project}/pipelines", response_model=mlrun.common.schemas.PipelinesOutput
-)
+@router.get("", response_model=mlrun.common.schemas.PipelinesOutput)
 async def list_pipelines(
     project: str,
     namespace: str = None,
     sort_by: str = "",
     page_token: str = "",
     filter_: str = Query("", alias="filter"),
     format_: mlrun.common.schemas.PipelinesFormat = Query(
@@ -97,15 +95,15 @@
     return mlrun.common.schemas.PipelinesOutput(
         runs=allowed_runs,
         total_size=total_size or 0,
         next_page_token=next_page_token or None,
     )
 
 
-@router.post("/projects/{project}/pipelines")
+@router.post("")
 async def create_pipeline(
     project: str,
     request: Request,
     namespace: str = None,
     experiment_name: str = Query("Default", alias="experiment"),
     run_name: str = Query("", alias="run"),
     auth_info: mlrun.common.schemas.AuthInfo = Depends(
@@ -196,15 +194,15 @@
         return None
     workflow_manifest = yaml.load(data, Loader=yaml.FullLoader)
     return mlrun.api.crud.Pipelines().resolve_project_from_workflow_manifest(
         workflow_manifest
     )
 
 
-@router.get("/projects/{project}/pipelines/{run_id}")
+@router.get("/{run_id}")
 async def get_pipeline(
     run_id: str,
     project: str,
     namespace: str = Query(config.namespace),
     format_: mlrun.common.schemas.PipelinesFormat = Query(
         mlrun.common.schemas.PipelinesFormat.summary, alias="format"
     ),
```

## mlrun/api/api/endpoints/runtime_resources.py

```diff
@@ -22,19 +22,19 @@
 
 import mlrun
 import mlrun.api.api.deps
 import mlrun.api.crud
 import mlrun.api.utils.auth.verifier
 import mlrun.common.schemas
 
-router = fastapi.APIRouter()
+router = fastapi.APIRouter(prefix="/projects/{project}/runtime-resources")
 
 
 @router.get(
-    "/projects/{project}/runtime-resources",
+    "",
     response_model=typing.Union[
         mlrun.common.schemas.RuntimeResourcesOutput,
         mlrun.common.schemas.GroupedByJobRuntimeResourcesOutput,
         mlrun.common.schemas.GroupedByProjectRuntimeResourcesOutput,
     ],
 )
 async def list_runtime_resources(
@@ -51,15 +51,15 @@
 ):
     return await _list_runtime_resources(
         project, auth_info, label_selector, group_by, kind, object_id
     )
 
 
 @router.delete(
-    "/projects/{project}/runtime-resources",
+    "",
     response_model=mlrun.common.schemas.GroupedByProjectRuntimeResourcesOutput,
 )
 async def delete_runtime_resources(
     project: str,
     label_selector: typing.Optional[str] = fastapi.Query(None, alias="label-selector"),
     kind: typing.Optional[str] = None,
     object_id: typing.Optional[str] = fastapi.Query(None, alias="object-id"),
```

## mlrun/api/api/endpoints/schedules.py

```diff
@@ -24,18 +24,18 @@
 import mlrun.api.utils.clients.chief
 import mlrun.api.utils.singletons.project_member
 import mlrun.common.schemas
 from mlrun.api.api import deps
 from mlrun.api.utils.singletons.scheduler import get_scheduler
 from mlrun.utils import logger
 
-router = APIRouter()
+router = APIRouter(prefix="/projects/{project}/schedules")
 
 
-@router.post("/projects/{project}/schedules")
+@router.post("")
 async def create_schedule(
     project: str,
     schedule: mlrun.common.schemas.ScheduleInput,
     request: fastapi.Request,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ):
@@ -82,15 +82,15 @@
         schedule.cron_trigger,
         schedule.labels,
         schedule.concurrency_limit,
     )
     return Response(status_code=HTTPStatus.CREATED.value)
 
 
-@router.put("/projects/{project}/schedules/{name}")
+@router.put("/{name}")
 async def update_schedule(
     project: str,
     name: str,
     schedule: mlrun.common.schemas.ScheduleUpdate,
     request: fastapi.Request,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
@@ -132,17 +132,15 @@
         schedule.scheduled_object,
         schedule.cron_trigger,
         labels=schedule.labels,
     )
     return Response(status_code=HTTPStatus.OK.value)
 
 
-@router.get(
-    "/projects/{project}/schedules", response_model=mlrun.common.schemas.SchedulesOutput
-)
+@router.get("", response_model=mlrun.common.schemas.SchedulesOutput)
 async def list_schedules(
     project: str,
     name: str = None,
     labels: str = None,
     kind: mlrun.common.schemas.ScheduleKinds = None,
     include_last_run: bool = False,
     include_credentials: bool = fastapi.Query(False, alias="include-credentials"),
@@ -174,15 +172,15 @@
         auth_info,
     )
     schedules.schedules = filtered_schedules
     return schedules
 
 
 @router.get(
-    "/projects/{project}/schedules/{name}",
+    "/{name}",
     response_model=mlrun.common.schemas.ScheduleOutput,
 )
 async def get_schedule(
     project: str,
     name: str,
     include_last_run: bool = False,
     include_credentials: bool = fastapi.Query(False, alias="include-credentials"),
@@ -203,15 +201,15 @@
         name,
         mlrun.common.schemas.AuthorizationAction.read,
         auth_info,
     )
     return schedule
 
 
-@router.post("/projects/{project}/schedules/{name}/invoke")
+@router.post("/{name}/invoke")
 async def invoke_schedule(
     project: str,
     name: str,
     request: fastapi.Request,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ):
@@ -236,17 +234,15 @@
         return await chief_client.invoke_schedule(
             project=project, name=name, request=request
         )
 
     return await get_scheduler().invoke_schedule(db_session, auth_info, project, name)
 
 
-@router.delete(
-    "/projects/{project}/schedules/{name}", status_code=HTTPStatus.NO_CONTENT.value
-)
+@router.delete("/{name}", status_code=HTTPStatus.NO_CONTENT.value)
 async def delete_schedule(
     project: str,
     name: str,
     request: fastapi.Request,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ):
@@ -272,15 +268,15 @@
             project=project, name=name, request=request
         )
 
     await run_in_threadpool(get_scheduler().delete_schedule, db_session, project, name)
     return Response(status_code=HTTPStatus.NO_CONTENT.value)
 
 
-@router.delete("/projects/{project}/schedules", status_code=HTTPStatus.NO_CONTENT.value)
+@router.delete("", status_code=HTTPStatus.NO_CONTENT.value)
 async def delete_schedules(
     project: str,
     request: fastapi.Request,
     auth_info: mlrun.common.schemas.AuthInfo = Depends(deps.authenticate_request),
     db_session: Session = Depends(deps.get_db_session),
 ):
     schedules = await run_in_threadpool(
```

## mlrun/api/api/endpoints/tags.py

```diff
@@ -21,18 +21,18 @@
 import mlrun.api.api.deps
 import mlrun.api.crud.tags
 import mlrun.api.utils.auth.verifier
 import mlrun.api.utils.singletons.project_member
 import mlrun.common.schemas
 from mlrun.utils.helpers import tag_name_regex_as_string
 
-router = fastapi.APIRouter()
+router = fastapi.APIRouter(prefix="/projects/{project}/tags")
 
 
-@router.post("/projects/{project}/tags/{tag}", response_model=mlrun.common.schemas.Tag)
+@router.post("/{tag}", response_model=mlrun.common.schemas.Tag)
 async def overwrite_object_tags_with_tag(
     project: str,
     tag: str = fastapi.Path(..., regex=tag_name_regex_as_string()),
     tag_objects: mlrun.common.schemas.TagObjects = fastapi.Body(...),
     auth_info: mlrun.common.schemas.AuthInfo = fastapi.Depends(
         mlrun.api.api.deps.authenticate_request
     ),
@@ -63,15 +63,15 @@
         project,
         tag,
         tag_objects,
     )
     return mlrun.common.schemas.Tag(name=tag, project=project)
 
 
-@router.put("/projects/{project}/tags/{tag}", response_model=mlrun.common.schemas.Tag)
+@router.put("/{tag}", response_model=mlrun.common.schemas.Tag)
 async def append_tag_to_objects(
     project: str,
     tag: str = fastapi.Path(..., regex=tag_name_regex_as_string()),
     tag_objects: mlrun.common.schemas.TagObjects = fastapi.Body(...),
     auth_info: mlrun.common.schemas.AuthInfo = fastapi.Depends(
         mlrun.api.api.deps.authenticate_request
     ),
@@ -100,17 +100,15 @@
         project,
         tag,
         tag_objects,
     )
     return mlrun.common.schemas.Tag(name=tag, project=project)
 
 
-@router.delete(
-    "/projects/{project}/tags/{tag}", status_code=http.HTTPStatus.NO_CONTENT.value
-)
+@router.delete("/{tag}", status_code=http.HTTPStatus.NO_CONTENT.value)
 async def delete_tag_from_objects(
     project: str,
     tag: str,
     tag_objects: mlrun.common.schemas.TagObjects,
     auth_info: mlrun.common.schemas.AuthInfo = fastapi.Depends(
         mlrun.api.api.deps.authenticate_request
     ),
```

## mlrun/api/api/endpoints/internal/memory_reports.py

```diff
@@ -13,30 +13,30 @@
 # limitations under the License.
 #
 import fastapi
 
 import mlrun.api.utils.memory_reports
 import mlrun.common.schemas
 
-router = fastapi.APIRouter()
+router = fastapi.APIRouter(prefix="/memory-reports")
 
 
 @router.get(
-    "/memory-reports/common-types",
+    "/common-types",
     response_model=mlrun.common.schemas.MostCommonObjectTypesReport,
 )
 def get_most_common_objects_report():
     report = (
         mlrun.api.utils.memory_reports.MemoryUsageReport().create_most_common_objects_report()
     )
     return mlrun.common.schemas.MostCommonObjectTypesReport(object_types=report)
 
 
 @router.get(
-    "/memory-reports/{object_type}",
+    "/{object_type}",
     response_model=mlrun.common.schemas.ObjectTypeReport,
 )
 def get_memory_usage_report(
     object_type: str,
     sample_size: int = 1,
     start_index: int = None,
     create_graph: bool = False,
```

## mlrun/api/crud/logs.py

```diff
@@ -240,28 +240,26 @@
             raise FileNotFoundError(f"Log file does not exist: {log_file}")
         return log_file.stat().st_mtime
 
     @staticmethod
     def log_file_exists_for_run_uid(project: str, uid: str) -> (bool, pathlib.Path):
         """
         Checks if the log file exists for the given project and uid
-        There could be two types of log files:
-        1. Log file which was created by the legacy logger with the following file format - project/<run-uid>)
-        2. Log file which was created by the new logger with the following file format- /project/<run-uid>-<pod-name>
-        Therefore, we check if the log file exists for both formats
+        A Run's log file path is: /mlrun/logs/{project}/{uid}
         :param project: project name
         :param uid: run uid
         :return: True if the log file exists, False otherwise, and the log file path
         """
         project_logs_dir = project_logs_path(project)
         if not project_logs_dir.exists():
             return False, None
-        for file in os.listdir(str(project_logs_dir)):
-            if file.startswith(uid):
-                return True, project_logs_dir / file
+
+        log_file = log_path(project, uid)
+        if log_file.exists():
+            return True, log_file
 
         return False, None
 
     def _list_project_logs_uids(self, project: str) -> typing.List[str]:
         logs_path = project_logs_path(project)
         return [
             file
```

## mlrun/api/crud/pipelines.py

```diff
@@ -119,21 +119,22 @@
         try:
             api_run_detail = kfp_client.get_run(run_id)
             if api_run_detail.run:
                 run = api_run_detail.to_dict()["run"]
                 if project and project != "*":
                     run_project = self.resolve_project_from_pipeline(run)
                     if run_project != project:
-                        raise mlrun.errors.MLRunInvalidArgumentError(
+                        raise mlrun.errors.MLRunNotFoundError(
                             f"Pipeline run with id {run_id} is not of project {project}"
                         )
                 run = self._format_run(
                     db_session, run, format_, api_run_detail.to_dict()
                 )
-
+        except mlrun.errors.MLRunHTTPStatusError:
+            raise
         except Exception as exc:
             raise mlrun.errors.MLRunRuntimeError(
                 f"Failed getting kfp run: {err_to_str(exc)}"
             ) from exc
 
         return run
```

## mlrun/api/crud/runtimes/nuclio/function.py

```diff
@@ -19,18 +19,20 @@
 import nuclio
 import nuclio.utils
 import requests
 
 import mlrun
 import mlrun.api.crud.runtimes.nuclio.helpers
 import mlrun.api.schemas
+import mlrun.api.utils.builder
 import mlrun.api.utils.singletons.k8s
 import mlrun.datastore
 import mlrun.errors
 import mlrun.runtimes.function
+import mlrun.runtimes.pod
 import mlrun.utils
 from mlrun.utils import logger
 
 
 def deploy_nuclio_function(
     function: mlrun.runtimes.function.RemoteRuntime,
     auth_info: mlrun.api.schemas.AuthInfo = None,
@@ -59,14 +61,19 @@
         function_config,
         function.spec.add_templated_ingress_host_mode
         or mlrun.mlconf.httpdb.nuclio.add_templated_ingress_host_mode,
         function.spec.service_type or mlrun.mlconf.httpdb.nuclio.default_service_type,
     )
 
     try:
+        logger.info(
+            "Starting Nuclio function deployment",
+            function_name=function_name,
+            project_name=project_name,
+        )
         return nuclio.deploy.deploy_config(
             function_config,
             dashboard_url=mlrun.mlconf.nuclio_dashboard_url,
             name=function_name,
             project=project_name,
             tag=function.metadata.tag,
             verbose=function.verbose,
@@ -167,37 +174,130 @@
 def _compile_function_config(
     function: mlrun.runtimes.function.RemoteRuntime,
     client_version: str = None,
     client_python_version: str = None,
     builder_env=None,
     auth_info=None,
 ):
+    _set_function_labels(function)
+
+    # resolve env vars before compiling the nuclio spec, as we need to set them in the spec
+    env_dict, external_source_env_dict = _resolve_env_vars(function)
+
+    nuclio_spec = nuclio.ConfigSpec(
+        env=env_dict,
+        external_source_env=external_source_env_dict,
+        config=function.spec.config,
+    )
+    nuclio_spec.cmd = function.spec.build.commands or []
+
+    _resolve_and_set_build_requirements(function, nuclio_spec)
+    _resolve_and_set_nuclio_runtime(
+        function, nuclio_spec, client_version, client_python_version
+    )
+
+    project = function.metadata.project or "default"
+    tag = function.metadata.tag
+    handler = function.spec.function_handler
+
+    _set_build_params(function, nuclio_spec, builder_env, project, auth_info)
+    _set_function_scheduling_params(function, nuclio_spec)
+    _set_function_replicas(function, nuclio_spec)
+    _set_misc_specs(function, nuclio_spec)
+
+    # if the user code is given explicitly or from a source, we need to set the handler and relevant attributes
+    if (
+        function.spec.base_spec
+        or function.spec.build.functionSourceCode
+        or function.spec.build.source
+        or function.kind == mlrun.runtimes.RuntimeKinds.serving  # serving can be empty
+    ):
+        config = function.spec.base_spec
+        if not config:
+            # if base_spec was not set (when not using code_to_function) and we have base64 code
+            # we create the base spec with essential attributes
+            config = nuclio.config.new_config()
+            mlrun.utils.update_in(config, "spec.handler", handler or "main:handler")
+
+        config = nuclio.config.extend_config(
+            config, nuclio_spec, tag, function.spec.build.code_origin
+        )
+
+        if (
+            function.kind == mlrun.runtimes.RuntimeKinds.serving
+            and not mlrun.utils.get_in(config, "spec.build.functionSourceCode")
+        ):
+            _set_source_code_and_handler(function, config)
+    else:
+        # this may also be called in case of using single file code_to_function(embed_code=False)
+        # this option need to be removed or be limited to using remote files (this code runs in server)
+        function_name, config, code = nuclio.build_file(
+            function.spec.source,
+            name=function.metadata.name,
+            project=project,
+            handler=handler,
+            tag=tag,
+            spec=nuclio_spec,
+            kind=function.spec.function_kind,
+            verbose=function.verbose,
+        )
+
+    mlrun.utils.update_in(
+        config, "spec.volumes", function.spec.generate_nuclio_volumes()
+    )
+
+    _resolve_and_set_base_image(function, config, client_version, client_python_version)
+    function_name = _set_function_name(function, config, project, tag)
+
+    return function_name, project, config
+
+
+def _set_function_labels(function):
     labels = function.metadata.labels or {}
     labels.update({"mlrun/class": function.kind})
     for key, value in labels.items():
         # Adding escaping to the key to prevent it from being split by dots if it contains any
         function.set_config(f"metadata.labels.\\{key}\\", value)
 
+
+def _resolve_env_vars(function):
     # Add secret configurations to function's pod spec, if secret sources were added.
     # Needs to be here, since it adds env params, which are handled in the next lines.
     # This only needs to run if we're running within k8s context. If running in Docker, for example, skip.
     if mlrun.api.utils.singletons.k8s.get_k8s_helper(
         silent=True
     ).is_running_inside_kubernetes_cluster():
         function.add_secrets_config_to_spec()
 
     env_dict, external_source_env_dict = function._get_nuclio_config_spec_env()
 
+    # In nuclio 1.6.0<=v<1.8.0, python runtimes default behavior was to not decode event strings
+    # Our code is counting on the strings to be decoded, so add the needed env var for those versions
+    if (
+        mlrun.api.crud.runtimes.nuclio.helpers.is_nuclio_version_in_range(
+            "1.6.0", "1.8.0"
+        )
+        and "NUCLIO_PYTHON_DECODE_EVENT_STRINGS" not in env_dict
+    ):
+        env_dict["NUCLIO_PYTHON_DECODE_EVENT_STRINGS"] = "true"
+
+    return env_dict, external_source_env_dict
+
+
+def _resolve_and_set_nuclio_runtime(
+    function, nuclio_spec, client_version, client_python_version
+):
     nuclio_runtime = (
         function.spec.nuclio_runtime
         or mlrun.api.crud.runtimes.nuclio.helpers.resolve_nuclio_runtime_python_image(
             mlrun_client_version=client_version, python_version=client_python_version
         )
     )
 
+    # For backwards compatibility, we need to adjust the runtime for old Nuclio versions
     if mlrun.api.crud.runtimes.nuclio.helpers.is_nuclio_version_in_range(
         "0.0.0", "1.6.0"
     ) and nuclio_runtime in [
         "python:3.7",
         "python:3.8",
     ]:
         nuclio_runtime_set_from_spec = nuclio_runtime == function.spec.nuclio_runtime
@@ -205,31 +305,18 @@
             raise mlrun.errors.MLRunInvalidArgumentError(
                 f"Nuclio version does not support the configured runtime: {nuclio_runtime}"
             )
         else:
             # our default is python:3.9, simply set it to python:3.6 to keep supporting envs with old Nuclio
             nuclio_runtime = "python:3.6"
 
-    # In nuclio 1.6.0<=v<1.8.0, python runtimes default behavior was to not decode event strings
-    # Our code is counting on the strings to be decoded, so add the needed env var for those versions
-    if (
-        mlrun.api.crud.runtimes.nuclio.helpers.is_nuclio_version_in_range(
-            "1.6.0", "1.8.0"
-        )
-        and "NUCLIO_PYTHON_DECODE_EVENT_STRINGS" not in env_dict
-    ):
-        env_dict["NUCLIO_PYTHON_DECODE_EVENT_STRINGS"] = "true"
+    nuclio_spec.set_config("spec.runtime", nuclio_runtime)
 
-    nuclio_spec = nuclio.ConfigSpec(
-        env=env_dict,
-        external_source_env=external_source_env_dict,
-        config=function.spec.config,
-    )
-    nuclio_spec.cmd = function.spec.build.commands or []
 
+def _resolve_and_set_build_requirements(function, nuclio_spec):
     if function.spec.build.requirements:
         resolved_requirements = []
         # wrap in single quote to ensure that the requirement is treated as a single string
         # quote the requirement to avoid issues with special characters, double quotes, etc.
         for requirement in function.spec.build.requirements:
             # -r / --requirement are flags and should not be escaped
             # we allow such flags (could be passed within the requirements.txt file) and do not
@@ -240,38 +327,26 @@
                     requirement = requirement[len(req_flag) :].strip()
                     resolved_requirements.append(req_flag)
                     break
 
             resolved_requirements.append(shlex.quote(requirement))
 
         encoded_requirements = " ".join(resolved_requirements)
-        nuclio_spec.cmd.append(f"python -m pip install {encoded_requirements}")
+        nuclio_spec.cmd.append(
+            f"python -m pip install --upgrade {encoded_requirements}"
+        )
 
-    project = function.metadata.project or "default"
-    tag = function.metadata.tag
-    handler = function.spec.function_handler
 
+def _set_build_params(function, nuclio_spec, builder_env, project, auth_info=None):
+    # handle archive build params
     if function.spec.build.source:
         mlrun.api.crud.runtimes.nuclio.helpers.compile_nuclio_archive_config(
             nuclio_spec, function, builder_env, project, auth_info=auth_info
         )
 
-    nuclio_spec.set_config("spec.runtime", nuclio_runtime)
-
-    # In Nuclio >= 1.6.x default serviceType has changed to "ClusterIP".
-    nuclio_spec.set_config(
-        "spec.serviceType",
-        function.spec.service_type or mlrun.mlconf.httpdb.nuclio.default_service_type,
-    )
-    if function.spec.readiness_timeout:
-        nuclio_spec.set_config(
-            "spec.readinessTimeoutSeconds", function.spec.readiness_timeout
-        )
-    if function.spec.resources:
-        nuclio_spec.set_config("spec.resources", function.spec.resources)
     if function.spec.no_cache:
         nuclio_spec.set_config("spec.build.noCache", True)
     if function.spec.build.functionSourceCode:
         nuclio_spec.set_config(
             "spec.build.functionSourceCode", function.spec.build.functionSourceCode
         )
 
@@ -281,14 +356,17 @@
         )
     )
     if image_pull_secret:
         nuclio_spec.set_config("spec.imagePullSecrets", image_pull_secret)
 
     if function.spec.base_image_pull:
         nuclio_spec.set_config("spec.build.noBaseImagesPull", False)
+
+
+def _set_function_scheduling_params(function, nuclio_spec):
     # don't send node selections if nuclio is not compatible
     if mlrun.runtimes.function.validate_nuclio_version_compatibility(
         "1.5.20", "1.6.10"
     ):
         if function.spec.node_selector:
             nuclio_spec.set_config("spec.nodeSelector", function.spec.node_selector)
         if function.spec.node_name:
@@ -312,145 +390,113 @@
     if mlrun.runtimes.function.validate_nuclio_version_compatibility("1.8.6"):
         if function.spec.preemption_mode:
             nuclio_spec.set_config(
                 "spec.PreemptionMode",
                 function.spec.preemption_mode,
             )
 
-    # don't send default or any priority class name if nuclio is not compatible
-    if (
-        function.spec.priority_class_name
-        and mlrun.runtimes.function.validate_nuclio_version_compatibility("1.6.18")
-        and len(mlrun.mlconf.get_valid_function_priority_class_names())
-    ):
-        nuclio_spec.set_config(
-            "spec.priorityClassName", function.spec.priority_class_name
-        )
 
+def _set_function_replicas(function, nuclio_spec):
     if function.spec.replicas:
-
         nuclio_spec.set_config(
             "spec.minReplicas",
             mlrun.utils.as_number("spec.Replicas", function.spec.replicas),
         )
         nuclio_spec.set_config(
             "spec.maxReplicas",
             mlrun.utils.as_number("spec.Replicas", function.spec.replicas),
         )
-
     else:
         nuclio_spec.set_config(
             "spec.minReplicas",
             mlrun.utils.as_number("spec.minReplicas", function.spec.min_replicas),
         )
         nuclio_spec.set_config(
             "spec.maxReplicas",
             mlrun.utils.as_number("spec.maxReplicas", function.spec.max_replicas),
         )
 
+
+def _set_misc_specs(function, nuclio_spec):
+    # in Nuclio >= 1.6.x default serviceType has changed to "ClusterIP".
+    nuclio_spec.set_config(
+        "spec.serviceType",
+        function.spec.service_type or mlrun.mlconf.httpdb.nuclio.default_service_type,
+    )
+    if function.spec.readiness_timeout:
+        nuclio_spec.set_config(
+            "spec.readinessTimeoutSeconds", function.spec.readiness_timeout
+        )
+    if function.spec.resources:
+        nuclio_spec.set_config("spec.resources", function.spec.resources)
+
+    # don't send default or any priority class name if nuclio is not compatible
+    if (
+        function.spec.priority_class_name
+        and mlrun.runtimes.function.validate_nuclio_version_compatibility("1.6.18")
+        and len(mlrun.mlconf.get_valid_function_priority_class_names())
+    ):
+        nuclio_spec.set_config(
+            "spec.priorityClassName", function.spec.priority_class_name
+        )
+
     if function.spec.service_account:
         nuclio_spec.set_config("spec.serviceAccount", function.spec.service_account)
 
     if function.spec.security_context:
         nuclio_spec.set_config(
             "spec.securityContext",
             mlrun.runtimes.pod.get_sanitized_attribute(
                 function.spec, "security_context"
             ),
         )
 
-    if (
-        function.spec.base_spec
-        or function.spec.build.functionSourceCode
-        or function.spec.build.source
-        or function.kind == mlrun.runtimes.RuntimeKinds.serving  # serving can be empty
-    ):
-        config = function.spec.base_spec
-        if not config:
-            # if base_spec was not set (when not using code_to_function) and we have base64 code
-            # we create the base spec with essential attributes
-            config = nuclio.config.new_config()
-            mlrun.utils.update_in(config, "spec.handler", handler or "main:handler")
 
-        config = nuclio.config.extend_config(
-            config, nuclio_spec, tag, function.spec.build.code_origin
+def _set_source_code_and_handler(function, config):
+    if not function.spec.build.source:
+        # set the source to the mlrun serving wrapper
+        body = nuclio.build.mlrun_footer.format(mlrun.runtimes.serving.serving_subkind)
+        mlrun.utils.update_in(
+            config,
+            "spec.build.functionSourceCode",
+            base64.b64encode(body.encode("utf-8")).decode("utf-8"),
         )
-
-        mlrun.utils.update_in(config, "metadata.name", function.metadata.name)
+    elif not function.spec.function_handler:
+        # point the nuclio function handler to mlrun serving wrapper handlers
         mlrun.utils.update_in(
-            config, "spec.volumes", function.spec.generate_nuclio_volumes()
+            config,
+            "spec.handler",
+            "mlrun.serving.serving_wrapper:handler",
         )
-        base_image = (
-            mlrun.utils.get_in(config, "spec.build.baseImage")
-            or function.spec.image
-            or function.spec.build.base_image
-        )
-        if base_image:
-            mlrun.utils.update_in(
-                config,
-                "spec.build.baseImage",
-                mlrun.utils.enrich_image_url(
-                    base_image, client_version, client_python_version
-                ),
-            )
 
-        logger.info("deploy started")
-        name = mlrun.runtimes.function.get_fullname(
-            function.metadata.name, project, tag
-        )
-        function.status.nuclio_name = name
-        mlrun.utils.update_in(config, "metadata.name", name)
 
-        if (
-            function.kind == mlrun.runtimes.RuntimeKinds.serving
-            and not mlrun.utils.get_in(config, "spec.build.functionSourceCode")
-        ):
-            if not function.spec.build.source:
-                # set the source to the mlrun serving wrapper
-                body = nuclio.build.mlrun_footer.format(
-                    mlrun.runtimes.serving.serving_subkind
-                )
-                mlrun.utils.update_in(
-                    config,
-                    "spec.build.functionSourceCode",
-                    base64.b64encode(body.encode("utf-8")).decode("utf-8"),
-                )
-            elif not function.spec.function_handler:
-                # point the nuclio function handler to mlrun serving wrapper handlers
-                mlrun.utils.update_in(
-                    config,
-                    "spec.handler",
-                    "mlrun.serving.serving_wrapper:handler",
-                )
-    else:
-        # this may also be called in case of using single file code_to_function(embed_code=False)
-        # this option need to be removed or be limited to using remote files (this code runs in server)
-        name, config, code = nuclio.build_file(
-            function.spec.source,
-            name=function.metadata.name,
-            project=project,
-            handler=handler,
-            tag=tag,
-            spec=nuclio_spec,
-            kind=function.spec.function_kind,
-            verbose=function.verbose,
+def _resolve_and_set_base_image(
+    function, config, client_version, client_python_version
+):
+    base_image = (
+        mlrun.utils.get_in(config, "spec.build.baseImage")
+        or function.spec.image
+        or function.spec.build.base_image
+    )
+    if base_image:
+        # we ignore the returned registry secret as nuclio uses the image pull secret, which is resolved in the
+        # build params
+        (
+            base_image,
+            _,
+        ) = mlrun.api.utils.builder.resolve_image_target_and_registry_secret(
+            base_image, secret_name=function.spec.build.secret
         )
-
         mlrun.utils.update_in(
-            config, "spec.volumes", function.spec.generate_nuclio_volumes()
+            config,
+            "spec.build.baseImage",
+            mlrun.utils.enrich_image_url(
+                base_image, client_version, client_python_version
+            ),
         )
-        base_image = function.spec.image or function.spec.build.base_image
-        if base_image:
-            mlrun.utils.update_in(
-                config,
-                "spec.build.baseImage",
-                mlrun.utils.enrich_image_url(
-                    base_image, client_version, client_python_version
-                ),
-            )
-
-        name = mlrun.runtimes.function.get_fullname(name, project, tag)
-        function.status.nuclio_name = name
 
-        mlrun.utils.update_in(config, "metadata.name", name)
 
-    return name, project, config
+def _set_function_name(function, config, project, tag):
+    name = mlrun.runtimes.function.get_fullname(function.metadata.name, project, tag)
+    function.status.nuclio_name = name
+    mlrun.utils.update_in(config, "metadata.name", name)
+    return name
```

## mlrun/api/db/sqldb/db.py

```diff
@@ -984,15 +984,39 @@
         labels = get_in(function, "metadata.labels", {})
         update_labels(fn, labels)
         fn.struct = function
         self._upsert(session, [fn])
         self.tag_objects_v2(session, [fn], project, tag)
         return hash_key
 
-    def get_function(self, session, name, project="", tag="", hash_key=""):
+    def get_function(self, session, name, project="", tag="", hash_key="") -> dict:
+        """
+        In version 1.4.0 we added a normalization to the function name before storing.
+        To be backwards compatible and allow users to query old non-normalized functions,
+        we're providing a fallback to get_function:
+        normalize the requested name and try to retrieve it from the database.
+        If no answer is received, we will check to see if the original name contained underscores,
+        if so, the retrieval will be repeated and the result (if it exists) returned.
+        """
+        normalized_function_name = mlrun.utils.normalize_name(name)
+        try:
+            return self._get_function(
+                session, normalized_function_name, project, tag, hash_key
+            )
+        except mlrun.errors.MLRunNotFoundError as exc:
+            if "_" in name:
+                logger.warning(
+                    "Failed to get underscore-named function, trying without normalization",
+                    function_name=name,
+                )
+                return self._get_function(session, name, project, tag, hash_key)
+            else:
+                raise exc
+
+    def _get_function(self, session, name, project="", tag="", hash_key=""):
         project = project or config.default_project
         query = self._query(session, Function, name=name, project=project)
         computed_tag = tag or "latest"
         tag_function_uid = None
         if not tag and hash_key:
             uid = hash_key
         else:
@@ -1028,14 +1052,15 @@
             raise mlrun.errors.MLRunNotFoundError(f"Function not found {function_uri}")
 
     def delete_function(self, session: Session, project: str, name: str):
         logger.debug("Removing function from db", project=project, name=name)
 
         # deleting tags and labels, because in sqlite the relationships aren't necessarily cascading
         self._delete_function_tags(session, project, name, commit=False)
+        self._delete_function_schedules(session, project, name)
         self._delete_class_labels(
             session, Function, project=project, name=name, commit=False
         )
         self._delete(session, Function, project=project, name=name)
 
     def _delete_functions(self, session: Session, project: str):
         for function_name in self._list_project_function_names(session, project):
@@ -1112,14 +1137,24 @@
             Function.Tag.project == project, Function.Tag.obj_name == function_name
         )
         for obj in query:
             session.delete(obj)
         if commit:
             session.commit()
 
+    def _delete_function_schedules(self, session, project, function_name, commit=True):
+        try:
+            self.delete_schedule(session=session, project=project, name=function_name)
+        except mlrun.errors.MLRunNotFoundError:
+            logger.info(
+                "No schedules were found for function",
+                project=project,
+                function=function_name,
+            )
+
     def _list_function_tags(self, session, project, function_id):
         query = (
             session.query(Function.Tag.name)
             .filter(Function.Tag.project == project, Function.Tag.obj_id == function_id)
             .distinct()
         )
         return [row[0] for row in query]
```

## mlrun/api/utils/builder.py

```diff
@@ -22,21 +22,16 @@
 from kubernetes import client
 
 import mlrun.api.utils.singletons.k8s
 import mlrun.common.constants
 import mlrun.common.schemas
 import mlrun.errors
 import mlrun.runtimes.utils
+import mlrun.utils
 from mlrun.config import config
-from mlrun.utils import (
-    enrich_image_url,
-    get_parsed_docker_registry,
-    logger,
-    normalize_name,
-)
 
 
 def make_dockerfile(
     base_image: str,
     commands: list = None,
     source: str = None,
     requirements_path: str = None,
@@ -79,18 +74,18 @@
         dock += f"ENV PYTHONPATH {workdir}\n"
     if commands:
         dock += "".join([f"RUN {command}\n" for command in commands])
     if requirements_path:
         dock += (
             f"RUN echo 'Installing {requirements_path}...'; cat {requirements_path}\n"
         )
-        dock += f"RUN python -m pip install -r {requirements_path}\n"
+        dock += f"RUN python -m pip install --upgrade -r {requirements_path}\n"
     if extra:
         dock += extra
-    logger.debug("Resolved dockerfile", dockfile_contents=dock)
+    mlrun.utils.logger.debug("Resolved dockerfile", dockfile_contents=dock)
     return dock
 
 
 def make_kaniko_pod(
     project: str,
     context,
     dest,
@@ -325,15 +320,15 @@
     verbose=False,
     builder_env=None,
     client_version=None,
     runtime=None,
 ):
     runtime_spec = runtime.spec if runtime else None
     builder_env = builder_env or {}
-    image_target, secret_name = _resolve_image_target_and_registry_secret(
+    image_target, secret_name = resolve_image_target_and_registry_secret(
         image_target, registry, secret_name
     )
     if requirements and isinstance(requirements, list):
         requirements_list = requirements
         requirements_path = "/empty/requirements.txt"
     else:
         requirements_list = None
@@ -349,15 +344,15 @@
         mlrun_command = resolve_mlrun_install_command(
             mlrun_version_specifier, client_version, commands
         )
         if mlrun_command:
             commands.append(mlrun_command)
 
     if not inline_code and not source and not commands and not requirements:
-        logger.info("skipping build, nothing to add")
+        mlrun.utils.logger.info("skipping build, nothing to add")
         return "skipped"
 
     context = "/context"
     to_mount = False
     is_v3io_source = False
     if source:
         is_v3io_source = source.startswith("v3io://") or source.startswith("v3ios://")
@@ -475,15 +470,17 @@
     k8s = mlrun.api.utils.singletons.k8s.get_k8s_helper(silent=False)
     kpod.namespace = k8s.resolve_namespace(namespace)
 
     if interactive:
         return k8s.run_job(kpod)
     else:
         pod, ns = k8s.create_pod(kpod)
-        logger.info(f'started build, to watch build logs use "mlrun watch {pod} {ns}"')
+        mlrun.utils.logger.info(
+            "Build started", pod=pod, namespace=ns, project=project, image=image_target
+        )
         return f"build:{pod}"
 
 
 def get_kaniko_spec_attributes_from_runtime():
     """get the names of Kaniko spec attributes that are defined for runtime but should also be applied to kaniko"""
     return [
         "node_name",
@@ -593,25 +590,31 @@
     inline = None  # noqa: F841
     if build.functionSourceCode:
         inline = b64decode(build.functionSourceCode).decode("utf-8")  # noqa: F841
     if not build.image:
         raise mlrun.errors.MLRunInvalidArgumentError(
             "build spec must have a target image, set build.image = <target image>"
         )
-    logger.info(f"building image ({build.image})")
+    name = mlrun.utils.normalize_name(f"mlrun-build-{runtime.metadata.name}")
 
-    name = normalize_name(f"mlrun-build-{runtime.metadata.name}")
     base_image: str = (
         build.base_image or runtime.spec.image or config.default_base_image
     )
-    enriched_base_image = enrich_image_url(
+    enriched_base_image = mlrun.utils.enrich_image_url(
         base_image,
         client_version,
         client_python_version,
     )
+    mlrun.utils.logger.info(
+        "Building runtime image",
+        base_image=enriched_base_image,
+        image=build.image,
+        project=project,
+        name=name,
+    )
 
     status = build_image(
         auth_info,
         project,
         image_target=build.image,
         base_image=enriched_base_image,
         commands=build.commands,
@@ -642,44 +645,26 @@
         runtime.status.build_pod = status[6:]
         # using the base_image, and not the enriched one so we won't have the client version in the image, useful for
         # exports and other cases where we don't want to have the client version in the image, but rather enriched on
         # API level
         runtime.spec.build.base_image = base_image
         return False
 
-    logger.info(f"build completed with {status}")
+    mlrun.utils.logger.info(f"build completed with {status}")
     if status in ["failed", "error"]:
         runtime.status.state = mlrun.common.schemas.FunctionState.error
         return False
 
     local = "" if build.secret or build.image.startswith(".") else "."
     runtime.spec.image = local + build.image
     runtime.status.state = mlrun.common.schemas.FunctionState.ready
     return True
 
 
-def _generate_builder_env(project, builder_env):
-    k8s = mlrun.api.utils.singletons.k8s.get_k8s_helper(silent=False)
-    secret_name = k8s.get_project_secret_name(project)
-    existing_secret_keys = k8s.get_project_secret_keys(project, filter_internal=True)
-
-    # generate env list from builder env and project secrets
-    env = []
-    for key in existing_secret_keys:
-        if key not in builder_env:
-            value_from = client.V1EnvVarSource(
-                secret_key_ref=client.V1SecretKeySelector(name=secret_name, key=key)
-            )
-            env.append(client.V1EnvVar(name=key, value_from=value_from))
-    for key, value in builder_env.items():
-        env.append(client.V1EnvVar(name=key, value=value))
-    return env
-
-
-def _resolve_image_target_and_registry_secret(
+def resolve_image_target_and_registry_secret(
     image_target: str, registry: str = None, secret_name: str = None
 ) -> (str, str):
     if registry:
         return "/".join([registry, image_target]), secret_name
 
     # if dest starts with a dot, we add the configured registry to the start of the dest
     if image_target.startswith(
@@ -687,21 +672,39 @@
     ):
 
         # remove prefix from image name
         image_target = image_target[
             len(mlrun.common.constants.IMAGE_NAME_ENRICH_REGISTRY_PREFIX) :
         ]
 
-        registry, repository = get_parsed_docker_registry()
+        registry, repository = mlrun.utils.get_parsed_docker_registry()
         secret_name = secret_name or config.httpdb.builder.docker_registry_secret
         if not registry:
             raise ValueError(
                 "Default docker registry is not defined, set "
                 "MLRUN_HTTPDB__BUILDER__DOCKER_REGISTRY/MLRUN_HTTPDB__BUILDER__DOCKER_REGISTRY_SECRET env vars"
             )
         image_target_components = [registry, image_target]
         if repository and repository not in image_target:
             image_target_components = [registry, repository, image_target]
 
         return "/".join(image_target_components), secret_name
 
     return image_target, secret_name
+
+
+def _generate_builder_env(project, builder_env):
+    k8s = mlrun.api.utils.singletons.k8s.get_k8s_helper(silent=False)
+    secret_name = k8s.get_project_secret_name(project)
+    existing_secret_keys = k8s.get_project_secret_keys(project, filter_internal=True)
+
+    # generate env list from builder env and project secrets
+    env = []
+    for key in existing_secret_keys:
+        if key not in builder_env:
+            value_from = client.V1EnvVarSource(
+                secret_key_ref=client.V1SecretKeySelector(name=secret_name, key=key)
+            )
+            env.append(client.V1EnvVar(name=key, value_from=value_from))
+    for key, value in builder_env.items():
+        env.append(client.V1EnvVar(name=key, value=value))
+    return env
```

## mlrun/api/utils/clients/log_collector.py

```diff
@@ -148,14 +148,19 @@
         :return: The logs bytes
         """
 
         # check if this run has logs to collect
         try:
             has_logs = await self.has_logs(run_uid, project, verbose, raise_on_error)
             if not has_logs:
+                logger.debug(
+                    "Run has no logs to collect",
+                    run_uid=run_uid,
+                    project=project,
+                )
 
                 # run has no logs - return empty logs and exit so caller won't wait for logs or retry
                 yield b""
                 return
         except mlrun.errors.MLRunInternalServerError as exc:
             logger.warning(
                 "Failed to check if run has logs to collect", run_uid=run_uid
```

## mlrun/launcher/base.py

```diff
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import abc
 import ast
 import copy
 import os
 import uuid
-from typing import Any, Dict, List, Optional, Union
+from typing import Any, Callable, Dict, List, Optional, Union
 
 import mlrun.common.schemas
 import mlrun.config
 import mlrun.errors
 import mlrun.kfpops
 import mlrun.lists
 import mlrun.model
@@ -72,16 +72,18 @@
         )
         hash_key = hash_key if versioned else None
         return "db://" + runtime._function_uri(hash_key=hash_key, tag=tag)
 
     def launch(
         self,
         runtime: "mlrun.runtimes.BaseRuntime",
-        task: Optional[Union["mlrun.run.RunTemplate", "mlrun.run.RunObject"]] = None,
-        handler: Optional[str] = None,
+        task: Optional[
+            Union["mlrun.run.RunTemplate", "mlrun.run.RunObject", dict]
+        ] = None,
+        handler: Optional[Union[str, Callable]] = None,
         name: Optional[str] = "",
         project: Optional[str] = "",
         params: Optional[dict] = None,
         inputs: Optional[Dict[str, str]] = None,
         out_path: Optional[str] = "",
         workdir: Optional[str] = "",
         artifact_path: Optional[str] = "",
@@ -180,14 +182,17 @@
             )
 
         if isinstance(task, mlrun.run.RunTemplate):
             return mlrun.run.RunObject.from_template(task)
         elif isinstance(task, dict):
             return mlrun.run.RunObject.from_dict(task)
 
+        # task is already a RunObject
+        return task
+
     def _enrich_run(
         self,
         runtime,
         run,
         handler=None,
         project_name=None,
         name=None,
@@ -202,14 +207,16 @@
         artifact_path=None,
         workdir=None,
         notifications: List[mlrun.model.Notification] = None,
     ):
         run.spec.handler = (
             handler or run.spec.handler or runtime.spec.default_handler or ""
         )
+        # callable handlers are valid for handler and dask runtimes,
+        # for other runtimes we need to convert the handler to a string
         if run.spec.handler and runtime.kind not in ["handler", "dask"]:
             run.spec.handler = run.spec.handler_name
 
         def_name = runtime.metadata.name
         if run.spec.handler_name:
             short_name = run.spec.handler_name
             for separator in ["#", "::", "."]:
```

## mlrun/launcher/local.py

```diff
@@ -9,15 +9,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import os
 import pathlib
-from typing import Dict, List, Optional, Union
+from typing import Callable, Dict, List, Optional, Union
 
 import mlrun.common.schemas.schedule
 import mlrun.errors
 import mlrun.launcher.client
 import mlrun.run
 import mlrun.runtimes.generators
 import mlrun.utils.clones
@@ -39,16 +39,18 @@
         """
         super().__init__()
         self._is_run_local = local
 
     def launch(
         self,
         runtime: "mlrun.runtimes.BaseRuntime",
-        task: Optional[Union["mlrun.run.RunTemplate", "mlrun.run.RunObject"]] = None,
-        handler: Optional[str] = None,
+        task: Optional[
+            Union["mlrun.run.RunTemplate", "mlrun.run.RunObject", dict]
+        ] = None,
+        handler: Optional[Union[str, Callable]] = None,
         name: Optional[str] = "",
         project: Optional[str] = "",
         params: Optional[dict] = None,
         inputs: Optional[Dict[str, str]] = None,
         out_path: Optional[str] = "",
         workdir: Optional[str] = "",
         artifact_path: Optional[str] = "",
@@ -129,21 +131,23 @@
         runtime: "mlrun.runtimes.BaseRuntime",
         run: Optional[Union["mlrun.run.RunTemplate", "mlrun.run.RunObject"]] = None,
     ):
 
         if "V3IO_USERNAME" in os.environ and "v3io_user" not in run.metadata.labels:
             run.metadata.labels["v3io_user"] = os.environ.get("V3IO_USERNAME")
 
-        logger.info(
-            "Storing function",
-            name=run.metadata.name,
-            uid=run.metadata.uid,
-            db=runtime.spec.rundb,
-        )
-        self._store_function(runtime, run)
+        # store function object in db unless running from within a run pod
+        if not runtime.is_child:
+            logger.info(
+                "Storing function",
+                name=run.metadata.name,
+                uid=run.metadata.uid,
+                db=runtime.spec.rundb,
+            )
+            self._store_function(runtime, run)
 
         execution = mlrun.run.MLClientCtx.from_dict(
             run.to_dict(),
             runtime._get_db(),
             autocommit=False,
             is_api=False,
             store_run=False,
```

## mlrun/launcher/remote.py

```diff
@@ -28,15 +28,17 @@
 from mlrun.utils import logger
 
 
 class ClientRemoteLauncher(mlrun.launcher.client.ClientBaseLauncher):
     def launch(
         self,
         runtime: "mlrun.runtimes.KubejobRuntime",
-        task: Optional[Union["mlrun.run.RunTemplate", "mlrun.run.RunObject"]] = None,
+        task: Optional[
+            Union["mlrun.run.RunTemplate", "mlrun.run.RunObject", dict]
+        ] = None,
         handler: Optional[str] = None,
         name: Optional[str] = "",
         project: Optional[str] = "",
         params: Optional[dict] = None,
         inputs: Optional[Dict[str, str]] = None,
         out_path: Optional[str] = "",
         workdir: Optional[str] = "",
```

## mlrun/model_monitoring/stream_processing_fs.py

```diff
@@ -403,15 +403,14 @@
         average latency and the number of predictions (per 5min and 1hour).
 
         :returns: A filtered event as a dictionary which will be written to the endpoint table in the next step.
         """
         super().__init__(**kwargs)
 
     def do(self, event):
-
         # Compute prediction per second
         event[EventLiveStats.PREDICTIONS_PER_SECOND] = (
             float(event[EventLiveStats.PREDICTIONS_COUNT_5M]) / 300
         )
         # Filter relevant keys
         e = {
             k: event[k]
@@ -461,15 +460,14 @@
 
         :returns: Dictionary of 2-3 dictionaries that contains stats and details about the events.
 
         """
         super().__init__(**kwargs)
 
     def do(self, event):
-
         # Compute prediction per second
         event[EventLiveStats.PREDICTIONS_PER_SECOND] = (
             float(event[EventLiveStats.PREDICTIONS_COUNT_5M]) / 300
         )
         base_fields = [
             EventFieldType.TIMESTAMP,
             EventFieldType.ENDPOINT_ID,
@@ -531,15 +529,14 @@
 
         :returns: Event dictionary with filtered data for the Parquet target.
 
         """
         super().__init__(**kwargs)
 
     def do(self, event):
-
         logger.info("ProcessBeforeParquet1", event=event)
         # Remove the following keys from the event
         for key in [
             EventFieldType.FEATURES,
             EventFieldType.NAMED_FEATURES,
         ]:
             event.pop(key, None)
@@ -617,18 +614,20 @@
 
         event[EventFieldType.VERSIONED_MODEL] = versioned_model
         event[EventFieldType.ENDPOINT_ID] = endpoint_id
 
         # In case this process fails, resume state from existing record
         self.resume_state(endpoint_id)
 
-        # Handle errors coming from stream
-        found_errors = self.handle_errors(endpoint_id, event)
-        if found_errors:
-            return None
+        # If error key has been found in the current event,
+        # increase the error counter by 1 and raise the error description
+        error = event.get("error")
+        if error:
+            self.error_count[endpoint_id] += 1
+            raise mlrun.errors.MLRunInvalidArgumentError(str(error))
 
         # Validate event fields
         model_class = event.get("model_class") or event.get("class")
         timestamp = event.get("when")
         request_id = event.get("request", {}).get("id") or event.get("resp", {}).get(
             "id"
         )
@@ -741,15 +740,14 @@
         :raise MLRunPreconditionFailedError: If the request time of the current is later than the previous request time.
         """
 
         if (
             endpoint_id in self.last_request
             and self.last_request[endpoint_id] > timestamp
         ):
-
             logger.error(
                 f"current event request time {timestamp} is earlier than the last request time "
                 f"{self.last_request[endpoint_id]} - write to TSDB will be rejected"
             )
 
     @staticmethod
     def is_list_of_numerics(
@@ -763,15 +761,14 @@
         )
         return False
 
     def resume_state(self, endpoint_id):
         # Make sure process is resumable, if process fails for any reason, be able to pick things up close to where we
         # left them
         if endpoint_id not in self.endpoints:
-
             logger.info("Trying to resume state", endpoint_id=endpoint_id)
             endpoint_record = get_endpoint_record(
                 project=self.project,
                 endpoint_id=endpoint_id,
             )
 
             # If model endpoint found, get first_request, last_request and error_count values
@@ -779,15 +776,14 @@
                 first_request = endpoint_record.get(EventFieldType.FIRST_REQUEST)
 
                 if first_request:
                     self.first_request[endpoint_id] = first_request
 
                 last_request = endpoint_record.get(EventFieldType.LAST_REQUEST)
                 if last_request:
-
                     self.last_request[endpoint_id] = last_request
 
                 error_count = endpoint_record.get(EventFieldType.ERROR_COUNT)
 
                 if error_count:
                     self.error_count[endpoint_id] = int(error_count)
 
@@ -802,21 +798,14 @@
         dict_path: typing.List[str],
     ):
         if validation_function(field, dict_path):
             return True
         self.error_count[endpoint_id] += 1
         return False
 
-    def handle_errors(self, endpoint_id, event) -> bool:
-        if "error" in event:
-            self.error_count[endpoint_id] += 1
-            return True
-
-        return False
-
 
 def is_not_none(field: typing.Any, dict_path: typing.List[str]):
     if field is not None:
         return True
     logger.error(
         f"Expected event field is missing: {field} [Event -> {','.join(dict_path)}]"
     )
@@ -1061,15 +1050,14 @@
         super().__init__(**kwargs)
         self.container = container
         self.v3io_framesd = v3io_framesd
         self.table = table
         self.keys = set()
 
     def do(self, event: typing.Dict):
-
         key_set = set(event.keys())
         if not key_set.issubset(self.keys):
             self.keys.update(key_set)
             # Apply infer_schema on the kv table for generating the schema file
             mlrun.utils.v3io_clients.get_frames_client(
                 container=self.container,
                 address=self.v3io_framesd,
```

## mlrun/projects/operations.py

```diff
@@ -232,29 +232,31 @@
     with_mlrun: bool = None,
     skip_deployed: bool = False,
     image=None,
     base_image=None,
     commands: list = None,
     secret_name=None,
     requirements: Union[str, List[str]] = None,
+    requirements_file: str = None,
     mlrun_version_specifier=None,
     builder_env: dict = None,
     project_object=None,
     overwrite_build_params: bool = False,
 ) -> Union[BuildStatus, kfp.dsl.ContainerOp]:
     """deploy ML function, build container with its dependencies
 
     :param function:        name of the function (in the project) or function object
     :param with_mlrun:      add the current mlrun package to the container build
     :param skip_deployed:   skip the build if we already have an image for the function
     :param image:           target image name/path
     :param base_image:      base image name/path (commands and source code will be added to it)
     :param commands:        list of docker build (RUN) commands e.g. ['pip install pandas']
     :param secret_name:     k8s secret for accessing the docker registry
-    :param requirements:    list of python packages or pip requirements file path, defaults to None
+    :param requirements:    list of python packages, defaults to None
+    :param requirements_file:    pip requirements file path, defaults to None
     :param mlrun_version_specifier:  which mlrun package version to include (if not current)
     :param builder_env:     Kaniko builder pod env vars dict (for config/credentials)
                             e.g. builder_env={"GIT_TOKEN": token}, does not work yet in KFP
     :param project_object:  override the project object to use, will default to the project set in the runtime context.
     :param builder_env:     Kaniko builder pod env vars dict (for config/credentials)
                             e.g. builder_env={"GIT_TOKEN": token}, does not work yet in KFP
     :param overwrite_build_params:  overwrite the function build parameters with the provided ones, or attempt to add
@@ -265,15 +267,15 @@
         raise mlrun.errors.MLRunInvalidArgumentError(
             "cannot build use deploy_function()"
         )
     if engine == "kfp":
         if overwrite_build_params:
             function.spec.build.commands = None
         if requirements:
-            function.with_requirements(requirements)
+            function.with_requirements(requirements, requirements_file)
         if commands:
             function.with_commands(commands)
         return function.deploy_step(
             image=image,
             base_image=base_image,
             commands=commands,
             secret_name=secret_name,
```

## mlrun/projects/project.py

```diff
@@ -10,14 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import datetime
 import getpass
 import glob
+import http
 import json
 import pathlib
 import shutil
 import tempfile
 import typing
 import uuid
 import warnings
@@ -27,14 +28,15 @@
 
 import dotenv
 import git
 import git.exc
 import inflection
 import kfp
 import nuclio
+import requests
 import yaml
 
 import mlrun.common.model_monitoring as model_monitoring_constants
 import mlrun.common.schemas
 import mlrun.db
 import mlrun.errors
 import mlrun.runtimes
@@ -1656,29 +1658,56 @@
         :param sync:  will reload/reinit the function from the project spec
         :param enrich: add project info/config/source info to the function object
         :param ignore_cache: read the function object from the DB (ignore the local cache)
         :param copy_function: return a copy of the function object
 
         :returns: function object
         """
-        if key in self.spec._function_objects and not sync and not ignore_cache:
-            function = self.spec._function_objects[key]
-        elif key in self.spec._function_definitions and not ignore_cache:
-            self.sync_functions([key])
-            function = self.spec._function_objects[key]
-        else:
-            function = get_db_function(self, key)
-            self.spec._function_objects[key] = function
+        function, err = self._get_function(
+            mlrun.utils.normalize_name(key), sync, ignore_cache
+        )
+        if not function and "_" in key:
+            function, err = self._get_function(key, sync, ignore_cache)
+
+        if not function:
+            raise err
+
         if enrich:
             function = enrich_function_object(
                 self, function, copy_function=copy_function
             )
             self.spec._function_objects[key] = function
+
         return function
 
+    def _get_function(self, key, sync, ignore_cache):
+        """
+        Function can be retrieved from the project spec (cache) or from the database.
+        In sync mode, we first perform a sync of the function_objects from the function_definitions,
+        and then returning it from the function_objects (if exists).
+        When not in sync mode, we verify and return from the function objects directly.
+        In ignore_cache mode, we query the function from the database rather than from the project spec.
+        """
+        if key in self.spec._function_objects and not sync and not ignore_cache:
+            function = self.spec._function_objects[key]
+
+        elif key in self.spec._function_definitions and not ignore_cache:
+            self.sync_functions([key])
+            function = self.spec._function_objects[key]
+        else:
+            try:
+                function = get_db_function(self, key)
+                self.spec._function_objects[key] = function
+            except requests.HTTPError as exc:
+                if exc.response.status_code != http.HTTPStatus.NOT_FOUND.value:
+                    raise exc
+                return None, exc
+
+        return function, None
+
     def get_function_objects(self) -> typing.Dict[str, mlrun.runtimes.BaseRuntime]:
         """ "get a virtual dict with all the project functions ready for use in a pipeline"""
         self.sync_functions()
         return FunctionsDict(self)
 
     def get_function_names(self) -> typing.List[str]:
         """get a list of all the project function names"""
@@ -2321,40 +2350,43 @@
         base_image: str = None,
         commands: list = None,
         secret_name: str = None,
         requirements: typing.Union[str, typing.List[str]] = None,
         mlrun_version_specifier: str = None,
         builder_env: dict = None,
         overwrite_build_params: bool = False,
+        requirements_file: str = None,
     ) -> typing.Union[BuildStatus, kfp.dsl.ContainerOp]:
         """deploy ML function, build container with its dependencies
 
-        :param function:        name of the function (in the project) or function object
-        :param with_mlrun:      add the current mlrun package to the container build
-        :param skip_deployed:   skip the build if we already have an image for the function
-        :param image:           target image name/path
-        :param base_image:      base image name/path (commands and source code will be added to it)
-        :param commands:        list of docker build (RUN) commands e.g. ['pip install pandas']
-        :param secret_name:     k8s secret for accessing the docker registry
-        :param requirements:    list of python packages or pip requirements file path, defaults to None
+        :param function:            name of the function (in the project) or function object
+        :param with_mlrun:          add the current mlrun package to the container build
+        :param skip_deployed:       skip the build if we already have an image for the function
+        :param image:               target image name/path
+        :param base_image:          base image name/path (commands and source code will be added to it)
+        :param commands:            list of docker build (RUN) commands e.g. ['pip install pandas']
+        :param secret_name:         k8s secret for accessing the docker registry
+        :param requirements:        list of python packages, defaults to None
+        :param requirements_file:   pip requirements file path, defaults to None
         :param mlrun_version_specifier:  which mlrun package version to include (if not current)
-        :param builder_env:     Kaniko builder pod env vars dict (for config/credentials)
-                                e.g. builder_env={"GIT_TOKEN": token}, does not work yet in KFP
+        :param builder_env:         Kaniko builder pod env vars dict (for config/credentials)
+                                    e.g. builder_env={"GIT_TOKEN": token}, does not work yet in KFP
         :param overwrite_build_params:  overwrite the function build parameters with the provided ones, or attempt to
          add to existing parameters
         """
         return build_function(
             function,
             with_mlrun=with_mlrun,
             skip_deployed=skip_deployed,
             image=image,
             base_image=base_image,
             commands=commands,
             secret_name=secret_name,
             requirements=requirements,
+            requirements_file=requirements_file,
             mlrun_version_specifier=mlrun_version_specifier,
             builder_env=builder_env,
             project_object=self,
             overwrite_build_params=overwrite_build_params,
         )
 
     def build_config(
@@ -2363,25 +2395,27 @@
         set_as_default: bool = False,
         with_mlrun: bool = None,
         base_image: str = None,
         commands: list = None,
         secret_name: str = None,
         requirements: typing.Union[str, typing.List[str]] = None,
         overwrite_build_params: bool = False,
+        requirements_file: str = None,
     ):
         """specify builder configuration for the project
 
         :param image: target image name/path. If not specified the project's existing `default_image` name will be
             used. If not set, the `mlconf.default_project_image_name` value will be used
         :param set_as_default: set `image` to be the project's default image (default False)
         :param with_mlrun: add the current mlrun package to the container build
         :param base_image: base image name/path
         :param commands:   list of docker build (RUN) commands e.g. ['pip install pandas']
         :param secret_name:     k8s secret for accessing the docker registry
-        :param requirements: requirements.txt file to install or list of packages to install on the built image
+        :param requirements: a list of packages to install on the built image
+        :param requirements_file: requirements file to install on the built image
         :param overwrite_build_params:  overwrite existing build configuration (default False)
 
            * False: the new params are merged with the existing (currently merge is applied to requirements and
              commands)
            * True: the existing params are replaced by the new ones
         """
         default_image_name = mlrun.mlconf.default_project_image_name.format(
@@ -2392,14 +2426,15 @@
         self.spec.build.build_config(
             image=image,
             base_image=base_image,
             commands=commands,
             secret=secret_name,
             with_mlrun=with_mlrun,
             requirements=requirements,
+            requirements_file=requirements_file,
             overwrite=overwrite_build_params,
         )
 
         if set_as_default and image != self.default_image:
             self.set_default_image(image)
 
     def build_image(
@@ -2411,27 +2446,29 @@
         base_image: str = None,
         commands: list = None,
         secret_name: str = None,
         requirements: typing.Union[str, typing.List[str]] = None,
         mlrun_version_specifier: str = None,
         builder_env: dict = None,
         overwrite_build_params: bool = False,
+        requirements_file: str = None,
     ) -> typing.Union[BuildStatus, kfp.dsl.ContainerOp]:
         """Builder docker image for the project, based on the project's build config. Parameters allow to override
         the build config.
 
         :param image: target image name/path. If not specified the project's existing `default_image` name will be
                         used. If not set, the `mlconf.default_project_image_name` value will be used
         :param set_as_default: set `image` to be the project's default image (default False)
         :param with_mlrun:      add the current mlrun package to the container build
         :param skip_deployed:   skip the build if we already have the image specified built
         :param base_image:      base image name/path (commands and source code will be added to it)
         :param commands:        list of docker build (RUN) commands e.g. ['pip install pandas']
         :param secret_name:     k8s secret for accessing the docker registry
-        :param requirements:    list of python packages or pip requirements file path, defaults to None
+        :param requirements:    list of python packages, defaults to None
+        :param requirements_file:  pip requirements file path, defaults to None
         :param mlrun_version_specifier:  which mlrun package version to include (if not current)
         :param builder_env:     Kaniko builder pod env vars dict (for config/credentials)
                                 e.g. builder_env={"GIT_TOKEN": token}, does not work yet in KFP
         :param overwrite_build_params:  overwrite existing build configuration (default False)
 
            * False: the new params are merged with the existing (currently merge is applied to requirements and
              commands)
@@ -2442,14 +2479,15 @@
             image=image,
             set_as_default=set_as_default,
             base_image=base_image,
             commands=commands,
             secret_name=secret_name,
             with_mlrun=with_mlrun,
             requirements=requirements,
+            requirements_file=requirements_file,
             overwrite_build_params=overwrite_build_params,
         )
 
         function = mlrun.new_function("mlrun--project--image--builder", kind="job")
 
         build = self.spec.build
         result = self.build_function(
```

## mlrun/runtimes/base.py

```diff
@@ -11,23 +11,20 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import enum
 import getpass
 import http
 import traceback
-import typing
 import warnings
 from abc import ABC, abstractmethod
-from ast import literal_eval
 from base64 import b64encode
-from copy import deepcopy
 from datetime import datetime, timedelta, timezone
 from os import environ
-from typing import Dict, List, Optional, Tuple, Union
+from typing import Callable, Dict, List, Optional, Tuple, Union
 
 import requests.exceptions
 from deprecated import deprecated
 from kubernetes.client.rest import ApiException
 from nuclio.build import mlrun_footer
 from sqlalchemy.orm import Session
 
@@ -45,22 +42,15 @@
 
 from ..config import config
 from ..datastore import store_manager
 from ..db import RunDBError, get_or_set_dburl, get_run_db
 from ..errors import err_to_str
 from ..kfpops import mlrun_op
 from ..lists import RunList
-from ..model import (
-    BaseMetadata,
-    HyperParamOptions,
-    ImageBuilder,
-    ModelObj,
-    RunObject,
-    RunTemplate,
-)
+from ..model import BaseMetadata, HyperParamOptions, ImageBuilder, ModelObj, RunObject
 from ..utils import (
     dict_to_json,
     dict_to_yaml,
     enrich_image_url,
     get_in,
     get_parsed_docker_registry,
     logger,
@@ -278,81 +268,82 @@
             return
         self.metadata.credentials.access_key = (
             mlrun.model.Credentials.generate_access_key
         )
 
     def run(
         self,
-        runspec: RunObject = None,
-        handler=None,
-        name: str = "",
-        project: str = "",
-        params: dict = None,
-        inputs: Dict[str, str] = None,
-        out_path: str = "",
-        workdir: str = "",
-        artifact_path: str = "",
-        watch: bool = True,
-        schedule: Union[str, mlrun.common.schemas.ScheduleCronTrigger] = None,
-        hyperparams: Dict[str, list] = None,
-        hyper_param_options: HyperParamOptions = None,
-        verbose=None,
-        scrape_metrics: bool = None,
-        local=False,
-        local_code_path=None,
-        auto_build=None,
-        param_file_secrets: Dict[str, str] = None,
-        notifications: List[mlrun.model.Notification] = None,
+        runspec: Optional[
+            Union["mlrun.run.RunTemplate", "mlrun.run.RunObject", dict]
+        ] = None,
+        handler: Optional[Union[str, Callable]] = None,
+        name: Optional[str] = "",
+        project: Optional[str] = "",
+        params: Optional[dict] = None,
+        inputs: Optional[Dict[str, str]] = None,
+        out_path: Optional[str] = "",
+        workdir: Optional[str] = "",
+        artifact_path: Optional[str] = "",
+        watch: Optional[bool] = True,
+        schedule: Optional[Union[str, mlrun.common.schemas.ScheduleCronTrigger]] = None,
+        hyperparams: Optional[Dict[str, list]] = None,
+        hyper_param_options: Optional[HyperParamOptions] = None,
+        verbose: Optional[bool] = None,
+        scrape_metrics: Optional[bool] = None,
+        local: Optional[bool] = False,
+        local_code_path: Optional[str] = None,
+        auto_build: Optional[bool] = None,
+        param_file_secrets: Optional[Dict[str, str]] = None,
+        notifications: Optional[List[mlrun.model.Notification]] = None,
         returns: Optional[List[Union[str, Dict[str, str]]]] = None,
     ) -> RunObject:
         """
         Run a local or remote task.
 
-        :param runspec:        run template object or dict (see RunTemplate)
-        :param handler:        pointer or name of a function handler
-        :param name:           execution name
-        :param project:        project name
-        :param params:         input parameters (dict)
+        :param runspec:        The run spec to generate the RunObject from. Can be RunTemplate | RunObject | dict.
+        :param handler:        Pointer or name of a function handler.
+        :param name:           Execution name.
+        :param project:        Project name.
+        :param params:         Input parameters (dict).
         :param inputs:         Input objects to pass to the handler. Type hints can be given so the input will be parsed
                                during runtime from `mlrun.DataItem` to the given type hint. The type hint can be given
                                in the key field of the dictionary after a colon, e.g: "<key> : <type_hint>".
-        :param out_path:       default artifact output path
-        :param artifact_path:  default artifact output path (will replace out_path)
-        :param workdir:        default input artifacts path
-        :param watch:          watch/follow run log
+        :param out_path:       Default artifact output path.
+        :param artifact_path:  Default artifact output path (will replace out_path).
+        :param workdir:        Default input artifacts path.
+        :param watch:          Watch/follow run log.
         :param schedule:       ScheduleCronTrigger class instance or a standard crontab expression string
                                (which will be converted to the class using its `from_crontab` constructor),
                                see this link for help:
                                https://apscheduler.readthedocs.io/en/3.x/modules/triggers/cron.html#module-apscheduler.triggers.cron
-        :param hyperparams:    dict of param name and list of values to be enumerated e.g. {"p1": [1,2,3]}
+        :param hyperparams:    Dict of param name and list of values to be enumerated e.g. {"p1": [1,2,3]}
                                the default strategy is grid search, can specify strategy (grid, list, random)
-                               and other options in the hyper_param_options parameter
-        :param hyper_param_options:  dict or :py:class:`~mlrun.model.HyperParamOptions` struct of
-                                     hyper parameter options
-        :param verbose:        add verbose prints/logs
-        :param scrape_metrics: whether to add the `mlrun/scrape-metrics` label to this run's resources
-        :param local:      run the function locally vs on the runtime/cluster
-        :param local_code_path: path of the code for local runs & debug
-        :param auto_build: when set to True and the function require build it will be built on the first
-                           function run, use only if you dont plan on changing the build config between runs
-        :param param_file_secrets: dictionary of secrets to be used only for accessing the hyper-param parameter file.
-                            These secrets are only used locally and will not be stored anywhere
-        :param notifications: list of notifications to push when the run is completed
+                               and other options in the hyper_param_options parameter.
+        :param hyper_param_options: Dict or :py:class:`~mlrun.model.HyperParamOptions` struct of hyperparameter options.
+        :param verbose:             Add verbose prints/logs.
+        :param scrape_metrics:      Whether to add the `mlrun/scrape-metrics` label to this run's resources.
+        :param local:               Run the function locally vs on the runtime/cluster.
+        :param local_code_path:     Path of the code for local runs & debug.
+        :param auto_build:          When set to True and the function require build it will be built on the first
+                                    function run, use only if you don't plan on changing the build config between runs.
+        :param param_file_secrets:  Dictionary of secrets to be used only for accessing the hyper-param parameter file.
+                                    These secrets are only used locally and will not be stored anywhere
+        :param notifications:       List of notifications to push when the run is completed
         :param returns: List of log hints - configurations for how to log the returning values from the handler's run
                         (as artifacts or results). The list's length must be equal to the amount of returning objects. A
                         log hint may be given as:
 
                         * A string of the key to use to log the returning value as result or as an artifact. To specify
                           The artifact type, it is possible to pass a string in the following structure:
                           "<key> : <type>". Available artifact types can be seen in `mlrun.ArtifactType`. If no
                           artifact type is specified, the object's default artifact type will be used.
                         * A dictionary of configurations to use when logging. Further info per object type and artifact
                           type can be given there. The artifact key must appear in the dictionary as "key": "the_key".
 
-        :return: run context object (RunObject) with run metadata, results and status
+        :return: Run context object (RunObject) with run metadata, results and status
         """
         launcher = mlrun.launcher.factory.LauncherFactory.create_launcher(
             self._is_remote, local
         )
         return launcher.launch(
             runtime=self,
             task=runspec,
@@ -400,33 +391,14 @@
             runtime_env["MLRUN_LOG_LEVEL"] = "DEBUG"
         if config.httpdb.api_url:
             runtime_env["MLRUN_DBPATH"] = config.httpdb.api_url
         if self.metadata.namespace or config.namespace:
             runtime_env["MLRUN_NAMESPACE"] = self.metadata.namespace or config.namespace
         return runtime_env
 
-    def _create_run_object(self, runspec):
-        # TODO: Once implemented the `Runtime` handlers configurations (doc strings, params type hints and returning
-        #       log hints, possible parameter values, etc), the configured type hints and log hints should be set into
-        #       the `RunObject` from the `Runtime`.
-        if runspec:
-            runspec = deepcopy(runspec)
-            if isinstance(runspec, str):
-                runspec = literal_eval(runspec)
-            if not isinstance(runspec, (dict, RunTemplate, RunObject)):
-                raise ValueError(
-                    "task/runspec is not a valid task object," f" type={type(runspec)}"
-                )
-
-        if isinstance(runspec, RunTemplate):
-            runspec = RunObject.from_template(runspec)
-        if isinstance(runspec, dict) or runspec is None:
-            runspec = RunObject.from_dict(runspec)
-        return runspec
-
     @staticmethod
     def _handle_submit_job_http_error(error: requests.HTTPError):
         # if we receive a 400 status code, this means the request was invalid and the run wasn't created in the DB.
         # so we don't need to update the run state and we can just raise the error.
         # more status code handling can be added here if needed
         if error.response.status_code == http.HTTPStatus.BAD_REQUEST.value:
             raise mlrun.errors.MLRunBadRequestError(
@@ -783,25 +755,27 @@
 
     def with_requirements(
         self,
         requirements: Union[str, List[str]],
         overwrite: bool = False,
         verify_base_image: bool = False,
         prepare_image_for_deploy: bool = True,
+        requirements_file: str = "",
     ):
         """add package requirements from file or list to build spec.
 
-        :param requirements:                python requirements file path or list of packages
+        :param requirements:                a list of python packages
+        :param requirements_file:           a local python requirements file path
         :param overwrite:                   overwrite existing requirements
         :param verify_base_image:           verify that the base image is configured
                                             (deprecated, use prepare_image_for_deploy)
         :param prepare_image_for_deploy:    prepare the image/base_image spec for deployment
         :return: function object
         """
-        self.spec.build.with_requirements(requirements, overwrite)
+        self.spec.build.with_requirements(requirements, requirements_file, overwrite)
 
         if verify_base_image or prepare_image_for_deploy:
             # TODO: remove verify_base_image in 1.6.0
             if verify_base_image:
                 warnings.warn(
                     "verify_base_image is deprecated in 1.4.0 and will be removed in 1.6.0, "
                     "use prepare_image_for_deploy",
@@ -934,15 +908,15 @@
                             line += f", default={p['default']}"
                         print("    " + line)
 
 
 class BaseRuntimeHandler(ABC):
     # setting here to allow tests to override
     kind = "base"
-    class_modes: typing.Dict[RuntimeClassMode, str] = {}
+    class_modes: Dict[RuntimeClassMode, str] = {}
     wait_for_deletion_interval = 10
 
     @staticmethod
     @abstractmethod
     def _get_object_label_selector(object_id: str) -> str:
         """
         Should return the label selector to get only resources of a specific object (with id object_id)
@@ -953,29 +927,29 @@
         """
         There are some runtimes which we don't collect logs for using the log collector
         :return: whether it should collect log for it
         """
         return True
 
     def _get_possible_mlrun_class_label_values(
-        self, class_mode: typing.Union[RuntimeClassMode, str] = None
+        self, class_mode: Union[RuntimeClassMode, str] = None
     ) -> List[str]:
         """
         Should return the possible values of the mlrun/class label for runtime resources that are of this runtime
         handler kind
         """
         if not class_mode:
             return list(self.class_modes.values())
         class_mode = self.class_modes.get(class_mode, None)
         return [class_mode] if class_mode else []
 
     def list_resources(
         self,
         project: str,
-        object_id: typing.Optional[str] = None,
+        object_id: Optional[str] = None,
         label_selector: str = None,
         group_by: Optional[
             mlrun.common.schemas.ListRuntimeResourcesGroupByField
         ] = None,
     ) -> Union[
         mlrun.common.schemas.RuntimeResources,
         mlrun.common.schemas.GroupedByJobRuntimeResourcesOutput,
@@ -1224,16 +1198,16 @@
                     "reason"
                 ] = "A runtime resource related to this run could not be found"
                 run.setdefault("status", {})["last_update"] = now.isoformat()
                 db.store_run(db_session, run, run_uid, project)
 
     def _add_object_label_selector_if_needed(
         self,
-        object_id: typing.Optional[str] = None,
-        label_selector: typing.Optional[str] = None,
+        object_id: Optional[str] = None,
+        label_selector: Optional[str] = None,
     ):
         if object_id:
             object_label_selector = self._get_object_label_selector(object_id)
             if label_selector:
                 label_selector = ",".join([object_label_selector, label_selector])
             else:
                 label_selector = object_label_selector
@@ -1358,15 +1332,15 @@
                         or last_container_completion_time < container_completion_time
                     ):
                         last_container_completion_time = container_completion_time
 
         return in_terminal_state, last_container_completion_time, run_state
 
     def _get_default_label_selector(
-        self, class_mode: typing.Union[RuntimeClassMode, str] = None
+        self, class_mode: Union[RuntimeClassMode, str] = None
     ) -> str:
         """
         Override this to add a default label selector
         """
         class_values = self._get_possible_mlrun_class_label_values(class_mode)
         if not class_values:
             return ""
@@ -1436,17 +1410,17 @@
             else:
                 crd_objects = crd_objects["items"]
         return crd_objects
 
     def resolve_label_selector(
         self,
         project: str,
-        object_id: typing.Optional[str] = None,
-        label_selector: typing.Optional[str] = None,
-        class_mode: typing.Union[RuntimeClassMode, str] = None,
+        object_id: Optional[str] = None,
+        label_selector: Optional[str] = None,
+        class_mode: Union[RuntimeClassMode, str] = None,
         with_main_runtime_resource_label_selector: bool = False,
     ) -> str:
         default_label_selector = self._get_default_label_selector(class_mode=class_mode)
 
         if label_selector:
             label_selector = ",".join([default_label_selector, label_selector])
         else:
@@ -1469,15 +1443,15 @@
                 )
 
         return label_selector
 
     @staticmethod
     def resolve_object_id(
         run: dict,
-    ) -> typing.Optional[str]:
+    ) -> Optional[str]:
         """
         Get the object id from the run object
         Override this if the object id is not the run uid
         :param run: run object
         :return: object id
         """
         return run.get("metadata", {}).get("uid", None)
```

## mlrun/runtimes/kubejob.py

```diff
@@ -108,29 +108,31 @@
         load_source_on_run=None,
         with_mlrun=None,
         auto_build=None,
         requirements=None,
         overwrite=False,
         verify_base_image=False,
         prepare_image_for_deploy=True,
+        requirements_file=None,
     ):
         """specify builder configuration for the deploy operation
 
         :param image:      target image name/path
         :param base_image: base image name/path
         :param commands:   list of docker build (RUN) commands e.g. ['pip install pandas']
         :param secret:     k8s secret for accessing the docker registry
         :param source:     source git/tar archive to load code from in to the context/workdir
                            e.g. git://github.com/mlrun/something.git#development
         :param extra:      extra Dockerfile lines
         :param load_source_on_run: load the archive code into the container at runtime vs at build time
         :param with_mlrun: add the current mlrun package to the container build
         :param auto_build: when set to True and the function require build it will be built on the first
                            function run, use only if you dont plan on changing the build config between runs
-        :param requirements: requirements.txt file to install or list of packages to install
+        :param requirements: a list of packages to install
+        :param requirements_file: requirements file to install
         :param overwrite:  overwrite existing build configuration
 
            * False: the new params are merged with the existing (currently merge is applied to requirements and
              commands)
            * True: the existing params are replaced by the new ones
         :param verify_base_image:           verify that the base image is configured
                                             (deprecated, use prepare_image_for_deploy)
@@ -144,14 +146,15 @@
             secret,
             source,
             extra,
             load_source_on_run,
             with_mlrun,
             auto_build,
             requirements,
+            requirements_file,
             overwrite,
         )
 
         if verify_base_image or prepare_image_for_deploy:
             if verify_base_image:
                 # TODO: remove verify_base_image in 1.6.0
                 warnings.warn(
```

## mlrun/utils/helpers.py

```diff
@@ -12,14 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import enum
 import hashlib
 import inspect
 import json
+import os
 import re
 import sys
 import time
 import typing
 import warnings
 from datetime import datetime, timezone
 from importlib import import_module
@@ -1328,14 +1329,19 @@
     """
     source, reference, branch = resolve_git_reference_from_source(url)
     if not branch and not reference:
         url = f"{url}#refs/heads/{repo.active_branch}"
     return url
 
 
+def is_file_path(filepath):
+    root, ext = os.path.splitext(filepath)
+    return os.path.isfile(filepath) and ext
+
+
 class DeprecationHelper(object):
     """A helper class to deprecate old schemas"""
 
     def __init__(self, new_target, version="1.4.0"):
         self._new_target = new_target
         self._version = version
```

## mlrun/utils/notifications/notification_pusher.py

```diff
@@ -47,15 +47,15 @@
         for run in self._runs:
             if isinstance(run, dict):
                 run = mlrun.model.RunObject.from_dict(run)
 
             for notification in run.spec.notifications:
                 notification.status = run.status.notifications.get(
                     notification.name
-                ).status
+                ).get("status", mlrun.common.schemas.NotificationStatus.PENDING)
                 if self._should_notify(run, notification):
                     self._notification_data.append((run, notification))
 
     def push(
         self,
         db: mlrun.api.db.base.DBInterface = None,
     ):
```

## mlrun/utils/version/version.json

### Pretty-printed

 * *Similarity: 0.5%*

 * *Differences: {"'git_commit'": "'729b30200c9c7e156527a2a9a2a6ebf92d6fc454'", "'version'": "'1.4.0-rc8'"}*

```diff
@@ -1,4 +1,4 @@
 {
-    "git_commit": "1b5fc7231758d1343e152ab06cde575d9b3f7028",
-    "version": "1.4.0-rc7"
+    "git_commit": "729b30200c9c7e156527a2a9a2a6ebf92d6fc454",
+    "version": "1.4.0-rc8"
 }
```

## Comparing `mlrun-1.4.0rc7.dist-info/LICENSE` & `mlrun-1.4.0rc8.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `mlrun-1.4.0rc7.dist-info/METADATA` & `mlrun-1.4.0rc8.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mlrun
-Version: 1.4.0rc7
+Version: 1.4.0rc8
 Summary: Tracking and config of machine learning runs
 Home-page: https://github.com/mlrun/mlrun
 Author: Yaron Haviv
 Author-email: yaronh@iguazio.com
 License: MIT
 Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
@@ -23,15 +23,14 @@
 License-File: LICENSE
 Requires-Dist: urllib3 (<1.27,>=1.25.4)
 Requires-Dist: chardet (<4.0,>=3.0.2)
 Requires-Dist: GitPython (>=3.1.30,~=3.1)
 Requires-Dist: aiohttp (~=3.8)
 Requires-Dist: aiohttp-retry (~=2.8)
 Requires-Dist: click (~=8.0.0)
-Requires-Dist: protobuf (<3.20,>=3.13)
 Requires-Dist: kfp (<1.8.14,~=1.8.0)
 Requires-Dist: nest-asyncio (~=1.0)
 Requires-Dist: ipython (<9.0,>=7.0)
 Requires-Dist: nuclio-jupyter (~=0.9.10)
 Requires-Dist: numpy (<1.23.0,>=1.16.5)
 Requires-Dist: pandas (<1.5.0,~=1.2)
 Requires-Dist: pyarrow (<12,>=10.0)
```

## Comparing `mlrun-1.4.0rc7.dist-info/RECORD` & `mlrun-1.4.0rc8.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -3,84 +3,84 @@
 mlrun/config.py,sha256=5PPsvyOm_5wE16UXBUC9VoEBW0uRpp3Ybfey6MBqBUk,55437
 mlrun/errors.py,sha256=XEb1pxwy5Lzr9q0VT4z_SjP74jy37HFSmdd2hddWgvY,6780
 mlrun/execution.py,sha256=RMuw1D78GOWxDk3aQfFtFRZZ5maM4T7BiXaApoQA_6E,39096
 mlrun/features.py,sha256=pDUvV6HlkxZnUwW3lg7oq3vBwdcJQBprvdyGPNv57X8,15624
 mlrun/k8s_utils.py,sha256=bU5bIrk7YfrX0nEBTogpSZtTG7pVwD0X1rBZmcDlDX0,4876
 mlrun/kfpops.py,sha256=CGVXW22wmYJ_2Dl-eReFMw77mKVhtOgBnIiqRitX8WM,29646
 mlrun/lists.py,sha256=yOKwpS71Fua08sV825Anth8aaR9H5bHZyV544YbnXj4,8360
-mlrun/model.py,sha256=oDsdnQiLa1YOfKk1ju2g6l6BE7ztI4oMZaUznqozpK4,57270
+mlrun/model.py,sha256=ddzP_ziCd_mSFEd-_9868Udg1fOaZPJLvc8b9dTm4F0,58708
 mlrun/render.py,sha256=983QAYawKTFlwXLpUwGC1gWEjUQUFxl1lo8bPQuXIA0,11828
-mlrun/run.py,sha256=B_y5_1tGoc6izObLCdDlih86cl5Jl6SN5rj87t08ewY,64759
+mlrun/run.py,sha256=kxSFJz1buuYLqDlUEOIDLtk01IDgQF2VN9XzYL29Bfg,64773
 mlrun/secrets.py,sha256=xr-Omz0j5qjLGPCG_Gn2vsCP0CbqJldAAKpy5N1KAiM,7783
 mlrun/api/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/alembic.ini,sha256=oeSJRHwBbF3c3-N_RJilcZD-diq3F-oPv21gDIkrZGs,2105
 mlrun/api/constants.py,sha256=fyTQXJe4sx4GK8vZxklivgJgaSyOftk_NezGKA1J-mo,685
 mlrun/api/initial_data.py,sha256=cr9mBSuVSO3zv6RbGXKvtewzqDJQoV_zu572050qkJ4,25653
-mlrun/api/launcher.py,sha256=VgdxypKd5puTldLOeqWklN1iEU3oVMau-ihidQJn7z4,7543
-mlrun/api/main.py,sha256=H8BSP38H_r11o1SveMC-elKBnISUIh3lV4hUaw6gSow,26443
+mlrun/api/launcher.py,sha256=sRz8YTyBW6TGxJQb1exKhZvhkOIdkB2XJ2ghEqPE2oE,7575
+mlrun/api/main.py,sha256=r-Xpj96nzB43l164uRltqvDfwgPJ48o-sMlnPkExz4g,26457
 mlrun/api/middlewares.py,sha256=D9d-3XudnhyK_J1EGdWexCCswiS4QuSWvhDvCH1LEEU,5247
 mlrun/api/api/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/api/api.py,sha256=N5QgIWwnm-wgeW_8bUqVTtnRqgOUJGKDUGpScHHs78Y,4243
 mlrun/api/api/deps.py,sha256=OZt6UxT9Yg0O6egcB7a_YbZkKYkk5Vh9tTMKQKxW8nI,3197
-mlrun/api/api/utils.py,sha256=vUtih16e1zpijAzivWiXut70TC0Dh9a_ba1xB451rEE,36404
+mlrun/api/api/utils.py,sha256=yJA6Pg1HBX3YpPutOICdOHPfAzr2VDmxsWaxgQOdlm4,36613
 mlrun/api/api/endpoints/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
-mlrun/api/api/endpoints/artifacts.py,sha256=LSOp8o8n30-tfoEFQ-T57i_mWKiSAElmM9x6Mh1k6t0,10394
+mlrun/api/api/endpoints/artifacts.py,sha256=Dwz4G9FVRYZVf-q0XcPUgvLa6sxm_aMPCuVxzi9ymzA,10452
 mlrun/api/api/endpoints/auth.py,sha256=YmcYs5pl8Il4jKDVjUGH_S5VXzam06kweO_xXpdSyeg,1199
 mlrun/api/api/endpoints/background_tasks.py,sha256=EQ5zvps1mXaVoNeoyOwMmRTAp0_nwpXtFAItvTA6uo4,3618
 mlrun/api/api/endpoints/client_spec.py,sha256=2hzm_Sq9JyPTfWgaKIjN_vGQX3xLnCScUpuoQjm3NU4,1214
 mlrun/api/api/endpoints/clusterization_spec.py,sha256=eBQya6jeYYBEe7WoCMNmXbkDxgmeDP5DCISGCZ4eAio,1175
-mlrun/api/api/endpoints/feature_store.py,sha256=CPISuRQeYuWyu0HiIQt35mOtJDQbDF6of7T7GGJsoiE,29543
+mlrun/api/api/endpoints/feature_store.py,sha256=fK_e9Yl_22-tdIGIR0gi3v-24Wnqx01wKcgLuoTUWRg,29192
 mlrun/api/api/endpoints/files.py,sha256=v_FwFb-29mqDlx2tI8D9VUHthyjnmUpGsWTnfVZR7cE,6104
 mlrun/api/api/endpoints/frontend_spec.py,sha256=iwXzTuTd5qcI-NQQagdOY_VBBXAJf8GS22V9N1SbgMo,5468
-mlrun/api/api/endpoints/functions.py,sha256=IUHh2zyoEXedkCK4H1c8XfloZ2E5f3dnUiGWkjwv_Q0,35206
-mlrun/api/api/endpoints/grafana_proxy.py,sha256=3tqafsudGF9Ru3VjZCRsXZuoLIEmIWnYJEQaIYWrqjg,5986
+mlrun/api/api/endpoints/functions.py,sha256=Gko9mxjSmFnC2SGDJ_7f5pVre-khIePX-hFCXg-ZbWY,35186
+mlrun/api/api/endpoints/grafana_proxy.py,sha256=CVh8dwHj0RtU4q_PeA-klfVUkCEP3MVgIDnPv4iLbWk,5935
 mlrun/api/api/endpoints/healthz.py,sha256=rp_esZLesf92tiaFM_E50LR0m_EbsdZxuudYNMG9VVU,1344
-mlrun/api/api/endpoints/hub.py,sha256=D3hiBs4hYAjtqt6CTigM8kcQLT_Wkf0Gh_dAxTO8DEk,10399
-mlrun/api/api/endpoints/logs.py,sha256=CXKdbcQtEth2tqr8I6dEWVpb3kZjL7BNdlDHwNsDQ_s,2450
-mlrun/api/api/endpoints/model_endpoints.py,sha256=qeKxuocrubBARRu_EvHCIHly7WVgLrjMcHCjCpEmbi4,15817
+mlrun/api/api/endpoints/hub.py,sha256=ozOtTM339AAVBZf1Q9pZ7-oESlWmsVR-uRyps92WmOo,10312
+mlrun/api/api/endpoints/logs.py,sha256=UvAUiycHZ7Mh7gczPd8QD2RipelAzCueiI_bFxNOkxM,2445
+mlrun/api/api/endpoints/model_endpoints.py,sha256=c5OqJaz2CZqy265BACaxLUWBYH2v2bJBXvvl0f8IFds,15651
 mlrun/api/api/endpoints/operations.py,sha256=lnfvQmZIcj1z6TgxCy5Tx5x7PiNls3DgE3Yzddvo-9Q,3756
-mlrun/api/api/endpoints/pipelines.py,sha256=eU0D_RFw6KYyL6hYuPjHfaIkXQ4_5u_ZTBxC3lSfJ1g,9220
+mlrun/api/api/endpoints/pipelines.py,sha256=9RVZR_7st3Om9IKNdo2tiqn_H87xZu69eQKdmqWQsWE,9165
 mlrun/api/api/endpoints/projects.py,sha256=sI1dYHBnBWjxqJqOVgRjs2bXML2SKfu8k6yE-2sHBPs,11494
 mlrun/api/api/endpoints/runs.py,sha256=S2kSYQnIliMMjDpo1-iyEGIZ46PWAwpzwUi7nY-IUTo,9078
-mlrun/api/api/endpoints/runtime_resources.py,sha256=YovL4c29KJOyln5xAdfJwv_XQEbzH3AmUVoAwkNW0T0,9063
-mlrun/api/api/endpoints/schedules.py,sha256=Ozke4eWnAAFMOmI9qsSNNKZHY9Rz0YvvkwzShzIQ42k,10731
+mlrun/api/api/endpoints/runtime_resources.py,sha256=1WHjBYuVEMSHtnKnj-W80-ZsIuApsaf8E8EiNlzDGak,9035
+mlrun/api/api/endpoints/schedules.py,sha256=ndEaQiwzGunHcEUTnbi5Yy81kzeWvsggKI5nhn-z2aE,10554
 mlrun/api/api/endpoints/secrets.py,sha256=GHxl-w4TUq28kHp8HR9jHbgjnp4LtDpiKwfQufTJ800,6061
 mlrun/api/api/endpoints/submit.py,sha256=loLzF5p5L7Wu5R2TnuPNNtwxTN1WIg_ei0ZdoCoMRDI,5298
-mlrun/api/api/endpoints/tags.py,sha256=kWEIdg9QvmX4pQOyYUQsBlzMVqGsluioDkKBNwWDgX4,4894
+mlrun/api/api/endpoints/tags.py,sha256=xz4PW25Ymuk0RGNCJTLxtxDAIbNOawXeKiZVpX-jKEY,4849
 mlrun/api/api/endpoints/internal/__init__.py,sha256=Lq7QbwU5hFGCq6hzU28fA5t1soMesi7DVo99T21blU8,1203
 mlrun/api/api/endpoints/internal/config.py,sha256=kXnraXbXv029QZMMEjwvhsUWof69wTvFBLcRyB32JFc,1043
-mlrun/api/api/endpoints/internal/memory_reports.py,sha256=plNcfWD6LgZTAA_3T-vXDPKvoojXFN7L9g6uDVylBLA,1724
+mlrun/api/api/endpoints/internal/memory_reports.py,sha256=8Jg15M_X-SxDs2_ZB2rIKnTHUwjeageFMmynGrzZ9Eg,1718
 mlrun/api/crud/__init__.py,sha256=uIwvg_fG3qljOheF5QeY2yLt3601YWaabhb0-eb_hQw,1209
 mlrun/api/crud/artifacts.py,sha256=aoOmrXCGqNCA9b39cQbPojmRXK6qKAaX9WlZjdduaaA,5610
 mlrun/api/crud/client_spec.py,sha256=3Xif0Od3-zqb3Ptd3BInjg6rKhNLlJyIU38CF3efZ58,7331
 mlrun/api/crud/clusterization_spec.py,sha256=GBvK-rCVTJFBfstvFp2wJAOQWKc370ysuPFGm1rqwJg,1055
 mlrun/api/crud/feature_store.py,sha256=0XGBGuPiG8IStGmQroIOC18KtrpRXnnOyo3MqrHuLGY,18628
 mlrun/api/crud/functions.py,sha256=HHCpT9Rbn-kl5o2m12JOSEXovq23Vx_gBjjpbim7g8c,3556
 mlrun/api/crud/hub.py,sha256=rcTgrmV5-iqRLvBzjjNEolEiw7anoWizhx6neEL5eco,12025
-mlrun/api/crud/logs.py,sha256=_iKAt9deN5cNVJ8FqSb7Je0392p0YAccQUKMpnwZqRA,9729
+mlrun/api/crud/logs.py,sha256=zzDHSQ_VmG48JlpoCfznzMjjdmA5wdt7kTnyc-4ACCk,9409
 mlrun/api/crud/notifications.py,sha256=aEIx2ByVQzHxdmjePiYXxzUpZA1yZ8YXhR-nvIbet3o,2751
-mlrun/api/crud/pipelines.py,sha256=wDGPUmEq7slXkW2aOyNiq_x1aSaz0kl9xC71NUnmF20,14030
+mlrun/api/crud/pipelines.py,sha256=0JQWYvN9IevOyMuUi_BPZQGYthc1vTt7VS4a2kybGnA,14090
 mlrun/api/crud/projects.py,sha256=h9695fNAmZ9MnhDdbOhS0ljG1cgm8XiGMiq1K-Cl7tg,14269
 mlrun/api/crud/runs.py,sha256=xpsN6z_JhBZpptoGUvva173biMfDCsZaBmfaYNSofnM,5963
 mlrun/api/crud/runtime_resources.py,sha256=aJoWA1aInheitsLw02Fi7ohYPKTrk4pWXck7NwZF1yA,5575
 mlrun/api/crud/secrets.py,sha256=5eTyi3b8p398Y1yzX7NbbFJbXScEEDagA0tmbRGX9fY,20145
 mlrun/api/crud/tags.py,sha256=FEu6E0Srp7886ICAQfccf4h0ssHyvYP7-kSpB_oa9yE,3277
 mlrun/api/crud/model_monitoring/__init__.py,sha256=CAW_Xhm94IVid0yos0tLQUd_UdCRYz-_2s_rAloZEZw,722
 mlrun/api/crud/model_monitoring/grafana.py,sha256=peEPjIsu0xvGPEdRis4c16n5m3-jxa8lbqgwCiGNu2s,15692
 mlrun/api/crud/model_monitoring/model_endpoints.py,sha256=8W77_N0h-Uq130W7tlLtTkh4fMH9-ofOBcQiZTFXTpM,43000
 mlrun/api/crud/runtimes/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/crud/runtimes/nuclio/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
-mlrun/api/crud/runtimes/nuclio/function.py,sha256=fEqGrM0yyyq8urUxzFcG43-m3txF-Oyxdhm6e4DCB4w,17168
+mlrun/api/crud/runtimes/nuclio/function.py,sha256=BZzOIwjICsSTdUyeDGxn8yBTGu5DBUddoA68VzSDDUw,18574
 mlrun/api/crud/runtimes/nuclio/helpers.py,sha256=E3ThgKBZyPa-VVWv3rTRtQAdR9lIVLkYz8_hfyntocA,11398
 mlrun/api/db/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/db/base.py,sha256=ETSlJ24N0s63dLpDS5yVo7vFg3ap-ySwhaKyCOcqUZo,15056
 mlrun/api/db/init_db.py,sha256=bx7urn0e9VweQwtbsldK_mn63aTZhqHRHpyhwbM-W_4,816
 mlrun/api/db/session.py,sha256=_5DVL4YyGGFG9sbtHx_Bq2C1aHrZC5V8MS7TJfNeWIk,993
 mlrun/api/db/sqldb/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
-mlrun/api/db/sqldb/db.py,sha256=t-ZGaWbTbyVSfXpB17TEt99TDh9h7bjNqushfih3aok,144159
+mlrun/api/db/sqldb/db.py,sha256=N18blG3DDWgxefDkoJpNHkgcbQr8GxGbKx3_VjpPWVQ,145830
 mlrun/api/db/sqldb/helpers.py,sha256=j8VK-l_qZ5vLUjGkFK3D3fBgDgPmi-U8hU1MkMIAhC0,2340
 mlrun/api/db/sqldb/session.py,sha256=97QcZc7EOhypk3ZMl0F5k1ogsgK834S3SxCj3UNry-s,2542
 mlrun/api/db/sqldb/models/__init__.py,sha256=0cHZKMpzqkC6u3WGPEYE8zPcahY6KxBrK2pwkzTCCME,1063
 mlrun/api/db/sqldb/models/models_mysql.py,sha256=zyFuS_tj6legl1QvJ5QBrLIgilAnDcZHSvHC-bXMqdQ,20642
 mlrun/api/db/sqldb/models/models_sqlite.py,sha256=10IzVBZ79Yj1vqFbWCocZ5QNrz1H91HzlzUFe6iu31k,18304
 mlrun/api/migrations_mysql/env.py,sha256=U5Fu1WLV5vggRYy4sa7d1ItJr1H3-T71BnkOw4ZjWIs,2906
 mlrun/api/migrations_mysql/versions/28383af526f3_market_place_to_hub.py,sha256=kcdNEMQHbTRGpzh4CfLlUJtClG_eHo-X0QNPOQEFBuI,1203
@@ -113,29 +113,29 @@
 mlrun/api/migrations_sqlite/versions/e5594ed3ab53_adding_name_and_updated_to_runs_table.py,sha256=lQ0lPq6xZD59iupkbAo0wCV-otE0G9lmjEpqIBZEguA,1831
 mlrun/api/migrations_sqlite/versions/f4249b4ba6fa_adding_feature_vectors.py,sha256=AWkrtG6jWOMJHyLqR8jrmbp95Fk9qB6qhjjYLb1mezo,3936
 mlrun/api/migrations_sqlite/versions/f7b5a1a03629_adding_feature_labels.py,sha256=KrIm5pHwHlJr5e3DdtMcBiEjgbopOniWzDi9T1XTSHQ,2588
 mlrun/api/schemas/__init__.py,sha256=JEimO9A93JbrxJQkJRDUNw4kAKyShmaD5McKulw3ykY,13338
 mlrun/api/utils/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/asyncio.py,sha256=E80efqnDt-rRLVqbdjlzHjfe5SNwB4Krn1Y9D0C0JMg,1092
 mlrun/api/utils/background_tasks.py,sha256=4FIdUB2rDJDb7bndMZIr1kQeWPDi9_loHHsjaVMq5Ys,7371
-mlrun/api/utils/builder.py,sha256=addItnH36FJzWmYT2iqkuKePWCMKZpNqXaTXBR1aJOA,25637
+mlrun/api/utils/builder.py,sha256=wuD38Uz7v27pyJQM4Tjh10pjeWG0wuvpL5jwEMy7fRg,25794
 mlrun/api/utils/helpers.py,sha256=kQglUe_oaTFll4LhHNg1pwkAkiynzFWowiQlWXc4_7U,2431
 mlrun/api/utils/memory_reports.py,sha256=Diraa4EbJJ28NGrfSuOuGroVsE2sNeRkjUp7Dl4qDlI,3728
 mlrun/api/utils/periodic.py,sha256=Vc8jz2WIsItkb7rcmdtxUfD4-Pohlg_XVbLEUw0S394,2599
 mlrun/api/utils/scheduler.py,sha256=5reTxTtKdQE4wJymnTemQmM8AJ3lvL8fEMeVWtcg0FY,39305
 mlrun/api/utils/auth/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/auth/verifier.py,sha256=-JjXEX0tqqBymuR7P-f5mgsJF9FvwZGmb5k2SnTiekE,12383
 mlrun/api/utils/auth/providers/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/auth/providers/base.py,sha256=VUvHxeh7HvyJRzo-xRj7ESjlwJ10ilt_-e9U53rui44,1381
 mlrun/api/utils/auth/providers/nop.py,sha256=Y1vv1aH7NDCXY3vnt3HHzZeDappHZx79Jp-C9or8t94,1460
 mlrun/api/utils/auth/providers/opa.py,sha256=xPjubPC29yIglhgBhKB5zVp7JqJC-x71xKwo2YKv9Jo,10883
 mlrun/api/utils/clients/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/clients/chief.py,sha256=gI6-LgsZyPVIi8VnjmX1ILgGG-jLYvtYSZVC1QLP3Bg,13271
 mlrun/api/utils/clients/iguazio.py,sha256=VZun1-HGB1NBVGxMweVp8SzEa0lA38Oj00DcuM9ziHI,31249
-mlrun/api/utils/clients/log_collector.py,sha256=d1Tj680X0QSC83re1vhX62z_0tt5WvNjHqKv1wMVNF4,12109
+mlrun/api/utils/clients/log_collector.py,sha256=5jgixIbzX4GFkOGUrIaTBHDyzlzT_DfHjnAbx6qp82A,12281
 mlrun/api/utils/clients/nuclio.py,sha256=yT8atthDWpvlDU4rQiyHXo1tCFDrx3-s1iLJadhJ3nk,9916
 mlrun/api/utils/clients/protocols/__init__.py,sha256=xY3wHC4TEJgez7qtnn1pQvHosi8-5UJOCtyGBS7FcGE,571
 mlrun/api/utils/clients/protocols/grpc.py,sha256=P_He0oRyRvsCpTz7Pl2bZkqwA1W04Wl3BJMusM30pkY,2567
 mlrun/api/utils/db/__init__.py,sha256=B-yvMk7vTs3QqtlPkM4pnZk_B4QKTGnfNhYr2n4Z30M,571
 mlrun/api/utils/db/alembic.py,sha256=sUVnWHXRzA_Yhn2GWiSqeQ8dcfpC4IPQpTFBjTta_iU,3305
 mlrun/api/utils/db/backup.py,sha256=LL4qL3YaLAbehS-KHn-Ieys333ZReEnmFIOoYV7BKzc,8214
 mlrun/api/utils/db/mysql.py,sha256=9FeqQpvOQjyuoxsRp8W1sv9mxUD43vJ4KAUitSX8gwk,3787
@@ -310,53 +310,53 @@
 mlrun/frameworks/tf_keras/callbacks/mlrun_logging_callback.py,sha256=N1_lNXSig6FwSUt1P8ZNKf1Hie-9pMo2feFjV7AoJzg,8791
 mlrun/frameworks/tf_keras/callbacks/tensorboard_logging_callback.py,sha256=YM7gNuryhioDrvVPBhpIUo9lH-bhE5JdE-xSo-kriP4,28728
 mlrun/frameworks/xgboost/__init__.py,sha256=2-q_HGIgwzZUoBpxMC5OBYpn29qh84HHwZpHRcOke_I,10287
 mlrun/frameworks/xgboost/mlrun_interface.py,sha256=JwbFkYz97gmkjLN1V_zu8nTG9zSey1RtUmUO6XfaZ54,878
 mlrun/frameworks/xgboost/model_handler.py,sha256=3KSLoL_uBBhRPkGEgRxJz1MPxQbcbvuIxJawQConfrQ,11617
 mlrun/frameworks/xgboost/utils.py,sha256=Yz7vIfnFMqa2A0k2GweXL912-tt7JnQdYsNX-pFs45I,1069
 mlrun/launcher/__init__.py,sha256=pZgS6ZN126aJme4z5spCX-RmdchShxMnQeCPya8AsQI,577
-mlrun/launcher/base.py,sha256=9mQZ3WA-H2sW5K1JWlYxYnVe2cl8vp7R5noesgRZK6Q,14925
+mlrun/launcher/base.py,sha256=g7bJmB54E2IRMZMqBqs8uOcoQC4tF2MvzIrOuJKgxtw,15180
 mlrun/launcher/client.py,sha256=OVEGewYy9gOvVjtVUonKJO5tBU4Ob2ORJ3IEjdrjREQ,6164
 mlrun/launcher/factory.py,sha256=Co7Y9WI9_CCbr5slKTVDbTV0uO4XQZ9ysC8d2YlTG94,1883
-mlrun/launcher/local.py,sha256=jrX-4SkWNWO46v96YxgWBjWyiCZ9gOANhdRfpmpB1X8,10378
-mlrun/launcher/remote.py,sha256=P68m2LrqVthBXvKw7HRsXGxc7qE11xI3eh72tf2A-io,6742
+mlrun/launcher/local.py,sha256=dAq_FKvFIcm0A-SBy4bHJbRhLRFBsTkS3OBy573-VR8,10569
+mlrun/launcher/remote.py,sha256=itlPtrmG2x7iLRvDzwDn8LJbNFNsH9ZvtXsosKaR3T4,6770
 mlrun/mlutils/__init__.py,sha256=enRhuXMjuev4xr-0l1zLxtoDp79FHc-HXbUoagYomvk,760
 mlrun/mlutils/data.py,sha256=uQ45eaKYx3Jy93l2TqosFW68Kj_ZtVI06ilxGxydaUY,5325
 mlrun/mlutils/models.py,sha256=_CijiNJkLnWdz0HU3DAU6P8TbobY7R2QVpuCOHTJD-4,2598
 mlrun/mlutils/plots.py,sha256=0-Rih6th9WkgzZRPIPZwz08lv4bVSX7YbyGNgA02xdA,30120
 mlrun/model_monitoring/__init__.py,sha256=YIUIQs1hwX-PWBu23dH-IY9gQYXW8HA0oFX3izaG9d0,1208
 mlrun/model_monitoring/features_drift_table.py,sha256=DlMkc-GwRhIALXB0OdCQkvOZQUVNI69RpJ1PAwLqK9Y,23948
 mlrun/model_monitoring/helpers.py,sha256=6e7yA4a3tErirdSCuC-BIH8OqISzkFcx-h9-5K38STU,9756
 mlrun/model_monitoring/model_endpoint.py,sha256=enXHLZ72Sd-lQ7lMeBQNnQaf4xX-TLZbTgEMuNw9UYQ,5196
 mlrun/model_monitoring/model_monitoring_batch.py,sha256=kmlD3q6rBT7X2fwugBeV9tKcLmrAFsX3uxa59VS8Yxs,36885
-mlrun/model_monitoring/stream_processing_fs.py,sha256=vVt34BY0p83a1MFfgWn3zzSOfvabm1Ioy-69f5e-qGU,43172
+mlrun/model_monitoring/stream_processing_fs.py,sha256=NAPRpD9lj6SOzPbAT-cT2NrUw-Fn0-wOel42eMINzHk,43134
 mlrun/model_monitoring/stores/__init__.py,sha256=0FlHSjq2etDBnlzzj930LEF0p6bO7G5i_INTUtT-lLE,4240
 mlrun/model_monitoring/stores/kv_model_endpoint_store.py,sha256=EmA0so7YnliUWWwzekmRkHKAmAy4wJ3Cao5G5wAaMM8,17357
 mlrun/model_monitoring/stores/model_endpoint_store.py,sha256=-Brbv-jMx47rIFUPP0Ykb92o1KPyic9FgGBy4TA3ejs,5695
 mlrun/model_monitoring/stores/sql_model_endpoint_store.py,sha256=wlu4OL0uydJVEeuZz1_C_flIRrrBGEjWzGjzjfoF_9Q,15706
 mlrun/model_monitoring/stores/models/__init__.py,sha256=ea5Sca62LlYpjsTDMlaxRyIjRCpwOPxRwFJ5sABur-k,884
 mlrun/model_monitoring/stores/models/base.py,sha256=Az7Q2JZKCTqZJ2hqYaOLr2owVMagClFp2KwuriKMx24,655
 mlrun/model_monitoring/stores/models/mysql.py,sha256=vVVSIssH_ZHMG-BbqwbFlaiPcN8DQtU3mM2vTySAPdY,3741
 mlrun/model_monitoring/stores/models/sqlite.py,sha256=jLWkY8srgal7_aCL2eDPZIoceNGsi4Dec1T2rHNd0BI,3658
 mlrun/platforms/__init__.py,sha256=NNh9MSxgjdi7QftO3DHp4axQnBeO5IjxD8oR13_jp3A,2400
 mlrun/platforms/iguazio.py,sha256=3lp40GjKu4YM2ITSUaSw8M9tDFh-jsJ88nWr5vBbIiw,23997
 mlrun/platforms/other.py,sha256=DwqbdbMNlkC2nEl1yJ0jF9WZJzjVu2IVPTC3bQ_W9Y0,11852
 mlrun/projects/__init__.py,sha256=dsXSDyqBhLi8OOfpdjLJpYOwC2fy_Q_Ki95Bk6gVSwc,1153
-mlrun/projects/operations.py,sha256=ifZGJidODXsnbJt7wG94upzkNOU24NQNhbivGWYTHRs,17480
+mlrun/projects/operations.py,sha256=-a_wikYQjMY2Le30CEdsxLw8Waf3-I8JfUz4qbqkqEM,17582
 mlrun/projects/pipelines.py,sha256=YLdLNirIp_p9Mm3BoU-tjRLtygzeJtd-cnfTQFVd2Ng,38343
-mlrun/projects/project.py,sha256=AkCJ8BfmDBEZL9SbcrYoWej0beqawph2QDll1GucsPs,111849
+mlrun/projects/project.py,sha256=cc_ZApfkmCFb7QjQBG6Pl_n4_d-1yjhNBfXLW60HmjQ,113384
 mlrun/runtimes/__init__.py,sha256=NpPeD7XxDNxmeOqLSEmb7tUN59cYZlvw-DnJxla_peE,8773
-mlrun/runtimes/base.py,sha256=f6MJJmaeagILyIHY-rFghRZOcuyw0o4ls-aVw_BpYZ4,86765
+mlrun/runtimes/base.py,sha256=h10BuVTDRkq4Pgu1tw85ED5uqO0vajIUfQrdlvfXk5o,86181
 mlrun/runtimes/constants.py,sha256=Os_6YpWE8WMhigm1h3RKvn9Uo4LXNaEbA2xNSEDDEao,6689
 mlrun/runtimes/daskjob.py,sha256=d7MRUptiR7fCTc-ClbGHzlWxqOw6xXLqyyXm0C42Fio,30353
 mlrun/runtimes/funcdoc.py,sha256=PAvbUFXLei7vFYPwlntJhnUgBqn38kMlaSbp_Y2Ice4,9561
 mlrun/runtimes/function.py,sha256=GH6XUVOAvnhARg_oV3BUyLEG5xaYZHtiwrBbZ2FwniE,45205
 mlrun/runtimes/function_reference.py,sha256=ikxeXeFPAn7PpfYR1DPBRFc9MSXXFM34uH5z6iRTz9M,4911
 mlrun/runtimes/generators.py,sha256=WvXzsfZZWqxLV1ncZ-lzFHZH2ITK6ICROgDv2vfQUs4,6530
-mlrun/runtimes/kubejob.py,sha256=CNn1zw6gbz2Dwo45rlRyKoX6QLqrDvXbnk8U6XsLSNk,15318
+mlrun/runtimes/kubejob.py,sha256=6Q3jYEPrZlOv-yoDJaF4sQSbvL39iN56Ux4nyS4GIAk,15410
 mlrun/runtimes/local.py,sha256=5lgXISWJUhu24lmiZzP6n4Y9HQ6ie0tiB-p5qLDU_0w,19158
 mlrun/runtimes/nuclio.py,sha256=ih2iwrJieeEom3iW0yU99QG4_u_Bdv7VWgs1CK4Q1P8,2885
 mlrun/runtimes/pod.py,sha256=foeea0tUMSWbH4_SS_biOIgEmUL3RP3NlQwNb62QGYk,60808
 mlrun/runtimes/remotesparkjob.py,sha256=Lp2EN32GQ1rY_34MEepdUzRTg-AP-OKyUM7xcy0Npb8,7695
 mlrun/runtimes/serving.py,sha256=jruUAxwi9PVHY-mlZkljMD7P5WGyfbSS8pJmzDqQI9E,29858
 mlrun/runtimes/utils.py,sha256=4ufkD4i38EZnFMgTsMykDZpiEJ87I3ZeWxbZDNyWs6c,21048
 mlrun/runtimes/mpijob/__init__.py,sha256=E0oiOsSYsRBBR0HV6e_EGaL_j2_dYEJwAcICnF8mOYU,790
@@ -379,32 +379,32 @@
 mlrun/serving/v1_serving.py,sha256=UF6Ydgyo-DuHZ4DkrEdNMQl5oopVaZqm4EfBMBSvhDY,11814
 mlrun/serving/v2_serving.py,sha256=7g-FBPqyc8zgCY6Xi8SoS23VldDnOoL2G81m8qGbDOU,21460
 mlrun/utils/__init__.py,sha256=YnW6IErGUxc1mdd7a3eNvoYO_fy-mv4Uvu5Go8uT-kM,826
 mlrun/utils/async_http.py,sha256=AvI4a9D0frI6XxHvqnQ4AzEXopezo90zZHvsOAJJt6g,10397
 mlrun/utils/azure_vault.py,sha256=atz9fIu1vfgWAND1g6flRQDhrX-xBxZ_6MOWm34Onh0,3456
 mlrun/utils/clones.py,sha256=lKgQeibQ3xQ9LH5bZTZCoYCXoOx_2mYNGD5A-OOxwAQ,6245
 mlrun/utils/db.py,sha256=SqDrvIpGX_qHs0MNx_PWQNRcUhHaKLngoHFKLW3m5j0,1662
-mlrun/utils/helpers.py,sha256=asyt3CPOj0y-sYuoZ-QGWEJTswb1rjX0zxbW_vcTISg,43609
+mlrun/utils/helpers.py,sha256=PaqRwL7K62do6gRr4iW6MxKYS68ogjB9NVugA6jZ3i4,43736
 mlrun/utils/http.py,sha256=FVgdYV8Np3TKbqszEtXrlgwqNyjScTMLAjJhlsWLifo,7093
 mlrun/utils/logger.py,sha256=yg3m2TAs4zgc0qJRtE6zvqkSHTr_rJSRfDqqEeHrh8c,7035
 mlrun/utils/model_monitoring.py,sha256=1y-E4AlR-yZ1qW2yfxcHvm3rHZoytDz4IbIju8cPOOU,9969
 mlrun/utils/regex.py,sha256=3hSOVEU5128xio_3BLBEmvvRGLipmGP2Sh7XgVAYs8w,3954
 mlrun/utils/singleton.py,sha256=kV9HhbzdmXo8gGKBPdbHWspRDutlkKX1ZEn96xs_LRs,883
 mlrun/utils/v3io_clients.py,sha256=ekxhjfcUnjV8cejQYTQUHnhYOKHA4KekIdSaywydTdM,1319
 mlrun/utils/vault.py,sha256=EgxGAfn-mxRCj8cKEzSrrZQ9SV7BFP8mIuSnbhJpNUQ,10447
 mlrun/utils/notifications/__init__.py,sha256=CgWLxslSqhTH-tExi_UR4AT-ipjkGUF4gwf9mKcNua8,990
-mlrun/utils/notifications/notification_pusher.py,sha256=SwftENaHxRdfrpI1XrenhbC2v81zJkdSyCf99zCFD2A,12462
+mlrun/utils/notifications/notification_pusher.py,sha256=DjCptmTG_l-prxxQV4v8qE3hP51FwuBiXzy1ZwVucJQ,12518
 mlrun/utils/notifications/notification/__init__.py,sha256=iNF31hiEkenkp1VmJ4keyjixS17-gZ0oGuWNO7tlnm4,1803
 mlrun/utils/notifications/notification/base.py,sha256=ddlf70Cd59bMvvWi2EFqzJQTXSRHw19E4r-oX2Tk8rk,2177
 mlrun/utils/notifications/notification/console.py,sha256=JggUV_Ql8lluvlONtkmQWk6SeSPY7gEhICAbkg0jYas,1971
 mlrun/utils/notifications/notification/git.py,sha256=mJGIuQbL_sECQ846mzcG_jMfIvzQVuZoHYDk9bvmr8g,4722
 mlrun/utils/notifications/notification/ipython.py,sha256=bYIUpzb2QnLPhacL8l20NU4suRjE0-lxeYYXpHuqiTw,2021
 mlrun/utils/notifications/notification/slack.py,sha256=hONSD43eLSxQ5n3x8HHqI-zhHc4ZxThR8lLcfkKoHfw,3751
 mlrun/utils/version/__init__.py,sha256=hwfJgGWYGWFpepVGI1GbuCPqqEFGRbgguJg5sC0v4TU,614
-mlrun/utils/version/version.json,sha256=6YazXR3Vq955Thvj7SbTrrmvt82_u3vKuYtDRh8Z9Zs,88
+mlrun/utils/version/version.json,sha256=LJejHtM1R3rXLZJMlUNOGv1ZUw2bbPSD0Gahn7F_31A,88
 mlrun/utils/version/version.py,sha256=O4Q4kwtKlI73oK7oBPuz4SVkUI8BC11E9DJIKHT91kU,1970
-mlrun-1.4.0rc7.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-mlrun-1.4.0rc7.dist-info/METADATA,sha256=81c4V21kcYD9FyUxiOrBGxGXTf5C-QQqqSiiUy3k9eE,16892
-mlrun-1.4.0rc7.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-mlrun-1.4.0rc7.dist-info/entry_points.txt,sha256=ZbXmb36B9JmK7EaleP8MIAbZSOQXQV0iwKR6si0HUWk,47
-mlrun-1.4.0rc7.dist-info/top_level.txt,sha256=NObLzw3maSF9wVrgSeYBv-fgnHkAJ1kEkh12DLdd5KM,6
-mlrun-1.4.0rc7.dist-info/RECORD,,
+mlrun-1.4.0rc8.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+mlrun-1.4.0rc8.dist-info/METADATA,sha256=Ua2qBcIiNq2aOnspdjbLIuAPTUMqCLnQt249Vh9rVbo,16853
+mlrun-1.4.0rc8.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+mlrun-1.4.0rc8.dist-info/entry_points.txt,sha256=ZbXmb36B9JmK7EaleP8MIAbZSOQXQV0iwKR6si0HUWk,47
+mlrun-1.4.0rc8.dist-info/top_level.txt,sha256=NObLzw3maSF9wVrgSeYBv-fgnHkAJ1kEkh12DLdd5KM,6
+mlrun-1.4.0rc8.dist-info/RECORD,,
```

